{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/PaleoLipidRR/marine-AOA-GDGT-distribution/blob/main/PNAS_pythonCodeS2_BeyondTEX86_Analytics_Visualizations_RR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hu3mLKn5Zpnq"
   },
   "source": [
    "# **Python Code S2**\n",
    "\n",
    "## Supplementary Information for:\n",
    "## Beyond TEX86: GDGT inform marine archaea ecology and evolution\n",
    "Ronnakrit Rattanasriampaipong, Yi Ge Zhang, Ann Pearson, Brian Hedlund, and Shuang Zhang\n",
    "\n",
    "Corresponding Author: Ronnakrit Rattanasriampaipong\n",
    "E-mail: rrattan@tamu.edu\n",
    "***\n",
    "\n",
    "Notebook Description:\n",
    "\n",
    "This is a jupyter notebook containing python scripts that we use to analyzed processed GDGT datasets (Dataset S2). The input file is an output from the Python Code S1 (see SI Appendix; Python Code S1, Dataset S1).\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Y-GCN7nqmLxi"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "warnings.warn('ProplotWarning:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yELfNTL-arLo"
   },
   "source": [
    "# **1. Import python packages of interest**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nunZrMhMA-qp"
   },
   "source": [
    "### 1.1 Mounting your google drive with Google colab so that you can read files directly from the google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jWGss5VNsfAy",
    "outputId": "3dff9e5d-9c26-4584-f377-1c1200e563ed"
   },
   "outputs": [],
   "source": [
    "# # Mounting your google drive\n",
    "# from google.colab import drive\n",
    "\n",
    "# ROOT = \"/content/drive\"\n",
    "# drive.mount(ROOT,force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhVWIne0gikv"
   },
   "source": [
    "\n",
    "### 1.2 Computation and Data Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fBmfwuUFZdiB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy as scipy\n",
    "from scipy import stats\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn import mixture\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, RANSACRegressor, HuberRegressor, TheilSenRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOtkQKexa1Lb"
   },
   "source": [
    "### 1.2 Data plotting and visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2B590oBhCu2"
   },
   "source": [
    "**Uncomment !apt-get if you run this notebook from Colab.**\n",
    "shapely and cartopy are not good friends, especially on Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xOt92dPOg-nV"
   },
   "outputs": [],
   "source": [
    "# ### %%capture is a command to suppress cell's outputs. So, please do not worry if you don't see anything coming out after running the cell. I just don't want to let the installations overwhelming your screen.\n",
    "# %%capture\n",
    "# !apt-get install libproj-dev proj-data proj-bin\n",
    "# !apt-get install libgeos-dev\n",
    "# %pip install cartopy\n",
    "# !apt-get -qq install python-cartopy python3-cartopy\n",
    "# %pip uninstall -y shapely    # cartopy and shapely aren't friends (early 2020)\n",
    "# %pip install shapely --no-binary shapely\n",
    "# %pip install proplot \n",
    "# %pip install pyrolite  ### This is to install libraries that are not available in Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "w6tNiqu6a1xb"
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms as transforms\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "import proplot as plot\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "from pyrolite.util.time import Timescale\n",
    "gts = Timescale()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twdVR-nvbHyE"
   },
   "source": [
    "###  1.3 Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DbuF-bcnbIK5"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import os\n",
    "import requests\n",
    "import io\n",
    "import netCDF4\n",
    "from netCDF4 import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ratta\\\\marine-AOA-GDGT-distribution'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JeuSBKvTbOEX"
   },
   "source": [
    "###  1.4 Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KnC3B3bXbOWB"
   },
   "outputs": [],
   "source": [
    "def sigmaT_cal_Miller_and_Poisson_1981(temp_array,sal_array):\n",
    "    '''\n",
    "    This is a function for seawater density (sigma-t) calculation based on seawater temperature and salinity.\n",
    "    The calculations follow Miller and Poisson (1981).\n",
    "    \n",
    "    Reference:\n",
    "    Millero, F. J., & Poisson, A. (1981). International one-atmosphere equation of state of seawater. Deep Sea Research Part A. Oceanographic Research Papers, 28(6), 625-629.\n",
    "    '''\n",
    "    #Miller and Poisson (1981)\n",
    "    #parameter for sigma calculation\n",
    "    A = 8.24493e-1 - 4.0899e-3*temp_array + 7.6438e-5*(temp_array**2) - 8.2467e-7*(temp_array**3) + 5.3875e-9*(temp_array**4)\n",
    "    B = -5.72466e-3 + 1.0227e-4*temp_array - 1.6546e-6*(temp_array**2)\n",
    "    C = 4.8314e-4\n",
    "    rho_0=999.842594 + 6.793952e-2*temp_array - 9.095290e-3*(temp_array**2) + 1.001685e-4*(temp_array**3) - 1.120083e-6*(temp_array**4) + 6.536336e-9*(temp_array**5)\n",
    "    rho=rho_0 + (A*sal_array) + (B*(sal_array**1.5)) + (C*(sal_array**2))\n",
    "    return rho-1000\n",
    "\n",
    "def rollmean_calculation_step(sel_df,sel_attribute,younger_age,older_age,bin_step):\n",
    "    '''\n",
    "    sel_attribute is the column name e.g., 'paleoDepth_adjusted'\n",
    "    \n",
    "    Return the array with 5 columns:\n",
    "    array_rollmean[:,0:4]\n",
    "    0: plot_timestep\n",
    "    1: mean\n",
    "    2: median\n",
    "    3: lower iqr (percentile 25th)\n",
    "    4: upper iqr (percentile 75th)\n",
    "    5: minimum of data range (percentile 0)\n",
    "    6: maximum of data range (percentile 100)\n",
    "    '''\n",
    "    \n",
    "    attributes = [sel_attribute]\n",
    "    \n",
    "    plot_timestep = np.arange(younger_age,older_age+bin_step,bin_step)\n",
    "    nbins = len(plot_timestep)\n",
    "    array_rollmean = np.empty((nbins,7))\n",
    "    array_rollmean[:,0] = plot_timestep\n",
    "\n",
    "    min_counts = 3\n",
    "\n",
    "\n",
    "    sel_group = sel_df[sel_df.dataType_level0==\"Ancient\"]\n",
    "\n",
    "    for i in range(len(array_rollmean[:,0])):\n",
    "        if sel_group[sel_attribute].where((sel_group.sampleAge>=plot_timestep[i])&\n",
    "                                          (sel_group.sampleAge<plot_timestep[i]+bin_step)).count() <=min_counts:\n",
    "            array_rollmean[i,1] = np.nan\n",
    "            array_rollmean[i,2] = np.nan\n",
    "            array_rollmean[i,3] = np.nan\n",
    "            array_rollmean[i,4] = np.nan\n",
    "            array_rollmean[i,5] = np.nan\n",
    "            array_rollmean[i,6] = np.nan\n",
    "\n",
    "\n",
    "        else:\n",
    "            bin_data = sel_group[sel_attribute].where((sel_group.sampleAge>=plot_timestep[i])&\n",
    "                                                      (sel_group.sampleAge<plot_timestep[i]+bin_step))\n",
    "            array_rollmean[i,1] = bin_data[~np.isnan(bin_data)].mean()\n",
    "            \n",
    "            a = scipy.stats.mstats.mquantiles(bin_data[~np.isnan(bin_data)], prob=[0,0.25, 0.5, 0.75,1], alphap=0.4, betap=0.4,axis=None, limit=())\n",
    "            array_rollmean[i,2] = a[2]\n",
    "            array_rollmean[i,3] = a[1]\n",
    "            array_rollmean[i,4] = a[3]\n",
    "            \n",
    "            array_rollmean[i,5] = a[0]\n",
    "            array_rollmean[i,6] = a[4]\n",
    "\n",
    "\n",
    "            \n",
    "    return array_rollmean\n",
    "\n",
    "\n",
    "#### codes to generate woa urls modified from https://pyoceans.github.io/python-oceans/_modules/oceans/datasets.html\n",
    "def _woa_variable(variable):\n",
    "    _VAR = {\n",
    "        'temperature': 't',\n",
    "        'salinity': 's',\n",
    "        'silicate': 'i',\n",
    "        'phosphate': 'p',\n",
    "        'nitrate': 'n',\n",
    "        'oxygen_saturation': 'O',\n",
    "        'dissolved_oxygen': 'o',\n",
    "        'apparent_oxygen_utilization': 'A',\n",
    "    }\n",
    "    v = _VAR.get(variable)\n",
    "    if not v:\n",
    "        raise ValueError(\n",
    "            f'Unrecognizable variable. Expected one of {list(_VAR.keys())}, got \"{variable}\".'\n",
    "        )\n",
    "    return v\n",
    "\n",
    "def _woa_url(variable, time_period, resolution):\n",
    "    base = 'https://www.ncei.noaa.gov/thredds-ocean/dodsC'\n",
    "\n",
    "    v = _woa_variable(variable)\n",
    "\n",
    "    if variable not in ['salinity', 'temperature']:\n",
    "        pref = 'woa09'\n",
    "        warnings.warn(\n",
    "            f'The variable \"{variable}\" is only available at 1 degree resolution, '\n",
    "            f'annual time period, and \"{pref}\".'\n",
    "        )\n",
    "        return (\n",
    "            f'{base}/'\n",
    "            f'{pref}/'\n",
    "            f'{variable}_annual_1deg.nc'\n",
    "        )\n",
    "    else:\n",
    "        dddd = 'decav'\n",
    "        pref = 'woa18'\n",
    "\n",
    "    grids = {\n",
    "        '5': ('5deg', '5d'),\n",
    "        '1': ('1.00', '01'),\n",
    "        '04': ('0.25', '04'),\n",
    "    }\n",
    "    grid = grids.get(resolution)\n",
    "    if not grid:\n",
    "        raise ValueError(\n",
    "            f'Unrecognizable resolution. Expected one of {list(grids.keys())}, got \"{resolution}\".'\n",
    "        )\n",
    "    res = grid[0]\n",
    "    gg = grid[1]\n",
    "\n",
    "    time_periods = {\n",
    "        'annual': '00',\n",
    "        'january': '01',\n",
    "        'february': '02',\n",
    "        'march': '03',\n",
    "        'april': '04',\n",
    "        'may': '05',\n",
    "        'june': '06',\n",
    "        'july': '07',\n",
    "        'august': '08',\n",
    "        'september': '09',\n",
    "        'october': '10',\n",
    "        'november': '11',\n",
    "        'december': '12',\n",
    "        'winter': '13',\n",
    "        'spring': '14',\n",
    "        'summer': '15',\n",
    "        'autumn': '16',\n",
    "    }\n",
    "\n",
    "    time_period = time_period.lower()\n",
    "    if len(time_period) == 3:\n",
    "        tt = [time_periods.get(k) for k in time_periods.keys() if k.startswith(time_period)][0]\n",
    "    elif len(time_period) == 2 and time_period in time_periods.values():\n",
    "        tt = time_period\n",
    "    else:\n",
    "        tt = time_periods.get(time_period)\n",
    "\n",
    "    if not tt:\n",
    "        raise ValueError(\n",
    "            f'Unrecognizable time_period. '\n",
    "            f'Expected one of {list(time_periods.keys())}, got \"{time_period}\".'\n",
    "        )\n",
    "\n",
    "    url = (\n",
    "        f'{base}'\n",
    "        '/ncei/woa/'\n",
    "        f'{variable}/decav/{res}/'\n",
    "        f'{pref}_{dddd}_{v}{tt}_{gg}.nc'  # '[PREF]_[DDDD]_[V][TT][FF][GG]' Is [FF] used?\n",
    "    )\n",
    "    return url\n",
    "\n",
    "   #  variables:\n",
    "   #      'temperature': 't',\n",
    "   #      'salinity': 's',\n",
    "   #      'silicate': 'i',\n",
    "   #      'phosphate': 'p',\n",
    "   #      'nitrate': 'n',\n",
    "   #      'oxygen_saturation': 'O',\n",
    "   #      'dissolved_oxygen': 'o',\n",
    "   #      'apparent_oxygen_utilization': 'A',\n",
    "   # time_periods:\n",
    "   #      'annual': '00',\n",
    "   #      'january': '01',\n",
    "   #      'february': '02',\n",
    "   #      'march': '03',\n",
    "   #      'april': '04',\n",
    "   #      'may': '05',\n",
    "   #      'june': '06',\n",
    "   #      'july': '07',\n",
    "   #      'august': '08',\n",
    "   #      'september': '09',\n",
    "   #      'october': '10',\n",
    "   #      'november': '11',\n",
    "   #      'december': '12',\n",
    "   #      'winter': '13',\n",
    "   #      'spring': '14',\n",
    "   #      'summer': '15',\n",
    "   #      'autumn': '16',\n",
    "   # resolutions:\n",
    "   #  '5': ('5deg', '5d'),\n",
    "   #  '1': ('1.00', '01'),\n",
    "   #  '04': ('0.25', '04'),\n",
    "        \n",
    "\n",
    "    # an=Objectively analyzed climatologies are the objectively interpolated mean fields for oceanographic variables at standard depth levels for the World Ocean.\n",
    "    # mn=The statistical mean is the average of all unflagged interpolated values at each standard depth level for each variable in each 1° square which contains at least one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EovgCV9jnx6g"
   },
   "source": [
    "# **2. Load and clean datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DWAqJOO5BLHU"
   },
   "source": [
    "## **2.1 Read xlsx/csv files as pandas dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "c4KN0wE9nlQ3",
    "outputId": "370968ab-2cdc-45d8-833f-cfe9a4705188"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/ratta/marine-AOA-GDGT-distribution/spreadsheets/PNAS_datasetS2_BeyondTEX86_RR.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19800/1529606558.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"C:/Users/ratta/marine-AOA-GDGT-distribution/spreadsheets/\"\u001b[0m  \u001b[1;31m### for local Git repository\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"PNAS_datasetS2_BeyondTEX86_RR.xlsx\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Sheet1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m##This line is to remove the Unnamed: 0 column (the additional column after completing the pythonCodeS1 pre-processing)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64bit\\envs\\pyleo\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64bit\\envs\\pyleo\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         raise ValueError(\n",
      "\u001b[1;32m~\\anaconda3_64bit\\envs\\pyleo\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1189\u001b[0m                 \u001b[0mext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xls\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m                 ext = inspect_excel_format(\n\u001b[0m\u001b[0;32m   1192\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m                 )\n",
      "\u001b[1;32m~\\anaconda3_64bit\\envs\\pyleo\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1068\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1069\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1070\u001b[1;33m     with get_handle(\n\u001b[0m\u001b[0;32m   1071\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1072\u001b[0m     ) as handle:\n",
      "\u001b[1;32m~\\anaconda3_64bit\\envs\\pyleo\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/ratta/marine-AOA-GDGT-distribution/spreadsheets/PNAS_datasetS2_BeyondTEX86_RR.xlsx'"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows',4,'display.max_columns',10)\n",
    "# filepath = \"/content/drive/MyDrive/Colab Notebooks/Excel/MarineAOA_project/\"  ### Replace with your the location of your file --- for mounted Google Drive\n",
    "filepath = \"C:/Users/ratta/marine-AOA-GDGT-distribution/spreadsheets/\"  ### for local Git repository\n",
    "filename = \"PNAS_datasetS2_BeyondTEX86_RR.xlsx\"\n",
    "df = pd.read_excel(filepath+filename,sheet_name='Sheet1')\n",
    "df = df.iloc[:,1:]  ##This line is to remove the Unnamed: 0 column (the additional column after completing the pythonCodeS1 pre-processing)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_K6Nobp5LFc",
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## **2.2. Import WOA18 data and generate seawater density (sigma-T)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ep-FT2T0OzAs"
   },
   "source": [
    "### 2.2.1 Annual average dataset from the multi-decadal climatologies (0.25degx0.25deg; 1955-2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i0Sv6-Mz36uV",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Uncomment this cell if you have netcdf files in your local directory\n",
    "# filepath = \"C:/Users/ratta/OneDrive - Texas A&M University/Marine AOA Evolution_shared/Desktop/netcdf/\"  ### change filepath to your local directory\n",
    "# ts_decav_filename = 'woa18_decav_t00_04.nc'\n",
    "# ts = xr.open_mfdataset(filepath+ts_decav_filename,decode_times=False,chunks={'time':1,'depth':1,'lon':100})\n",
    "\n",
    "# ss_decav_afilname = 'woa18_decav_s00_04.nc'\n",
    "# ss = xr.open_mfdataset(filepath+ss_decav_filname,decode_times=False,chunks={'time':1,'depth':1,'lon':100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = _woa_url('temperature','00','04')\n",
    "ts = xr.open_dataset(url,decode_times=False,chunks={'time':1,'depth':1})\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = _woa_url('salinity','00','04')\n",
    "ss = xr.open_dataset(url,decode_times=False,chunks={'time':1,'depth':1})\n",
    "ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iugrl_3MH0HU"
   },
   "source": [
    "### 2.2.2 Monthly average dataset from the multi-decadal climatologies (0.25degx0.25deg; 1955-2017)#### Uncomment this cell if you have netcdf files in your local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ut8gQ_BoAl5Y"
   },
   "outputs": [],
   "source": [
    "#### Uncomment this cell if you have netcdf files in your local directory\n",
    "# filepath = \"/content/drive/MyDrive/Colab Notebooks/netcdf/WOA18_monthly/\" ### change filepath to your local directory\n",
    "# ts_mon_filname =\"woa18_decav_t*.nc\"\n",
    "# ts_mon = xr.open_mfdataset(filepath+ts_mon_filname,concat_dim='time',decode_times=False,combine = 'nested',chunks={'time':1,'depth':1,'lon':100})\n",
    "\n",
    "# ss_mon_filname =\"woa18_decav_s*.nc\"\n",
    "# ss_mon = xr.open_mfdataset(filepath+ss_mon_filname,concat_dim='time',decode_times=False,combine = 'nested', chunks={'time':1,'depth':1,'lon':100})\n",
    "\n",
    "# mon_rng = np.linspace(1,12,12)\n",
    "# ts_mon = ts_mon.update({\"time\":(\"time\",mon_rng)})\n",
    "# ss_mon = ss_mon.update({\"time\":(\"time\",mon_rng)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = []\n",
    "for i in range(12):\n",
    "    url = _woa_url('temperature',str(i+1).zfill(2),'04') ### extracting files from 01 to 12 (January to December)\n",
    "    url_list.append(url)\n",
    "url_list\n",
    "ts_mon = xr.open_mfdataset(url_list,concat_dim='time',decode_times=False,combine = 'nested',chunks={'time':1,'depth':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "25Fr32S_nJzw",
    "outputId": "1e9c10e8-8aa2-451e-a307-0b0d55c2c4ff"
   },
   "outputs": [],
   "source": [
    "url_list = []\n",
    "for i in range(12):\n",
    "    url = _woa_url('salinity',str(i+1).zfill(2),'04') ### extracting files from 01 to 12 (January to December)\n",
    "    url_list.append(url)\n",
    "url_list\n",
    "ss_mon = xr.open_mfdataset(url_list,concat_dim='time',decode_times=False,combine = 'nested',chunks={'time':1,'depth':1})\n",
    "ss_mon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1qtcfDXKlyM",
    "tags": []
   },
   "source": [
    "## 2.3 Calculate seawater density (sigma-T) from imported temperture and salinity following Millero and Poission (1981)\n",
    "\n",
    "Reference: <br>\n",
    "Millero, F. J., & Poisson, A. (1981). International one-atmosphere equation of state of seawater. Deep Sea Research Part A. Oceanographic Research Papers, 28(6), 625-629."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AbmtBHz8L9tg"
   },
   "source": [
    "### *2.3.1 Annual average of Sigma-T climatologies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "7lu1QtO_IiD7",
    "outputId": "2845caa6-b661-41f7-e58b-529c0ea6d9cc"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19800/1313192425.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Load t_an and s_an data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mt_an_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt_an\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0ms_an_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms_an\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msel_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt_an_all\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ts' is not defined"
     ]
    }
   ],
   "source": [
    "#Load t_an and s_an data\n",
    "t_an_all = ts.t_an.isel(time=0)\n",
    "s_an_all = ss.s_an.isel(time=0)\n",
    "\n",
    "sel_t = t_an_all\n",
    "sel_s = s_an_all\n",
    "\n",
    "sigma_all=sigmaT_cal_Miller_and_Poisson_1981(sel_t,sel_s)\n",
    "sigma_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yyyVsGg5MXGH"
   },
   "source": [
    "### **2.3.2 Monthly average of Sigma-T climatologies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "kaAxKn9DKwi6",
    "outputId": "57ab95de-9b49-43ca-8a6c-47c697e9cd5c"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ts_mon' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19800/526803270.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Load t_an and s_an data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mt_an_all_mon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mts_mon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt_an\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0ms_an_all_mon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mss_mon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms_an\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msel_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt_an_all_mon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ts_mon' is not defined"
     ]
    }
   ],
   "source": [
    "#Load t_an and s_an data\n",
    "t_an_all_mon = ts_mon.t_an\n",
    "s_an_all_mon = ss_mon.s_an\n",
    "\n",
    "sel_t = t_an_all_mon\n",
    "sel_s = s_an_all_mon\n",
    "\n",
    "sigma_all_mon=sigmaT_cal_Miller_and_Poisson_1981(sel_t,sel_s)\n",
    "sigma_all_mon = sigma_all_mon.chunk(chunks={'depth':57})\n",
    "sigma_all_mon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywc8e2LVN4hz"
   },
   "source": [
    "### **2.3.3 Standard deviation volution of monthly average of Sigma-T climatologies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "nZnjon01L57r",
    "outputId": "7924ca7c-b00a-4d89-9281-ccd71f85fa23",
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sigma_all_mon' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19800/3824067110.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msigma_mon_std\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigma_all_mon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msigma_mon_std\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sigma_all_mon' is not defined"
     ]
    }
   ],
   "source": [
    "sigma_mon_std = sigma_all_mon.std(dim='time')\n",
    "sigma_mon_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JevUvR7BC3Zk"
   },
   "source": [
    "# **3. Data preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KmuXJZxuDEPw"
   },
   "source": [
    "## **3.1 Some labeling adjustments that will ease my data visualizations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aiSC1XDSAg5k",
    "outputId": "9d72c6f4-67ff-4dea-f98b-79b216819d1c"
   },
   "outputs": [],
   "source": [
    "new_dataType = []\n",
    "for i in range(df.shape[0]):\n",
    "    if df.dataType_level1.iloc[i] == 'Core top':\n",
    "        if df.oceanLayer_class.iloc[i] == 'Surface ocean':\n",
    "            new_dataType.append('Shallow core top')\n",
    "        elif df.oceanLayer_class.iloc[i] == 'Deep ocean':\n",
    "            new_dataType.append('Deep core top')\n",
    "        else:\n",
    "            new_dataType.append(df.dataType_level1.iloc[i])\n",
    "    elif df.dataType_level1.iloc[i] == 'Water-column SPM':\n",
    "        if df.oceanLayer_class.iloc[i] == 'Surface ocean':\n",
    "            new_dataType.append('Shallow SPM')\n",
    "        elif df.oceanLayer_class.iloc[i] == 'Deep ocean':\n",
    "            new_dataType.append('Deep SPM')\n",
    "        else:\n",
    "            new_dataType.append(df.dataType_level1.iloc[i])\n",
    "    else:\n",
    "        new_dataType.append(df.dataType_level1.iloc[i])\n",
    "\n",
    "df['dataType_level3'] = new_dataType\n",
    "df.dataType_level3.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yqxhkvNmDa_V"
   },
   "source": [
    "## **3.2 Paleo-water depth adjustment**\n",
    "\n",
    "For some paleo water depths that are above sea level (SL), we will assume those paleo depths to be at SL (0m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "Bgw8MAaLDMXu",
    "outputId": "6fd9e0d1-5704-4650-dfa2-0ab9872cb975"
   },
   "outputs": [],
   "source": [
    "for i in range(len(df.paleoWaterDepth)):\n",
    "    if df.paleoWaterDepth.iloc[i] < 0:\n",
    "        df.paleoWaterDepth.iloc[i] = 0\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "df.paleoWaterDepth.hist(bins=np.arange(0,6000,100))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kFnaUx_EMvc"
   },
   "source": [
    "## **3.3 Splitting IPL, non-IPL, and hot spring datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Oe9FP-2EOGx"
   },
   "outputs": [],
   "source": [
    "df_IPL = df[df.lipidClass=='IPL-GDGTs']\n",
    "df_nonIPL = df[df.lipidClass!='IPL-GDGTs'][((df.dataType_level1!='Culture - Hot spring')&\n",
    "                                            (df.dataType_level1!='Hot spring')&\n",
    "                                            (df.dataType_level1!='Culture - ThAOA')\n",
    "                                           )]\n",
    "\n",
    "## We separate hot spring datasets as the GDGT QC indices may not applicable with the thermophilic archaea                                       \n",
    "df_nonIPL_hs = df[df.lipidClass!='IPL-GDGTs'][((df.dataType_level1=='Culture - Hot spring')|\n",
    "                                            (df.dataType_level1=='Hot spring')|\n",
    "                                            (df.dataType_level1=='Culture - ThAOA')\n",
    "                                           )]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PF_N1S_wEXxO"
   },
   "source": [
    "# **4. Data visualizations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dh1JmOVgEeig"
   },
   "source": [
    "## **4.1 Dictionaries for data visualizations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZCuhzaaZEWQr"
   },
   "outputs": [],
   "source": [
    "colors_mapping = {'Culture - Hot spring':'red9',\n",
    "                  'Culture - ThAOA':'red5',\n",
    "                  'Culture - AOA':'teal7',\n",
    "                  'Hot spring':'gold',  #yellow Hot Springs #EDC948\n",
    "                  'Shallow SPM':'lime3', #lightgreen Water-column SPM (0-100m)\n",
    "                  'Deep SPM':'lime7', #green Water-column SPM\n",
    "                  'Shallow core top':'blue3',  #light blue Core Top (0-100m)\n",
    "                  'Deep core top':'blue7',  #blue Core Top\n",
    "                  'Late Cenozoic':'yellow3',  #light organge Late Cenozoic\n",
    "                  'Early Cenozoic':'yellow7',  #orange Early Cenozoic\n",
    "                  'Mesozoic':'#B07AA1',  #purple Mesozoic\n",
    "                  'C0 cluster':'#1F77B4',\n",
    "                  'C1 cluster':'#FF7F0E',\n",
    "                 }\n",
    "\n",
    "plots_mapping = {'Culture - Hot spring':0,\n",
    "                 'Culture - ThAOA':1,\n",
    "                 'Culture - AOA':3,\n",
    "                 'Hot spring':2,\n",
    "                 'Shallow SPM':4,\n",
    "                 'Deep SPM':6,\n",
    "                 'Shallow core top':5,\n",
    "                 'Deep core top':7,\n",
    "                 'Late Cenozoic':8,\n",
    "                 'Early Cenozoic':9,\n",
    "                 'Mesozoic':10,  \n",
    "                 }\n",
    "\n",
    "plots_mapping2 = {'Hot spring':0,\n",
    "                 'Shallow SPM':1,\n",
    "                 'Deep SPM':3,\n",
    "                 'Shallow core top':2,\n",
    "                 'Deep core top':4,\n",
    "                 'Late Cenozoic':5,\n",
    "                 'Early Cenozoic':6,\n",
    "                 'Mesozoic':7,  \n",
    "                 }\n",
    "\n",
    "names_mapping={'Culture - Hot spring':r'$\\it{Crenarchaeota}$ cultures',\n",
    "               'Culture - ThAOA':'ThAOA cultures',\n",
    "               'Culture - AOA':'Shallow AOA cultures',\n",
    "               'Hot spring':'Hot spring mats',\n",
    "               'Shallow SPM':'Shallow SPM',\n",
    "               'Deep SPM':'Deep SPM',\n",
    "               'Shallow core top':'Shallow core tops',\n",
    "               'Deep core top':'Deep core tops',\n",
    "               'Late Cenozoic':'Late Cenozoic',\n",
    "               'Early Cenozoic':'Early Cenozoic',\n",
    "               'Mesozoic':'Mesozoic',  \n",
    "             }\n",
    "colors_GMM_mapping = {0:'#1F77B4',\n",
    "                      '0':'#1F77B4',\n",
    "                      1:'#FF7F0E',\n",
    "                      '1':'#FF7F0E',\n",
    "                      2:'#BAB0AC',\n",
    "                      '2':'#BAB0AC'\n",
    "                      }\n",
    "\n",
    "month_mapping = { 0 : 'Jan',\n",
    "                 1 : \"Feb\",\n",
    "                 2 : \"Mar\",\n",
    "                 3 : \"Apr\",\n",
    "                 4 : \"May\",\n",
    "                 5 : \"Jun\",\n",
    "                 6 : \"Jul\",\n",
    "                 7 : \"Aug\",\n",
    "                 8 : \"Sep\",\n",
    "                 9 : \"Oct\",\n",
    "                 10 : \"Nov\",\n",
    "                 11 : \"Dec\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4h_nqWJtcDnk"
   },
   "source": [
    "## **4.2 Figures in main text**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ff-x_mLrcMdJ"
   },
   "source": [
    "### **4.2.1 Figure 1 in main text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dlbDM9_eEkIp"
   },
   "outputs": [],
   "source": [
    "def fig1_mainText_PNAS_MarineAOA():\n",
    "    new_rc_params = {'text.usetex': False,\n",
    "                     \"svg.fonttype\": 'none',\n",
    "                     'text.labelsize':'10',\n",
    "                     'facecolor':'#FFFFFF',\n",
    "                     'fontname': 'TeX Gyre Heros'\n",
    "                    }\n",
    "    plot.rc.update(new_rc_params)\n",
    "    plot_data = pd.concat([df_nonIPL[df_nonIPL.QC_Indices_check=='Pass'],df_nonIPL_hs]).dropna(how='any',subset=['TEX86','gdgt23ratio'])\n",
    "    \n",
    "    fig, axs = plot.subplots(ncols=1,nrows=1)\n",
    "    axs.format(\n",
    "        xlabel='xlabel', ylabel='Data Type',\n",
    "        xtickminor=True, xgridminor=True, xgrid=True,\n",
    "    )\n",
    "    \n",
    "    orders = [\"Culture - Hot spring\",\"Culture - ThAOA\",\"Hot spring\",\"Culture - AOA\",\"Shallow SPM\", \"Shallow core top\",\n",
    "              \"Deep SPM\",\"Deep core top\",\"Late Cenozoic\",\"Early Cenozoic\",\"Mesozoic\"]\n",
    "    colors = ['red9',\n",
    "              'red5',\n",
    "              'gold',  #yellow Hot Springs #EDC948\n",
    "              'teal7',\n",
    "              'lime3', #lightgreen Water-column SPM (0-100m)\n",
    "              'blue3',  #light blue Core Top (0-100m)\n",
    "              'lime7', #green Water-column SPM\n",
    "              'blue7',  #blue Core Top\n",
    "              'yellow3',  #light organge Late Cenozoic\n",
    "              'yellow7',  #orange Early Cenozoic\n",
    "              '#B07AA1',  #purple Mesozoic\n",
    "             ]\n",
    "    \n",
    "    yposlist = plot_data.groupby(plot_data.dataType_level3)[['dataType_level3','gdgt23ratio']].median()\n",
    "    yposlist = pd.DataFrame(yposlist, index=orders)\n",
    "    \n",
    "    countlist = plot_data.groupby(plot_data.dataType_level3)[['dataType_level3','gdgt23ratio']].count()\n",
    "    countlist = pd.DataFrame(countlist, index=orders)\n",
    "    \n",
    "    dataType_abc = list(string.ascii_uppercase)\n",
    "    \n",
    "    sns.set_palette(sns.color_palette(colors))\n",
    "    \n",
    "    ax = axs[0]\n",
    "    sns.violinplot(y=\"dataType_level3\", x=\"gdgt23ratio\", data=plot_data, palette=colors,\n",
    "                   order=orders,\n",
    "                   lc='gray5',\n",
    "                   linewidth=1,\n",
    "                   width=0.7,\n",
    "                   showmeans=True,\n",
    "                   trim=True,\n",
    "                   scale='width',\n",
    "                   ax=ax)\n",
    "    \n",
    "    for i in range(len(yposlist)):\n",
    "        group_median='%.2f'%yposlist['gdgt23ratio'][i]\n",
    "        ax.text(yposlist['gdgt23ratio'][i]+6,i-0.08,\n",
    "                f\"{group_median} \"+f\"(n = {countlist.gdgt23ratio[i]})\")\n",
    "        ax.text(28.5,i-0.08,dataType_abc[i],fontweight='bold')\n",
    "        \n",
    "    ax.set_yticklabels([r'$\\it{Crenarchaeota}$ cultures',\n",
    "                        'ThAOA cultures',\n",
    "                        'Hot spring mats',\n",
    "                        'Shallow AOA cultures',\n",
    "                        'Shallow SPM',\n",
    "                        'Shallow core tops',\n",
    "                        'Deep SPM',\n",
    "                        'Deep core tops',\n",
    "                        'Late Cenozoic',\n",
    "                        'Early Cenozoic',\n",
    "                        'Mesozoic'\n",
    "                       ])\n",
    "    ax.format(\n",
    "        abc=False,\n",
    "        xlabel=('GDGT-2/-3'),\n",
    "        xlim = (0,30),\n",
    "        xlocator=5, xminorlocator=1,\n",
    "        xtickloc='bottom',\n",
    "        ylabel='',\n",
    "        ytickminor=False\n",
    "    )\n",
    "    # filepath = \"/content/drive/MyDrive/Colab Notebooks/images/MarineAOA_project/\"\n",
    "    filepath = \"C:\\\\Users\\\\ratta\\\\marine-AOA-GDGT-distribution\\\\figures\\\\main-text\\\\\"\n",
    "    figname = 'fig1_PNAS_violin_plots'\n",
    "    fig.savefig(filepath+figname+'.pdf',dpi=330,bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "id": "tV0PYDkPcXbd",
    "outputId": "d2065d9a-70c0-4f68-c00c-999a057abeb6"
   },
   "outputs": [],
   "source": [
    "fig1_mainText_PNAS_MarineAOA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8Gb5JiveBIT"
   },
   "source": [
    "### Figure 1. Ranges and distributions of GDGT-2/-3 ratios from different archives (top panel)\n",
    "Figure caption\n",
    ">Fig. 1 (Top) Ranges and distributions of GDGT-2/-3 ratios from different archives and (Bottom) structures of common GDGTs found in marine settings. (A) Cultures of thermophilic Crenarchaeota. (B) Cultures of thermophilic AOA strains. (C) Environmental samples from terrestrial hot spring algal mats from sites with pH≥ 6.5. (D) Cultures of known shallow AOA strains. Globally distributed suspended particulate matter (SPM) from (E) above (shallow SPM) and (F) below (deep SPM) the permanent pycnocline. Globally distributed surface (core-top) sediments from sites sitting (G) above (shallow core-tops) and (H) below (deep core tops) the permanent pycnocline. Open marine sediments from different geologic time intervals: (I) the Late Cenozoic (Oligocene-Recent), the Early Cenozoic (Paleocene-Eocene), and the Mesozoic (Early Jurassic-Cretaceous). The median values (white dots), the interquartile range (black bars) of GDGT-2/-3 ratios and the number of observations (n) associated with each group are also reported. Structures of six common GDGTs found in marine settings as discussed in the main text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKZfcTghgbmU"
   },
   "source": [
    "### **4.2.2 Figure 2 in main text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from scipy.stats import mstats\n",
    "m_arr = np.ma.array([1, 1, 0, 0, 0, 0], mask=[0, 0, 1, 1, 1, 0])\n",
    "stats.mode(m_arr)[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_nonIPL' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19800/4284237196.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mselected_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_nonIPL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_nonIPL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQC_Indices_check\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'Pass'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_nonIPL_hs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'any'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TEX86'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'gdgt23ratio'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mselected_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselected_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Function to find distance ## see details from 4.3.1 PTD analysis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcoef_PTD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m0.4242141432\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mintercept_PTD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.1579773469\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_nonIPL' is not defined"
     ]
    }
   ],
   "source": [
    "selected_data = pd.concat([df_nonIPL[df_nonIPL.QC_Indices_check=='Pass'],df_nonIPL_hs]).dropna(how='any',subset=['TEX86','gdgt23ratio'])\n",
    "selected_data = selected_data.reset_index()\n",
    "# Function to find distance ## see details from 4.3.1 PTD analysis \n",
    "coef_PTD = -0.4242141432\n",
    "intercept_PTD = 1.1579773469\n",
    "\n",
    "# Function to find distance \n",
    "a = float(coef_PTD)\n",
    "b = -1\n",
    "c = float(intercept_PTD)\n",
    "array = [[1,2,3,4],\n",
    "         [5,6,7,8],\n",
    "         [9,10,11,0]]\n",
    "fig, axs = plot.subplots(array,share=False,width=6,height=3,wspace='3.5em',hspace='3.5em')\n",
    "\n",
    "selected_data['OrthoDist_from_PTD'] = abs(a*selected_data.gdgt23ratio+(b*selected_data.TEX86)+c)/np.sqrt(a*a+b*b)\n",
    "selected_data\n",
    "\n",
    "grouped = selected_data.groupby('dataType_level3')\n",
    "temp_sktest = []\n",
    "group_name = []\n",
    "kde_lines_x =  []\n",
    "kde_lines_y =  []\n",
    "for i, (name, group) in enumerate(grouped):\n",
    "    \n",
    "    ax = axs[plots_mapping.get(name)]\n",
    "    if name == 'Deep SPM':\n",
    "        sns.kdeplot(group.OrthoDist_from_PTD,ax=ax,shade=True,color=colors_mapping.get(name),alpha=0.3,\n",
    "               common_norm=True)\n",
    "        sns.kdeplot(group.OrthoDist_from_PTD,ax=ax,color='0.3',ls='--',\n",
    "                   common_norm=True)\n",
    "        data2 = group[group.Site_edited!='South China Sea']\n",
    "        \n",
    "        # removed SCS dataset\n",
    "        sns.kdeplot(data2.OrthoDist_from_PTD,ax=ax,shade=True,color=colors_mapping.get(name),alpha=1,\n",
    "                   common_norm=True)\n",
    "        kde = sns.kdeplot(data2.OrthoDist_from_PTD,ax=ax,color='k',\n",
    "                   common_norm=True)\n",
    "    else:\n",
    "        sns.kdeplot(group.OrthoDist_from_PTD,ax=ax,shade=True,color=colors_mapping.get(name),alpha=1,\n",
    "                   common_norm=True)\n",
    "        kde = sns.kdeplot(group.OrthoDist_from_PTD,ax=ax,color='k',\n",
    "                   common_norm=True)\n",
    "    line = kde.lines[0]\n",
    "    x, y = line.get_data()\n",
    "\n",
    "    a = scipy.stats.skew(x)\n",
    "    print(f\"Skewness of {name} is %.2e.\" % a)\n",
    "    temp_sktest.append(a)\n",
    "    group_name.append(name)\n",
    "    kde_lines_x.append(x)\n",
    "    kde_lines_y.append(y)\n",
    "    ax.vlines(1,0,y.max()*1.25,c='k')\n",
    "    ax.format(\n",
    "        abc=True,abcloc='ur',abcstyle=\"A\",\n",
    "        ltitle=names_mapping.get(name),\n",
    "        xlim=(-1,15),\n",
    "        ylim=(0,y.max()*1.25)\n",
    "        # xscale='symlog'\n",
    "    )\n",
    "plot_axes = [0,1,2,3,5,6,7,8,9,10]\n",
    "for i in range(len(plot_axes)):\n",
    "    ax = axs[plot_axes[i]]\n",
    "    ax.format(ylabel='')\n",
    "plot_axes = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "for i in range(len(plot_axes)):\n",
    "    ax = axs[plot_axes[i]]\n",
    "    ax.format(xlabel='')\n",
    "axs[9].text(-5,-0.75,r\"Orthogonal Distance from 'PTD' Trend (dash lines; OD$_{PTD}$)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l2dsHlzdcaPM"
   },
   "outputs": [],
   "source": [
    "def fig2_mainText_PNAS_MarineAOA():\n",
    "    ########## HIGHLIGHT SOUTH CHINA SEA --- DEEP SPM showing PTD trend ##########\n",
    "    plot.rc.update({'text.labelsize':8})\n",
    "    plot.rc.update({'font.size':8})\n",
    "    array= [[1,2,3,4,5,6],[7,8,9,10,11,0],[12,13,14,15,16,17],[18,19,20,21,22,0]]\n",
    "    fig, axs = plot.subplots(array,\n",
    "                              width=6.5,wspace='0.8em',\n",
    "                              hspace=['0.8em','3.3em','0.8em'],hratios=[1,1,0.4,0.4],\n",
    "                              spanx=False,spany=False,sharex=False,sharey=False\n",
    "                            )\n",
    "\n",
    "    selected_data = pd.concat([df_nonIPL[df_nonIPL.QC_Indices_check=='Pass'],df_nonIPL_hs]).dropna(how='any',subset=['TEX86','gdgt23ratio'])\n",
    "    selected_data = selected_data.reset_index()\n",
    "    grouped = selected_data.groupby(selected_data.dataType_level3)\n",
    "\n",
    "\n",
    "    for name, group in grouped:\n",
    "        i = plots_mapping.get(name)\n",
    "        ax = axs[i]\n",
    "        ax.format(lrtitle=f'n = {group.sampleID_new.count()}')\n",
    "\n",
    "        sns.kdeplot(x=group.gdgt23ratio,y=group.TEX86,ax=ax,\n",
    "                    shade=True,thresh=0.05,levels=10,bw_adjust=1,linewidth=0.05,color=colors_mapping.get(name),alpha=0.9,zorder=1)\n",
    "        if ('SPM' in name) | ('core top' in name):\n",
    "            grouped_sites = group.groupby(group.Site_edited)\n",
    "            for name2, group2 in grouped_sites:\n",
    "                if 'South China Sea' in name2:\n",
    "                    ax.scatter(group2.gdgt23ratio,group2.TEX86,marker='.',c='red9',s=0.25,zorder=2)\n",
    "                else:\n",
    "                    ax.scatter(group2.gdgt23ratio,group2.TEX86,marker='.',c='gray9',s=0.25,zorder=2)\n",
    "        else:\n",
    "            ax.scatter(group.gdgt23ratio,group.TEX86,marker='.',c='gray9',s=0.25,zorder=2)\n",
    "        data_count=group.gdgt23ratio.count()\n",
    "\n",
    "        \n",
    "        if 'Culture - Hot spring' in name:\n",
    "\n",
    "            x1, y1 = 3, 0.4\n",
    "            x2, y2 = 12, 0.55\n",
    "            ax.annotate(\"'PTD'\\ntrend\",color='0.5',fontsize=7,weight='bold',linespacing=1,\n",
    "                        xy=(x1, y1), xycoords='data',\n",
    "                        xytext=(x2, y2), textcoords='data',\n",
    "                        arrowprops=dict(arrowstyle=\"fancy\",\n",
    "                                        color=\"0.5\",\n",
    "                                        shrinkB=5,\n",
    "                                        connectionstyle=\"arc3,rad=-0.3\",\n",
    "                                        relpos=(0,0)\n",
    "                                        ),\n",
    "                        )\n",
    "\n",
    "\n",
    "    # Function to find distance ## see details from 4.3.1 PTD analysis \n",
    "    coef_PTD = -0.4242141432\n",
    "    intercept_PTD = 1.1579773469\n",
    "\n",
    "    # Function to find distance \n",
    "    a = float(coef_PTD)\n",
    "    b = -1\n",
    "    c = float(intercept_PTD)\n",
    "\n",
    "    ### Perpendicular distance equation from https://www.nagwa.com/en/explainers/349153496801/\n",
    "\n",
    "    selected_data['OrthoDist_from_PTD'] = abs(a*selected_data.gdgt23ratio+(b*selected_data.TEX86)+c)/np.sqrt(a*a+b*b)\n",
    "\n",
    "    # taken from seaborn's source code (utils.py and distributions.py)\n",
    "    def seaborn_kde_support(data, bw, gridsize, cut, clip):\n",
    "        if clip is None:\n",
    "            clip = (-np.inf, np.inf)\n",
    "        support_min = max(data.min() - bw * cut, clip[0])\n",
    "        support_max = min(data.max() + bw * cut, clip[1])\n",
    "        return np.linspace(support_min, support_max, gridsize)\n",
    "\n",
    "    # https://stackoverflow.com/questions/29661574/normalize-numpy-array-columns-in-python\n",
    "    def normalize(x):\n",
    "        return (x - x.min(0)) / x.ptp(0)\n",
    "\n",
    "    grouped = selected_data.groupby(selected_data.dataType_level3)\n",
    "    \n",
    "    temp_OD_PTD = []\n",
    "    for name, group in grouped:\n",
    "        ax = axs[plots_mapping.get(name)+11]\n",
    "        ax.format(\n",
    "            xlim=(-1, 1000),\n",
    "            xticks=[-1,0,1,10],\n",
    "            xtickrange=(-1,10),\n",
    "            ylim=(0,1.5),\n",
    "            yticks=np.arange(0,1.2,0.5),\n",
    "            xscale='symlog',\n",
    "            xscale_kw={'linthresh': 1},\n",
    "            xtickminor=True\n",
    "        )\n",
    "        data = group.OrthoDist_from_PTD.dropna(how='any')\n",
    "        \n",
    "#         tf_data = np.log10(data+1-min(data))\n",
    "#         if len(tf_data) < 8:\n",
    "#             continue\n",
    "#         else:\n",
    "#             skew_test_score = scipy.stats.skewtest(data)\n",
    "#         skew_score = \"{:.2e}\".format((np.exp(np.std(tf_data)**2)+2)*(np.sqrt((np.exp(np.std(tf_data)**2)-1))))\n",
    "#         skewness_scipy = \"{:.2e}\".format(scipy.stats.skew(data))\n",
    "#         pearson_mode_skewness = (np.mean(tf_data)-scipy.stats.mode(tf_data)[0][0])/np.std(tf_data)\n",
    "        \n",
    "#         print(f\"Log-norm skewness of {name}: {skew_score}\")\n",
    "#         print(f\"Pearson's mode skewness: {pearson_mode_skewness}\")\n",
    "#         # print(f\"Skew test score of {name}: {skew_test_score}\")\n",
    "#         # print(f\"Skewness (scipy) of {name}: {skewness_scipy}\")\n",
    "        \n",
    "        kde_estim = stats.gaussian_kde(data, bw_method='scott')\n",
    "\n",
    "        # or better: mimic seaborn's internal stuff\n",
    "        bw = kde_estim.scotts_factor() * np.std(data)\n",
    "        linearized = seaborn_kde_support(data, bw, 200, 3, None)\n",
    "\n",
    "        # computes values of the estimated function on the estimated linearized inputs\n",
    "        Z = kde_estim.evaluate(linearized)\n",
    "\n",
    "        # normalize so it is between 0;1\n",
    "        Z2 = normalize(Z)\n",
    "\n",
    "        if 'Deep SPM' in name:\n",
    "            ax.plot(linearized, Z2,color='0.3',lw=0.5,ls='--',zorder=3)\n",
    "            ax.fill_between(linearized, Z2,color=colors_mapping.get(name),alpha=0.3,zorder=2)\n",
    "            \n",
    "            data2 = data[group[group.Site_edited!='South China Sea'].index]\n",
    "            \n",
    "#             if len(tf_data) < 8:\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 tf_data2 = np.log10(data2+1-min(data2))\n",
    "#             skew_test_score = scipy.stats.skewtest(data2)\n",
    "#             skew_score = \"{:.2e}\".format((np.exp(np.std(tf_data2)**2)+2)*(np.sqrt((np.exp(np.std(tf_data2)**2)-1))))\n",
    "#             skewness_scipy = \"{:.2e}\".format(scipy.stats.skew(data2))\n",
    "#             pearson_mode_skewness = (np.mean(tf_data2)-scipy.stats.mode(tf_data2)[0][0])/np.std(tf_data2)\n",
    "\n",
    "#             print(f\"Log-norm skewness of {name}: {skew_score}\")\n",
    "#             print(f\"Pearson's mode skewness: {pearson_mode_skewness}\")\n",
    "#             # print(f\"Skew test score of {name}: {skew_test_score}\")\n",
    "#             # print(f\"Skewness (scipy) of {name}: {skewness_scipy}\")\n",
    "            \n",
    "            kde_estim = stats.gaussian_kde(data2, bw_method='scott')\n",
    "\n",
    "            # or better: mimic seaborn's internal stuff\n",
    "            bw = kde_estim.scotts_factor() * np.std(data2)\n",
    "            linearized = seaborn_kde_support(data2, bw, 200, 3, None)\n",
    "\n",
    "            # computes values of the estimated function on the estimated linearized inputs\n",
    "            Z = kde_estim.evaluate(linearized)\n",
    "\n",
    "            # normalize so it is between 0;1\n",
    "            Z2 = normalize(Z)\n",
    "\n",
    "            ax.plot(linearized, Z2,color='k',lw=1,ls='-',zorder=3)\n",
    "            ax.fill_between(linearized, Z2,color=colors_mapping.get(name),alpha=0.7,zorder=2)\n",
    "            temp_OD_PTD.append(data2)\n",
    "\n",
    "        else:\n",
    "            ax.plot(linearized, Z2,color='k',lw=1,ls='-',zorder=3)\n",
    "            ax.fill_between(linearized, Z2,color=colors_mapping.get(name),alpha=0.7,zorder=2)\n",
    "            temp_OD_PTD.append(data)\n",
    "\n",
    "\n",
    "    ############### PLOT ANNOTATION and COSMETIC ###########################################\n",
    "    x2, y2 = 11, 0.65\n",
    "    axs[7].text(x2,y2,\"'Non-thermal'\\nbehavior\",color='0.5',fontsize=6,linespacing=1) \n",
    "\n",
    "\n",
    "    ##### Draw envelop of OD = ############\n",
    "    # Function to find distance ## see details from 4.3.1 PTD analysis \n",
    "    coef_PTD = -0.4242141432\n",
    "    intercept_PTD = 1.1579773469\n",
    "    \n",
    "\n",
    "    theta = np.arctan(float(coef_PTD))\n",
    "    intercept_OD = 1/np.cos(theta)\n",
    "    x1 = 0\n",
    "    y1 = (float(coef_PTD)*x1+(float(intercept_PTD)+intercept_OD))\n",
    "    y2 = 0\n",
    "    x2 = (y2-(float(intercept_PTD)+intercept_OD))/float(coef_PTD)\n",
    "\n",
    "\n",
    "    x3 = 0\n",
    "    y3 = (float(coef_PTD)*x3+(float(intercept_PTD)-intercept_OD))\n",
    "    y4 = 0\n",
    "    x4 = (y4-(float(intercept_PTD)-intercept_OD))/float(coef_PTD)\n",
    "\n",
    "    x_line = np.linspace(0,8,5)\n",
    "    topLine = (float(coef_PTD)*x_line+(float(intercept_PTD)+intercept_OD))\n",
    "    bottomLine = (float(coef_PTD)*x_line+(float(intercept_PTD)-intercept_OD))\n",
    "    midLine = (float(coef_PTD)*x_line+(float(intercept_PTD)))\n",
    "\n",
    "    for i in range(11):\n",
    "        ax = axs[i]\n",
    "        ax.plot([x1,x2],[y1,y2],color='gray5',zorder=0,ls='dotted',lw=1)\n",
    "        ax.plot([x3,x4],[y3,y4],color='gray5',zorder=0,ls='dotted',lw=1)\n",
    "        ax.fill_between(x_line,topLine,bottomLine,alpha=0.8,zorder=0,color='gray2')\n",
    "        ax.plot(x_line,midLine,\n",
    "              zorder=0,color='gray5',ls='--',lw=1)\n",
    "        ax.format(\n",
    "            abc=True,abcstyle='A',abcloc='ur',\n",
    "            xlim=(0,25),\n",
    "            ylim=(0,1),\n",
    "            yticks=np.arange(0,1.2,0.2),\n",
    "            xticks=np.arange(0,25,5),\n",
    "            xlabel='',\n",
    "            ylabel=''\n",
    "        )\n",
    "        ax = axs[i+11]\n",
    "        ax.format(\n",
    "            abc=True,abcstyle='A',abcloc='ur',\n",
    "            ylim=(0,1.5),\n",
    "        )\n",
    "        x_PTD = 0.025\n",
    "        log10zero = np.log10(x_PTD)\n",
    "        ax.vlines(0,0,1.6,ls='--',color='w',zorder=1)\n",
    "        ax.vlines(1,0,1.6,ls='dotted',color='w',zorder=1)\n",
    "        ax.fill_between([0,1],1.6,alpha=0.8,zorder=0,color='gray2')\n",
    "    adj_axs = [1,2,3,4,5,7,8,9,10]\n",
    "    for i in range(len(adj_axs)):\n",
    "        ax = axs[adj_axs[i]]\n",
    "        ax.format(\n",
    "            ylabel='',\n",
    "            yticklabels=[]\n",
    "        )\n",
    "        ax = axs[adj_axs[i]+11]\n",
    "        ax.format(\n",
    "            ylabel='',\n",
    "            yticklabels=[]\n",
    "        )\n",
    "    adj_axs = [0,1,2,3,4]\n",
    "    for i in range(len(adj_axs)):\n",
    "        ax = axs[adj_axs[i]]\n",
    "        ax.format(\n",
    "            xlabel='',\n",
    "            xticklabels=[]\n",
    "        )  \n",
    "        ax = axs[adj_axs[i]+11]\n",
    "        ax.format(\n",
    "            xlabel='',\n",
    "            xticklabels=[]\n",
    "        )\n",
    "\n",
    "\n",
    "    axs[6].text(-11,0.9,r\"TEX$_{86}$\",rotation=90)\n",
    "    axs[8].text(18,-0.35,\"GDGT-2/-3\")\n",
    "    axs[17].text(-150,0,\"Normalized KDE\",rotation=90)\n",
    "    axs[19].text(1000,-1.5,r\"Orthogonal Distance from 'PTD' Trend (dash lines; OD$_{PTD}$)\",ha='center')\n",
    "\n",
    "    x1, y1 = 0.05, 1.2\n",
    "    x2, y2 = 1.0, 0.2\n",
    "    axs[11].annotate(\"No distance\\nfrom PTD\",color='k',fontsize=6,linespacing=1,\n",
    "                xy=(x1, y1), xycoords='data',\n",
    "                xytext=(x2, y2), textcoords='data',\n",
    "                arrowprops=dict(arrowstyle=\"-|>\",\n",
    "                                color=\"k\",\n",
    "                                shrinkB=0,\n",
    "                                connectionstyle=\"angle,angleA=90,angleB=-180,rad=0\",\n",
    "                                shrinkA=0, \n",
    "                                relpos=(0.3,1)\n",
    "                                )\n",
    "                    )\n",
    "\n",
    "    x1, y1 = 1.0, 1.2\n",
    "    x2, y2 = 1.2, 0.2\n",
    "    axs[12].annotate(\"O.D. = 1.0\",color='k',fontsize=6,linespacing=1,\n",
    "                xy=(x1, y1), xycoords='data',\n",
    "                xytext=(x2, y2), textcoords='data',\n",
    "                arrowprops=dict(arrowstyle=\"-|>\",\n",
    "                                color=\"k\",\n",
    "                                shrinkB=0,\n",
    "                                connectionstyle=\"angle,angleA=-90,angleB=180,rad=0\",\n",
    "                                shrinkA=0, \n",
    "                                relpos=(0.3,0)\n",
    "                                )\n",
    "                    )\n",
    "\n",
    "\n",
    "    x1, y1 = 0.1, 0.8\n",
    "    x2, y2 = 0.8,0.2\n",
    "    axs[13].annotate(\"Thermal cluster\\n(following PTD)\",color='k',fontsize=6,linespacing=1,\n",
    "                xy=(x1, y1), xycoords='data',\n",
    "                xytext=(x2, y2), textcoords='data',\n",
    "                arrowprops=dict(arrowstyle=\"-|>\",\n",
    "                                color=\"k\",\n",
    "                                shrinkB=5,\n",
    "                                connectionstyle=\"arc3,rad=0.5\",\n",
    "                                shrinkA=3, \n",
    "                                relpos=(0.4,1)\n",
    "                                )\n",
    "                    )\n",
    "\n",
    "\n",
    "    x1, y1 = 0.9, 0.8\n",
    "    x2, y2 = 2.5, 0.2\n",
    "    axs[18].annotate(\"Non-thermal\\ncluster\",color='k',fontsize=6,linespacing=1,\n",
    "                xy=(x1, y1), xycoords='data',\n",
    "                xytext=(x2, y2), textcoords='data',\n",
    "                arrowprops=dict(arrowstyle=\"-|>\",\n",
    "                                color=\"k\",\n",
    "                                shrinkB=5,\n",
    "                                connectionstyle=\"arc3,rad=0.5\",\n",
    "                                shrinkA=3, \n",
    "                                relpos=(0.4,1)\n",
    "                                )\n",
    "                    )\n",
    "\n",
    "    # filepath = \"/content/drive/MyDrive/Colab Notebooks/images/MarineAOA_project/\"\n",
    "    filepath = \"C:\\\\Users\\\\ratta\\\\marine-AOA-GDGT-distribution\\\\figures\\\\main-text\\\\\"\n",
    "    figname = 'fig2_PNAS_GDGTdistributions'\n",
    "    fig.savefig(filepath+figname+'.png',dpi=330)#,bbox_inches='tight')\n",
    "    plt.show()\n",
    "    return temp_OD_PTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = fig2_mainText_PNAS_MarineAOA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig2_mainText_PNAS_MarineAOA():\n",
    "    ########## HIGHLIGHT SOUTH CHINA SEA --- DEEP SPM showing PTD trend ##########\n",
    "    plot.rc.update({'text.labelsize':8})\n",
    "    plot.rc.update({'font.size':8})\n",
    "    array= [[1,2,3,4,5,6],[7,8,9,10,11,0]]\n",
    "    fig, axs = plot.subplots(array,\n",
    "                              width=6.5,wspace='0.8em',\n",
    "                              hspace=['0.8em'],hratios=[1,1],\n",
    "                              spanx=False,spany=False,sharex=False,sharey=False\n",
    "                            )\n",
    "\n",
    "    selected_data = pd.concat([df_nonIPL[df_nonIPL.QC_Indices_check=='Pass'],df_nonIPL_hs]).dropna(how='any',subset=['TEX86','gdgt23ratio'])\n",
    "    selected_data = selected_data.reset_index()\n",
    "    grouped = selected_data.groupby(selected_data.dataType_level3)\n",
    "\n",
    "\n",
    "    for name, group in grouped:\n",
    "        i = plots_mapping.get(name)\n",
    "        ax = axs[i]\n",
    "        ax.format(lrtitle=f'n = {group.sampleID_new.count()}')\n",
    "\n",
    "        sns.kdeplot(x=group.gdgt23ratio,y=group.TEX86,ax=ax,\n",
    "                    shade=True,thresh=0.05,levels=10,bw_adjust=1,linewidth=0.05,linecolor='0.5',color=colors_mapping.get(name),alpha=0.9,zorder=1)\n",
    "        if ('SPM' in name) | ('core top' in name):\n",
    "            grouped_sites = group.groupby(group.Site_edited)\n",
    "            for name2, group2 in grouped_sites:\n",
    "                if 'South China Sea' in name2:\n",
    "                    ax.scatter(group2.gdgt23ratio,group2.TEX86,marker='.',c='red9',s=0.25,zorder=2)\n",
    "                else:\n",
    "                    ax.scatter(group2.gdgt23ratio,group2.TEX86,marker='.',c='gray9',s=0.25,zorder=2)\n",
    "        else:\n",
    "            ax.scatter(group.gdgt23ratio,group.TEX86,marker='.',c='gray9',s=0.25,zorder=2)\n",
    "        data_count=group.gdgt23ratio.count()\n",
    "\n",
    "        \n",
    "        if 'Culture - Hot spring' in name:\n",
    "\n",
    "            x1, y1 = 1, 0.3\n",
    "            x2, y2 = 6, 0.45\n",
    "            ax.annotate(\"'PTD' trend\\nfrom combined\\ncultured data\\n(2A, 2B, 2D)\",color='k',fontsize=6,linespacing=1,\n",
    "                        xy=(x1, y1), xycoords='data',\n",
    "                        xytext=(x2, y2), textcoords='data',\n",
    "                        arrowprops=dict(arrowstyle=\"-|>\",\n",
    "                                        color=\"k\",\n",
    "                                        shrinkB=5,\n",
    "                                        connectionstyle=\"arc3,rad=-0.3\",\n",
    "                                        relpos=(0,1)\n",
    "                                        ),\n",
    "                        )\n",
    "        elif name == 'Early Cenozoic':\n",
    "            x1, y1 = 12, 0.5\n",
    "            x2, y2 = 3, 0.35\n",
    "            ax.annotate(\"\",color='k', xy=(x1, y1),xytext=(x2, y2),\n",
    "                        arrowprops=dict(arrowstyle=\"-|>\",\n",
    "                                        color=\"k\",\n",
    "                                        shrinkB=5,\n",
    "                                        connectionstyle=\"arc3,rad=-0.3\",\n",
    "                                        relpos=(0,0)\n",
    "                                        ),\n",
    "                       )\n",
    "            x3, y3 = 5, 0.25\n",
    "            ax.text(x3,y3,\"Localized\\n'non-thermal'\",color='k',fontsize=6,linespacing=1) \n",
    "        \n",
    "        elif name == 'Mesozoic':\n",
    "            x1, y1 = 13, 0.65\n",
    "            x2, y2 = 4, 0.5\n",
    "            ax.annotate(\"\",color='k', xy=(x1, y1),xytext=(x2, y2),\n",
    "                        arrowprops=dict(arrowstyle=\"-|>\",\n",
    "                                        color=\"k\",\n",
    "                                        shrinkB=5,\n",
    "                                        connectionstyle=\"arc3,rad=-0.2\",\n",
    "                                        relpos=(0,0)\n",
    "                                        ),\n",
    "                       )\n",
    "            x3, y3 = 7, 0.4\n",
    "            ax.text(x3,y3,\"Localized\\n'non-thermal'\",color='k',fontsize=6,linespacing=1) \n",
    "\n",
    "    # Function to find distance ## see details from 4.3.1 PTD analysis \n",
    "    coef_PTD = -0.4242141432\n",
    "    intercept_PTD = 1.1579773469\n",
    "\n",
    "    # Function to find distance \n",
    "    a = float(coef_PTD)\n",
    "    b = -1\n",
    "    c = float(intercept_PTD)\n",
    "\n",
    "    ### Perpendicular distance equation from https://www.nagwa.com/en/explainers/349153496801/\n",
    "\n",
    "    selected_data['OrthoDist_from_PTD'] = abs(a*selected_data.gdgt23ratio+(b*selected_data.TEX86)+c)/np.sqrt(a*a+b*b)\n",
    "\n",
    "    \n",
    "\n",
    "    ############### PLOT ANNOTATION and COSMETIC ###########################################\n",
    "    x2, y2 = 7, 0.8\n",
    "    axs[7].text(x2,y2,\"'Non-thermal'\\nbehavior\",color='k',fontsize=6,linespacing=1) \n",
    "\n",
    "\n",
    "    ##### Draw envelop of OD = ############\n",
    "    # Function to find distance ## see details from 4.3.1 PTD analysis \n",
    "    coef_PTD = -0.4242141432\n",
    "    intercept_PTD = 1.1579773469\n",
    "    \n",
    "\n",
    "    theta = np.arctan(float(coef_PTD))\n",
    "    intercept_OD = 1/np.cos(theta)\n",
    "    x1 = 0\n",
    "    y1 = (float(coef_PTD)*x1+(float(intercept_PTD)+intercept_OD))\n",
    "    y2 = 0\n",
    "    x2 = (y2-(float(intercept_PTD)+intercept_OD))/float(coef_PTD)\n",
    "\n",
    "\n",
    "    x3 = 0\n",
    "    y3 = (float(coef_PTD)*x3+(float(intercept_PTD)-intercept_OD))\n",
    "    y4 = 0\n",
    "    x4 = (y4-(float(intercept_PTD)-intercept_OD))/float(coef_PTD)\n",
    "\n",
    "    x_line = np.linspace(0,8,5)\n",
    "    topLine = (float(coef_PTD)*x_line+(float(intercept_PTD)+intercept_OD))\n",
    "    bottomLine = (float(coef_PTD)*x_line+(float(intercept_PTD)-intercept_OD))\n",
    "    midLine = (float(coef_PTD)*x_line+(float(intercept_PTD)))\n",
    "\n",
    "    for i in range(11):\n",
    "        ax = axs[i]\n",
    "        ax.plot([x1,x2],[y1,y2],color='gray5',zorder=0,ls='dotted',lw=1)\n",
    "        ax.plot([x3,x4],[y3,y4],color='gray5',zorder=0,ls='dotted',lw=1)\n",
    "        ax.fill_between(x_line,topLine,bottomLine,alpha=0.8,zorder=0,color='gray2')\n",
    "        ax.plot(x_line,midLine,\n",
    "              zorder=0,color='gray5',ls='--',lw=1)\n",
    "        ax.format(\n",
    "            abc=True,abcstyle='A',abcloc='ur',\n",
    "            xlim=(0,25),\n",
    "            ylim=(0,1),\n",
    "            yticks=np.arange(0,1.2,0.2),\n",
    "            xticks=np.arange(0,25,5),\n",
    "            xlabel='',\n",
    "            ylabel=''\n",
    "        )\n",
    "\n",
    "    adj_axs = [1,2,3,4,5,7,8,9,10]\n",
    "    for i in range(len(adj_axs)):\n",
    "        ax = axs[adj_axs[i]]\n",
    "        ax.format(\n",
    "            ylabel='',\n",
    "            yticklabels=[]\n",
    "        )\n",
    "\n",
    "    adj_axs = [0,1,2,3,4]\n",
    "    for i in range(len(adj_axs)):\n",
    "        ax = axs[adj_axs[i]]\n",
    "        ax.format(\n",
    "            xlabel='',\n",
    "            xticklabels=[]\n",
    "        )  \n",
    "\n",
    "\n",
    "    axs[6].text(-11,0.9,r\"TEX$_{86}$\",rotation=90)\n",
    "    axs[8].text(18,-0.35,\"GDGT-2/-3\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # filepath = \"/content/drive/MyDrive/Colab Notebooks/images/MarineAOA_project/\"\n",
    "    filepath = \"C:\\\\Users\\\\ratta\\\\marine-AOA-GDGT-distribution\\\\figures\\\\main-text\\\\\"\n",
    "    figname = 'fig2_PNAS_GDGTdistributions'\n",
    "    fig.savefig(filepath+figname+'.pdf',dpi=330,bbox_inches='tight')\n",
    "    plt.show()\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "id": "abupyha1h2aX",
    "outputId": "8d44bac6-f23a-49bc-ad7c-c2c220fe85b1"
   },
   "outputs": [],
   "source": [
    "a = fig2_mainText_PNAS_MarineAOA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azRALH72oL5L"
   },
   "source": [
    "### Figure 2. Thermal and non-thermal behaviors of isoGDGTs from different archives. \n",
    "Figure caption:\n",
    "> Fig. 2 Thermal and non-thermal behaviors of GDGTs from different archives. (A-K) Scatter plots of GDGT-2/-3 ratios versus TEX86 and (L-V) their normalized KDE of orthogonal distances from the PTD trend (ODPTD). The order and colors of all subplots correspond to Fig. 1. GDGTs derived from (A) Cultures of thermophilic Crenarchaeota, (B) pure cultures of thermophilic AOA, (C) hot spring mats, (D) cultures of shallow-water AOA, (E) shallow SPM, and (F) shallow core-top sediments follow the PTD trend. GDGTs from (G) deep SPM and (H) deep core-top sediments show trends that deviate from the PTD trend. Samples from the (K) Mesozoic and the (J) Early Cenozoic also largely follow the PTD trend, while the (I) Late Cenozoic pattern resembles modern deep sediments and SPM. Red dots in 2E, 2F, 2G and 2H are data from the South China Sea (SCS). Contour plots of joint KDE (shaded, colored regions in A-K) are plotted with a contour interval of 0.1 from the joint density of 0.1 (outer rim) to 0.9 (core). Dashed gray lines in all subplots show the established PTD trend. Shaded gray areas represent ranges of ODPTD that approximately follow ‘thermal’ (0 ≤ ODPTD ≤ 1.0) behaviors. In L-V, normalized KDE values of 1 indicate the highest probability density at the corresponding ODPTD values. The dash-line curve in subplot R shows the normalized KDE when also including the SCS dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3cMTc5sjDRoi",
    "outputId": "e046a568-7bbb-4a64-fcf6-a937b334ae7a"
   },
   "outputs": [],
   "source": [
    "### Regression of combined cultured data (gdgt23ratio on TEX86)\n",
    "# data = df_nonIPL_hs[df_nonIPL_hs.dataType_level3=='Culture - Hot spring'].dropna(how='any',subset=['TEX86','gdgt23ratio'])\n",
    "selected_data = pd.concat([df_nonIPL[df_nonIPL.dataType_level1=='Culture - AOA'][df_nonIPL.QC_Indices_check=='Pass'],df_nonIPL_hs[df_nonIPL_hs.dataType_level0=='Culture']]).dropna(how='any',subset=['TEX86','gdgt23ratio'])\n",
    "data = selected_data.reset_index()\n",
    "\n",
    "X = np.expand_dims(data.TEX86,axis=1)\n",
    "y = np.array(data.gdgt23ratio)\n",
    "\n",
    "import statsmodels.api as sm\n",
    "X2 = sm.add_constant(X)\n",
    "regress_model=sm.OLS(y,X2)\n",
    "result=regress_model.fit()\n",
    "print(result.summary())\n",
    "print(\"P-value: \",result.pvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-V-nRKNgtf1"
   },
   "source": [
    "### **4.2.3 Figure 3 in main text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgJNkV7CoMdL"
   },
   "outputs": [],
   "source": [
    "def fig3_mainText_PNAS_MarineAOA():\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    mpl.rcParams['pdf.fonttype'] = 42\n",
    "    mpl.rcParams['ps.fonttype'] = 42\n",
    "    new_rc_params = {'text.usetex': False,\n",
    "    \"svg.fonttype\": 'none'\n",
    "    }\n",
    "    plot.rc.update({'fontsize': 9,'fontname': 'Tex Gyre Heros','text.labelsize':9,})\n",
    "    pycno_label_name = {\n",
    "        'Shallow SPM':'Shallow',\n",
    "        'Deep SPM':'Deep',\n",
    "        'Shallow core tops':'Shallow',\n",
    "        'Deep core tops':'Deep'\n",
    "    }\n",
    "\n",
    "\n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    array = [\n",
    "        [1,0,5,0,0],\n",
    "        [2,3,4,6,7],\n",
    "        [8,0,12,0,0],\n",
    "        [9,10,11,13,14]\n",
    "\n",
    "    ]\n",
    "\n",
    "    fig, axs = plot.subplots(array,figsize=(12/1.2,4*2/1.2),sharex=False,sharey=False,\n",
    "                             wratios=[1,1,1,0.25,1],hratios=[0.25,1,0.25,1],\n",
    "                             wspace=['5em','1.5em','1.5em','5em'],hspace=['2em','4em','2em'],\n",
    "                            )\n",
    "\n",
    "    selected_data = df_nonIPL[df_nonIPL.QC_Indices_check=='Pass']\n",
    "    selected_data = selected_data[((selected_data.dataType_level1=='Water-column SPM')\n",
    "                          &(selected_data.Site_edited!='South China Sea'))]\n",
    "    selected_data = selected_data.dropna(how='any',subset=['gdgt23ratio','TEX86'])\n",
    "    selected_data = selected_data.reset_index()\n",
    "\n",
    "    # Function to find distance ## see details from 4.3.1 PTD analysis \n",
    "    coef_PTD = -0.4242141432\n",
    "    intercept_PTD = 1.1579773469\n",
    "    \n",
    "    a = float(coef_PTD)\n",
    "    b = -1\n",
    "    c = float(intercept_PTD)\n",
    "    selected_data['OrthoDist_from_PTD'] = abs(a*selected_data.gdgt23ratio+(b*selected_data.TEX86)+c)/np.sqrt(a*a+b*b)\n",
    "\n",
    "    selected_data = selected_data.dropna(how='any',subset=['OrthoDist_from_PTD'])\n",
    "    selected_data = selected_data.reset_index()\n",
    "    selected_data = selected_data.drop(columns=['index'])\n",
    "\n",
    "    features2=['gdgt23ratio','TEX86']\n",
    "    selected_data_unscaled = selected_data[features2]\n",
    "    \n",
    "    n_clusters_plot = [2,2]\n",
    "\n",
    "    from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "    import matplotlib.cm as cm\n",
    "    sns.set_palette('tableau')\n",
    "    plot.rc.cycle = 'tableau'\n",
    "    range_n_clusters = np.arange(1,10,1)\n",
    "    \n",
    "    X = selected_data_unscaled\n",
    "    silhouette_avg=[]\n",
    "    BIC = []\n",
    "\n",
    "    for n_clusters in range_n_clusters:\n",
    "        # Initialize the clusterer with n_clusters value\n",
    "        clusterer = mixture.GaussianMixture(n_components=n_clusters, covariance_type='full',\n",
    "                                            n_init=20,random_state=1).fit(X)\n",
    "        cluster_labels = clusterer.predict(X)\n",
    "\n",
    "        # The silhouette_score gives the average value for all the samples.\n",
    "        # This gives a perspective into the density and separation of the formed clusters\n",
    "        if n_clusters == 1:\n",
    "            sil_avg = np.nan\n",
    "        else:\n",
    "            sil_avg = silhouette_score(X, cluster_labels,metric='mahalanobis')\n",
    "\n",
    "        bic = clusterer.bic(X)\n",
    "        silhouette_avg.append(sil_avg)\n",
    "        BIC.append(bic)\n",
    "\n",
    "        if n_clusters==n_clusters_plot[0]:\n",
    "            cl_weights, cl_means, cl_covars = clusterer.weights_, clusterer.means_, clusterer.covariances_\n",
    "            selected_data['cluster'] = cluster_labels\n",
    "            \n",
    "            ax1 = axs[1]\n",
    "            ax1.format(\n",
    "                abc=True,abcloc='lr',abcstyle='A'\n",
    "            )\n",
    "\n",
    "            # The 1st subplot is the silhouette plot\n",
    "            # The silhouette coefficient can range from -1, 1 \n",
    "            ax1.set_xlim([-0.2, 1])\n",
    "            # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "            # plots of individual clusters, to demarcate them clearly.\n",
    "            ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "            print(\"For n_clusters =\", n_clusters,\n",
    "                  \"The average silhouette_score is :\", np.round(sil_avg,decimals=4))\n",
    "\n",
    "            # Compute the silhouette scores for each sample\n",
    "            sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "            y_lower = 10\n",
    "            for i in range(n_clusters):\n",
    "                # Aggregate the silhouette scores for samples belonging to\n",
    "                # cluster i, and sort them\n",
    "                ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "                ith_cluster_silhouette_values.sort()\n",
    "                ith_cluster_silh_mean = ith_cluster_silhouette_values.mean()\n",
    "\n",
    "                size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "                y_upper = y_lower + size_cluster_i\n",
    "\n",
    "                cmap = plot.Colormap('tableau')\n",
    "                color = cmap(float(i) /10)\n",
    "                ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                                  0, ith_cluster_silhouette_values,\n",
    "                                  facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "                # Label the silhouette plots with their cluster numbers at the middle\n",
    "                ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "                ax1.text(0.8, y_lower + 0.5 * size_cluster_i, str(np.round(ith_cluster_silh_mean,3)))\n",
    "\n",
    "                # Add middle line for each silhouette plot\n",
    "                ax1.axhline(y_lower + (0.5 * size_cluster_i),0.1,color='gray5',ls='--')\n",
    "\n",
    "                # Compute the new y_lower for next plot\n",
    "                y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "            ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "            ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "            # The vertical line for average silhouette score of all the value\n",
    "            ax1.axvline(x=sil_avg, color=\"red\", linestyle=\"--\")\n",
    "            ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "            ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    ######################################################################################################\n",
    "    #### Calculated centers of each cluster on the real dimension\n",
    "        v1_mean = np.array(selected_data['gdgt23ratio'].groupby(selected_data.cluster).mean())\n",
    "        v2_mean = np.array(selected_data['TEX86'].groupby(selected_data.cluster).mean())\n",
    "        v3_mean = np.array(selected_data['OrthoDist_from_PTD'].groupby(selected_data.cluster).mean())\n",
    "        realvalue_centers = np.transpose(np.vstack([v1_mean,v2_mean,v3_mean]))\n",
    "    #######################################################################################################   \n",
    "        ax2 = axs[2]\n",
    "        ax2.format(\n",
    "            abc=True,abcloc='lr',abcstyle='A',\n",
    "        )    \n",
    "        # 2nd Plot showing the actual clusters formed\n",
    "        cmap = plot.Colormap('tableau')\n",
    "        colors = cmap(cluster_labels.astype(float) /10)\n",
    "        ax2.scatter(selected_data['gdgt23ratio'], selected_data.TEX86, marker='.', s=30, lw=0, alpha=0.7,\n",
    "                    c=colors, edgecolor='k')\n",
    "\n",
    "        # Labeling the clusters\n",
    "        centers = realvalue_centers\n",
    "\n",
    "\n",
    "        # Draw white circles at cluster centers\n",
    "        ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "                    c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "\n",
    "        for i, c in enumerate(centers):\n",
    "            ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
    "                        s=50, edgecolor='k')\n",
    "\n",
    "        ax2.set_xlabel(\"GDGT-2/-3\")\n",
    "        ax2.set_ylabel(\"TEX86\")\n",
    "        ax2.format(\n",
    "            ylim=(0,1)\n",
    "        )\n",
    "\n",
    "    ####################################################################################################\n",
    "    #Create a contour plot of sigma with T=0-30, S=32-38. Make sure the axes are labelled.\n",
    "    t_plot = np.arange(-5,31,0.05)\n",
    "    s_plot = np.arange(15,42.01,0.01)\n",
    "    S, T = np.meshgrid(s_plot,t_plot)\n",
    "    sigma_plot=sigmaT_cal_Miller_and_Poisson_1981(T,S)\n",
    "\n",
    "    #SPM column\n",
    "    ax = axs[6]\n",
    "    ax.format(\n",
    "        ultitle=\"C.I. = 1\",\n",
    "        abc=True,\n",
    "        abcstyle='A',\n",
    "        abcloc='lr',\n",
    "        xlim=(30,40),\n",
    "        xticks=np.arange(30,42,2),\n",
    "        xlabel='WOA18_insituS',\n",
    "        ylabel='WOA18_insituT'\n",
    "    )\n",
    "\n",
    "    CS = ax.contourf(s_plot,t_plot,sigma_plot,levels=np.arange(21,31,1), \n",
    "                     labels=False,\n",
    "                     cmap='Deep', \n",
    "                     labels_kw={'weight': 'bold'},\n",
    "                     lw=0.5,\n",
    "                     alpha=0.1,\n",
    "                     zorder=0\n",
    "    )\n",
    "    CS = ax.contour(s_plot,t_plot,sigma_plot,levels=np.arange(26.5,27,0.5), \n",
    "                     labels=False,\n",
    "                     c='darkred',ls='--',\n",
    "                     labels_kw={'weight': 'bold'},\n",
    "                     lw=2,\n",
    "                    zorder=1\n",
    "    ) \n",
    "    x1, y1, x2, y2 = 33,0,30.5,10\n",
    "    ax.annotate(r'$\\sigma_{T}$=26.5',color='0.1',weight='bold',\n",
    "                fontsize=9,\n",
    "                xy=(x1, y1), xycoords='data',\n",
    "                xytext=(x2, y2), textcoords='data',\n",
    "                arrowprops=dict(arrowstyle=\"fancy\",\n",
    "                                color='0',\n",
    "                                shrinkB=5,\n",
    "                                connectionstyle=\"arc3,rad=0.3\",\n",
    "                                relpos=(0.5,0)\n",
    "                               ),\n",
    "           )\n",
    "\n",
    "\n",
    "    ############################################################################################\n",
    "    grouped_cluster = selected_data.groupby(selected_data.cluster)\n",
    "    sns.set_palette('tableau')\n",
    "    for name, group in grouped_cluster:\n",
    "\n",
    "        data2 = group\n",
    "        ax = axs[4]\n",
    "        ax.format(\n",
    "            abc=True,abcloc='lr',abcstyle='A'\n",
    "        )    \n",
    "        ax.hist(data2.gdgt23ratio.values,bins=np.arange(0,30,2),\n",
    "                orientation='vertical',alpha=0.5,histtype='step',lw=1.5,\n",
    "                color=colors_GMM_mapping.get(name)\n",
    "               )\n",
    "\n",
    "        ax.format(\n",
    "            xlim=(0,50),\n",
    "            xticklabels=None,\n",
    "        )\n",
    "        ax.set_xticklabels([])\n",
    "\n",
    "        ax = axs[3]\n",
    "\n",
    "        sns.kdeplot(x=data2.gdgt23ratio,y=data2.TEX86,ax=ax,\n",
    "                    shade=True,thresh=0.05,color=colors_GMM_mapping.get(name),\n",
    "                    levels=np.arange(0.1,1.1,0.1),\n",
    "                    alpha=0.5,lw=0\n",
    "                   )\n",
    "\n",
    "        ax.format(\n",
    "            abc=True,abcloc='lr',abcstyle='A',\n",
    "            yticks=np.arange(0,1.2,0.2),\n",
    "            yticklabels=None,\n",
    "            xreverse=False,\n",
    "            ylim=(0,1),\n",
    "            xlim=(0,50),\n",
    "            xlabel='GDGT-2/-3'\n",
    "        )\n",
    "\n",
    "        ax.grid(True)\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "        ax = axs[5]\n",
    "        ax.format(\n",
    "            abc=True,abcloc='lr',abcstyle='A'\n",
    "        )    \n",
    "        ax.hist(data2.TEX86.values,bins=np.arange(0.1,1.1,0.1),orientation='horizontal',alpha=0.5,histtype='step',lw=1.5,color=colors_GMM_mapping.get(name))\n",
    "        ax.format(\n",
    "            ylabel=None,\n",
    "    #         ylim=(0,1),\n",
    "    #         yticks=np.arange(0,1.2,0.2)\n",
    "        )\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "        ax = axs[6]\n",
    "        ax.scatter(data2.WOA18_decav_insituS,data2.WOA18_decav_insituT,marker='.',alpha=1,zorder=2,color=colors_GMM_mapping.get(name))\n",
    "\n",
    "    ##### Envelop of the pycnocline separation (not GMM clustering)\n",
    "    ax = axs[3]\n",
    "    grouped_pycno = selected_data.groupby(selected_data.dataType_level3)\n",
    "    for name, gr_pycno in grouped_pycno:\n",
    "        x = gr_pycno.gdgt23ratio\n",
    "        y = gr_pycno.TEX86\n",
    "        \n",
    "        if 'Shallow' in pycno_label_name.get(name):\n",
    "            sns.kdeplot(x=x,y=y,shade=False,thresh=0.05,levels=[0.1],ls='--',\n",
    "                        color='k',\n",
    "                        zorder=0,\n",
    "                        ax=ax)\n",
    "\n",
    "            x1, y1, x2, y2 = 5,0.82,8,0.87\n",
    "            ax.annotate('Above Pycnocline\\n(Dash line)',color='0.25',\n",
    "                        fontsize=9,\n",
    "                        xy=(x1, y1), xycoords='data',\n",
    "                        xytext=(x2, y2), textcoords='data',\n",
    "                        arrowprops=dict(arrowstyle=\"fancy\",\n",
    "                                        color='0.25',\n",
    "                                        shrinkB=5,\n",
    "                                        connectionstyle=\"arc3,rad=0.3\",\n",
    "                                        relpos=(0,1)\n",
    "                                       ),\n",
    "                   )\n",
    "        elif 'Deep' in pycno_label_name.get(name):\n",
    "            print(pycno_label_name.get(name))\n",
    "            sns.kdeplot(x,y,shade=False,thresh=0.05,levels=[0.1],ls='dotted',\n",
    "                        color='k',\n",
    "                        zorder=0,\n",
    "                        ax=ax)\n",
    "    #         ax.scatter(x,y,marker='.',s=5,\n",
    "    #                    color='k',\n",
    "    #                   )\n",
    "            x1, y1, x2, y2 = 10,0.4,12,0.1\n",
    "            ax.annotate('Below Pycnocline\\n(Dotted line)',color='0.25',\n",
    "                        fontsize=9,\n",
    "                        xy=(x1, y1), xycoords='data',\n",
    "                        xytext=(x2, y2), textcoords='data',\n",
    "                        arrowprops=dict(arrowstyle=\"fancy\",\n",
    "                                        color='0.25',\n",
    "                                        shrinkB=8,\n",
    "                                        connectionstyle=\"arc3,rad=0.3\",\n",
    "                                        relpos=(0,1)\n",
    "                                       ),\n",
    "                   )\n",
    "\n",
    "    ####################################################################################################### \n",
    "    ##### Plotting Silhouette Scores and BIC curves\n",
    "    ax = axs[0]\n",
    "    ax.plot(range_n_clusters,silhouette_avg,marker='o',color='k',zorder=2)\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(range_n_clusters,BIC,marker='o',ls='--',color='0.5',zorder=1)\n",
    "\n",
    "    ax.format(\n",
    "        xticks=np.arange(1,10,1),\n",
    "        xtickminor=[],\n",
    "        ylabel='SS'\n",
    "    )\n",
    "    ax2.format(\n",
    "        ytickcolor='gray5',\n",
    "        ylabel='BIC'\n",
    "    )\n",
    "\n",
    "\n",
    "    ############################################################################\n",
    "    ############################################################################\n",
    "    ############################################################################\n",
    "    ############################################################################\n",
    "\n",
    "    selected_data_IPL = df_IPL[df_IPL.dataType_level1=='Water-column SPM'][df_IPL.QC_Indices_check=='Pass']\n",
    "    selected_data_IPL = selected_data_IPL.dropna(how='any',subset=['gdgt23ratio','TEX86'])\n",
    "    selected_data_IPL = selected_data_IPL.reset_index()\n",
    "    # Function to find distance ## see details from 4.3.1 PTD analysis \n",
    "    coef_PTD = -0.4242141432\n",
    "    intercept_PTD = 1.1579773469\n",
    "\n",
    "    # Function to find distance \n",
    "    a = float(coef_PTD)\n",
    "    b = -1\n",
    "    c = float(intercept_PTD)\n",
    "    selected_data_IPL['OrthoDist_from_PTD'] = abs(a*selected_data_IPL.gdgt23ratio+(b*selected_data_IPL.TEX86)+c)/np.sqrt(a*a+b*b)\n",
    "    selected_data_IPL = selected_data_IPL.dropna(how='any',subset=['gdgt23ratio','TEX86'])\n",
    "    selected_data_IPL = selected_data_IPL.reset_index()\n",
    "    selected_data_IPL = selected_data_IPL.drop(columns=['index'])\n",
    "\n",
    "    #Pre-processing data\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    features2=['gdgt23ratio','TEX86']\n",
    "    # df4 = scaler.fit_transform(selected_data_IPL[features2])\n",
    "    # selected_data_scaled = pd.DataFrame(df4,columns=features2)\n",
    "\n",
    "    selected_data_unscaled = selected_data_IPL[features2]\n",
    "\n",
    "\n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "    import matplotlib.cm as cm\n",
    "    sns.set_palette('tableau')\n",
    "    plot.rc.cycle = 'tableau'\n",
    "    range_n_clusters = np.arange(1,10,1)\n",
    "    X = selected_data_unscaled\n",
    "    silhouette_avg=[]\n",
    "    BIC = []\n",
    "\n",
    "    for n_clusters in range_n_clusters:\n",
    "        # Initialize the clusterer with n_clusters value and a random generator\n",
    "        # seed of 10 for reproducibility.\n",
    "        clusterer = mixture.GaussianMixture(n_components=n_clusters, covariance_type='full',n_init=20,random_state=1).fit(X)\n",
    "        cluster_labels = clusterer.predict(X)\n",
    "\n",
    "        # The silhouette_score gives the average value for all the samples.\n",
    "        # This gives a perspective into the density and separation of the formed\n",
    "        # clusters\n",
    "        if n_clusters == 1:\n",
    "            sil_avg = np.nan\n",
    "        else:\n",
    "            sil_avg = silhouette_score(X, cluster_labels,metric='mahalanobis')\n",
    "\n",
    "        bic = clusterer.bic(X)\n",
    "        aic = clusterer.aic(X)\n",
    "        silhouette_avg.append(sil_avg)\n",
    "        BIC.append(bic)\n",
    "\n",
    "        if n_clusters==n_clusters_plot[1]:\n",
    "            cl_weights, cl_means, cl_covars = clusterer.weights_, clusterer.means_, clusterer.covariances_\n",
    "            selected_data_IPL['cluster'] = cluster_labels\n",
    "            ax1 = axs[1+7]\n",
    "            ax1.format(\n",
    "                abc=True,abcloc='lr',abcstyle='A'\n",
    "            )\n",
    "\n",
    "            # The 1st subplot is the silhouette plot\n",
    "            # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "            # lie within [-0.1, 1]\n",
    "            ax1.set_xlim([-0.2, 1])\n",
    "            # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "            # plots of individual clusters, to demarcate them clearly.\n",
    "            ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "            print(\"For n_clusters =\", n_clusters,\n",
    "                  \"The average silhouette_score is :\", np.round(sil_avg,decimals=4))\n",
    "\n",
    "            # Compute the silhouette scores for each sample\n",
    "            sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "            y_lower = 10\n",
    "            for i in range(n_clusters):\n",
    "                # Aggregate the silhouette scores for samples belonging to\n",
    "                # cluster i, and sort them\n",
    "                ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "                ith_cluster_silhouette_values.sort()\n",
    "                ith_cluster_silh_mean = ith_cluster_silhouette_values.mean()\n",
    "\n",
    "                size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "                y_upper = y_lower + size_cluster_i\n",
    "\n",
    "                cmap = plot.Colormap('tableau')\n",
    "                color = cmap(float(i)/10)\n",
    "                ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                                  0, ith_cluster_silhouette_values,\n",
    "                                  facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "                # Label the silhouette plots with their cluster numbers at the middle\n",
    "                ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "                ax1.text(0.8, y_lower + 0.5 * size_cluster_i, str(np.round(ith_cluster_silh_mean,3)))\n",
    "\n",
    "                # Add middle line for each silhouette plot\n",
    "                ax1.axhline(y_lower + (0.5 * size_cluster_i),0.1,color='gray5',ls='--')\n",
    "\n",
    "                # Compute the new y_lower for next plot\n",
    "                y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "            ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "            ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "            # The vertical line for average silhouette score of all the values\n",
    "\n",
    "            ax1.axvline(x=sil_avg, color=\"red\", linestyle=\"--\")\n",
    "    #         ax1.format(\n",
    "    #             title='Silhouette average score\\nfor $%d$ clusters = '% n_clusters+str(np.round(silhouette_avg[0],decimals=3),)\n",
    "    #         )\n",
    "\n",
    "            ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "            ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "        ######################################################################################################\n",
    "        #### Calculated centers of each cluster on the real dimension ########################################\n",
    "\n",
    "            v1_mean = np.array(selected_data_IPL['gdgt23ratio'].groupby(selected_data_IPL.cluster).mean())\n",
    "        #     v1_mean = np.array(selected_data_IPL['log10gdgt23ratio'].groupby(selected_data_IPL.cluster).mean())\n",
    "            v2_mean = np.array(selected_data_IPL['TEX86'].groupby(selected_data_IPL.cluster).mean())\n",
    "            v3_mean = np.array(selected_data_IPL['OrthoDist_from_PTD'].groupby(selected_data_IPL.cluster).mean())\n",
    "        # #     v4_mean = np.array(selected_data_IPL['Depth'].groupby(selected_data_IPL.cluster).mean())\n",
    "        #     v4_mean = np.array(selected_data_IPL['log10Depth'].groupby(selected_data_IPL.cluster).mean())\n",
    "            realvalue_centers = np.transpose(np.vstack([v1_mean,v2_mean,v3_mean]))\n",
    "        #######################################################################################################   \n",
    "            ax2 = axs[2+7]\n",
    "            ax2.format(\n",
    "                abc=True,abcloc='lr',abcstyle='A',\n",
    "            )    \n",
    "            # 2nd Plot showing the actual clusters formed\n",
    "        #     colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "            cmap = plot.Colormap('tableau')\n",
    "            colors = cmap(cluster_labels.astype(float) /10)\n",
    "            ax2.scatter(selected_data_IPL['gdgt23ratio'], selected_data_IPL.TEX86, marker='.', s=30, lw=0, alpha=0.7,\n",
    "                        c=colors, edgecolor='k')\n",
    "\n",
    "            # Labeling the clusters\n",
    "        #     centers = clusterer.cluster_centers_\n",
    "            centers = realvalue_centers\n",
    "\n",
    "\n",
    "            # Draw white circles at cluster centers\n",
    "\n",
    "            ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "                        c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "\n",
    "            for i, c in enumerate(centers):\n",
    "                ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
    "                            s=50, edgecolor='k')\n",
    "\n",
    "                ax2.set_xlabel(\"GDGT-2/-3\")\n",
    "                ax2.set_ylabel(\"TEX86\")\n",
    "                ax2.format(\n",
    "                    ylim=(0,1)\n",
    "                )\n",
    "            #########################################################\n",
    "            ########################################################\n",
    "            grouped_cluster = selected_data_IPL.groupby(selected_data_IPL.cluster)\n",
    "            sns.set_palette('tableau')\n",
    "            for name, group in grouped_cluster:\n",
    "\n",
    "                data2 = group\n",
    "                ax = axs[4+7]\n",
    "                ax.format(\n",
    "                    abc=True,abcloc='lr',abcstyle='A'\n",
    "                )    \n",
    "                ax.hist(data2.gdgt23ratio.values,bins=np.arange(0,30,2),\n",
    "                        orientation='vertical',alpha=0.5,histtype='step',lw=1.5,\n",
    "                        color=colors_GMM_mapping.get(name)\n",
    "                       )\n",
    "\n",
    "                ax.format(\n",
    "                    xlim=(0,50),\n",
    "                    xticklabels=None,\n",
    "                )\n",
    "                ax.set_xticklabels([])\n",
    "\n",
    "                ax = axs[3+7]\n",
    "                ax.format(\n",
    "                    abc=True,abcloc='lr',abcstyle='A'\n",
    "                )\n",
    "\n",
    "                sns.kdeplot(data2.gdgt23ratio,data2.TEX86,ax=ax,\n",
    "                            shade=True,thresh=0.05,color=colors_GMM_mapping.get(name),\n",
    "                            levels=np.arange(0.1,1.1,0.1),\n",
    "                            alpha=0.5,lw=0\n",
    "                           )\n",
    "\n",
    "                ax.format(\n",
    "                    yticks=np.arange(0,1.2,0.2),\n",
    "                    yticklabels=None,\n",
    "                    xreverse=False,\n",
    "                    ylim=(0,1),\n",
    "                    xlim=(0,50),\n",
    "                    xlabel='GDGT-2/-3'\n",
    "                )\n",
    "\n",
    "                ax.grid(True)\n",
    "                ax.set_yticklabels([])\n",
    "\n",
    "                ax = axs[5+7]\n",
    "                ax.format(\n",
    "                    abc=True,abcloc='lr',abcstyle='A'\n",
    "                )    \n",
    "                ax.hist(data2.TEX86.values,bins=np.arange(0.1,1.1,0.1),orientation='horizontal',alpha=0.5,histtype='step',lw=1.5,color=colors_GMM_mapping.get(name))\n",
    "                ax.format(\n",
    "                    ylabel=None\n",
    "                )\n",
    "                ax.set_yticklabels([])\n",
    "\n",
    "                ax = axs[6+7]\n",
    "                ax.scatter(data2.WOA18_decav_insituS,data2.WOA18_decav_insituT,marker='.',alpha=1,zorder=2,color=colors_GMM_mapping.get(name))\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    ####################################################################################################\n",
    "    #Create a contour plot of sigma with T=0-30, S=32-38. Make sure the axes are labelled.\n",
    "    t_plot = np.arange(-5,31,0.05)\n",
    "    s_plot = np.arange(15,42.01,0.01)\n",
    "    S, T = np.meshgrid(s_plot,t_plot)\n",
    "    sigma_plot=sigmaT_cal_Miller_and_Poisson_1981(T,S)\n",
    "\n",
    "    #SPM column\n",
    "    ax = axs[6+7]\n",
    "    ax.format(\n",
    "        ultitle=\"C.I. = 1\",\n",
    "        abc=True,\n",
    "        abcstyle='A',\n",
    "        abcloc='lr',\n",
    "        xlim=(30,40),\n",
    "        xticks=np.arange(30,42,2),\n",
    "        xlabel='WOA18_insituS',\n",
    "        ylabel='WOA18_insituT'\n",
    "    )\n",
    "\n",
    "    CS = ax.contourf(s_plot,t_plot,sigma_plot,levels=np.arange(21,31,1), \n",
    "                     labels=False,\n",
    "                     cmap='Deep', \n",
    "                     labels_kw={'weight': 'bold'},\n",
    "                     lw=0.5,\n",
    "                     alpha=0.1,\n",
    "                     zorder=0\n",
    "    )\n",
    "    CS = ax.contour(s_plot,t_plot,sigma_plot,levels=np.arange(26.5,27,0.5), \n",
    "                     labels=False,\n",
    "                     c='darkred',ls='--',\n",
    "                     labels_kw={'weight': 'bold'},\n",
    "                     lw=2,\n",
    "                    zorder=1\n",
    "    ) \n",
    "    x1, y1, x2, y2 = 33,0,30.5,10\n",
    "    ax.annotate(r'$\\sigma_{T}$=26.5',color='0.1',weight='bold',\n",
    "                fontsize=9,\n",
    "                xy=(x1, y1), xycoords='data',\n",
    "                xytext=(x2, y2), textcoords='data',\n",
    "                arrowprops=dict(arrowstyle=\"fancy\",\n",
    "                                color='0',\n",
    "                                shrinkB=5,\n",
    "                                connectionstyle=\"arc3,rad=0.3\",\n",
    "                                relpos=(0.5,0)\n",
    "                               ),\n",
    "           )\n",
    "\n",
    "\n",
    "    # ############################################################################################\n",
    "\n",
    "    ax = axs[3+7]\n",
    "    grouped_pycno = selected_data_IPL.groupby(selected_data_IPL.dataType_level3)\n",
    "    for name, gr_pycno in grouped_pycno:\n",
    "        x = gr_pycno.gdgt23ratio\n",
    "        y = gr_pycno.TEX86\n",
    "        print(name)\n",
    "        if 'Shallow' in pycno_label_name.get(name):\n",
    "            sns.kdeplot(x,y,shade=False,thresh=0.05,levels=[0.1],ls='--',\n",
    "                        color='k',\n",
    "                        zorder=0,\n",
    "                        ax=ax)\n",
    "\n",
    "            x1, y1, x2, y2 = 8,0.82,15,0.87\n",
    "            ax.annotate('Above Pycnocline\\n(Dash line)',color='0.25',\n",
    "                        fontsize=9,\n",
    "                        xy=(x1, y1), xycoords='data',\n",
    "                        xytext=(x2, y2), textcoords='data',\n",
    "                        arrowprops=dict(arrowstyle=\"fancy\",\n",
    "                                        color='0.25',\n",
    "                                        shrinkB=5,\n",
    "                                        connectionstyle=\"arc3,rad=0.3\",\n",
    "                                        relpos=(0,1)\n",
    "                                       ),\n",
    "                       )\n",
    "            \n",
    "        elif 'Deep' in pycno_label_name.get(name):\n",
    "            print(pycno_label_name.get(name))\n",
    "            sns.kdeplot(x,y,shade=False,thresh=0.05,levels=[0.1],ls='dotted',\n",
    "                        color='k',\n",
    "                        zorder=0,\n",
    "                        ax=ax)\n",
    "\n",
    "            x1, y1, x2, y2 = 30,0.4,20,0.1\n",
    "            ax.annotate('Below Pycnocline\\n(Dotted line)',color='0.25',\n",
    "                        fontsize=9,\n",
    "                        xy=(x1, y1), xycoords='data',\n",
    "                        xytext=(x2, y2), textcoords='data',\n",
    "                        arrowprops=dict(arrowstyle=\"fancy\",\n",
    "                                        color='0.25',\n",
    "                                        shrinkB=8,\n",
    "                                        connectionstyle=\"arc3,rad=0.3\",\n",
    "                                        relpos=(0.5,1)\n",
    "                                       ),\n",
    "                   )\n",
    "\n",
    "    \n",
    "    #######################################################################################################   \n",
    "    ax = axs[0+7]\n",
    "    ax.plot(range_n_clusters,silhouette_avg,marker='o',color='k',zorder=2)\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(range_n_clusters,BIC,marker='o',ls='--',color='0.5',zorder=1)\n",
    "\n",
    "    ax.format(\n",
    "        abc=True,abcstyle='A',abcloc='ur',\n",
    "        xticks=np.arange(1,10,1),\n",
    "        xtickminor=[],\n",
    "        ylabel='SS'\n",
    "    )\n",
    "    \n",
    "    ax2.format(\n",
    "        ytickcolor='gray6',\n",
    "        ycolor='gray8',\n",
    "        ylabel='BIC'\n",
    "    )\n",
    "\n",
    "\n",
    "    ##### Draw envelop of OD ############\n",
    "    # Function to find distance ## see details from 4.3.1 PTD analysis \n",
    "    coef_PTD = -0.4242141432\n",
    "    intercept_PTD = 1.1579773469\n",
    "    \n",
    "    theta = np.arctan(float(coef_PTD))\n",
    "    intercept_OD = 1/np.cos(theta)\n",
    "    x1 = 0\n",
    "    y1 = (float(coef_PTD)*x1+(float(intercept_PTD)+intercept_OD))\n",
    "    y2 = 0\n",
    "    x2 = (y2-(float(intercept_PTD)+intercept_OD))/float(coef_PTD)\n",
    "\n",
    "\n",
    "    x3 = 0\n",
    "    y3 = (float(coef_PTD)*x3+(float(intercept_PTD)-intercept_OD))\n",
    "    y4 = 0\n",
    "    x4 = (y4-(float(intercept_PTD)-intercept_OD))/float(coef_PTD)\n",
    "\n",
    "    x_line = np.linspace(0,8,5)\n",
    "    topLine = (float(coef_PTD)*x_line+(float(intercept_PTD)+intercept_OD))\n",
    "    bottomLine = (float(coef_PTD)*x_line+(float(intercept_PTD)-intercept_OD))\n",
    "    PTD_Line = (float(coef_PTD)*x_line+(float(intercept_PTD)))\n",
    "\n",
    "    plot_axes = [2,9]\n",
    "    for i in range(len(plot_axes)):\n",
    "        ax = axs[plot_axes[i]]\n",
    "        ax.fill_between(x_line,topLine,bottomLine,alpha=0.8,zorder=0,color='gray2')\n",
    "        ax.plot(x_line,PTD_Line,\n",
    "             zorder=0,color='gray5',ls='--',lw=1)\n",
    "        ax.format(\n",
    "            xlim=(0,50)\n",
    "        )\n",
    "\n",
    "    plot_axes = [3,4,10,11]\n",
    "    for i in range(len(plot_axes)):\n",
    "        ax = axs[plot_axes[i]]\n",
    "        ax.format(\n",
    "            xlim=(0,50),\n",
    "            xticks=np.arange(0,55,10)\n",
    "        )\n",
    "    plot_axes = [0,7]\n",
    "    for i in range(len(plot_axes)):\n",
    "        ax = axs[plot_axes[i]]\n",
    "        ax.format(\n",
    "            abc=True,abcstyle='A',abcloc='ur'\n",
    "        )\n",
    "    plot_axes = [3,10]\n",
    "    for i in range(len(plot_axes)):\n",
    "        ax = axs[plot_axes[i]]\n",
    "        ax.format(\n",
    "            ylabel=''\n",
    "        )\n",
    "    # filepath = \"/content/drive/MyDrive/Colab Notebooks/images/MarineAOA_project/\"\n",
    "    # filepath = \"C:\\\\Users\\\\ratta\\\\marine-AOA-GDGT-distribution\\\\figures\\\\main-text\\\\\"\n",
    "    # filename = 'fig3_PNAS_SPM_GMM.pdf'\n",
    "    # fig.savefig(filepath+filename,api=330,bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "    return selected_data, selected_data_IPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "FI2wyQj8hEx_",
    "outputId": "8eb28414-73bc-4408-ffd6-76f66fb316aa"
   },
   "outputs": [],
   "source": [
    "##Run fig3_mainText_PNAS_MarineAOA() below first\n",
    "total_GDGT_SPM, IPL_GDGT_SPM = fig3_mainText_PNAS_MarineAOA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-x2HCuDhHYK"
   },
   "source": [
    "### Figure 3. Clustering Analysis of modern SPM based on Gaussian Mixture Model (GMM) clustering algorithm\n",
    "Figure caption:\n",
    "> Fig. 3 Clustering Analysis of modern SPM based on Gaussian Mixture Model (GMM) algorithm. The consensus number of clusters (K) is 2. Subplots (A) to (G) represent the SPM total-GDGTs: (A) Average silhouette scores (SS) based on Mahalanobis Distance and Bayesian Information Criterion (BIC) for K=1 to K=9. (B) Silhouette plots of the two resulting clusters. (C) The distribution pattern of the two clusters resembles the “shallow” and “deep” groups as shown in Fig. 2E and 2G. The PTD trend (ODPTD = 1, grey shaded area) is also plotted. (D) Contour plots of joint KDE for cluster 0 (C0; blue) and cluster 1 (C1; orange) with a contour interval of 0.1, from KDE = 0.1 to 0.9. Histograms showing the distribution of TEX86 (E) and GDGT-2/-3 (F) of each cluster. (G) Density contours (T on p-t-s diagram) suggest C1 and C0 reflect “shallow” (less dense) and “deep” (denser) water masses, respectively. Subplots (H) to (N) represent the SPM IPL-GDGT dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gp1b4DcG-HTJ"
   },
   "source": [
    "### **4.2.4 Figure 4 in main text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rf4QJ2ZAhHFk"
   },
   "outputs": [],
   "source": [
    "def fig4_mainText_PNAS_marineAOA():\n",
    "    rc_params = {\n",
    "        'fontsize': 8,\n",
    "        'fontname': 'Tex Gyre Heros',\n",
    "        'text.labelsize':8,\n",
    "        'axes.labelpad':2\n",
    "    }\n",
    "    plot.rc.update(rc_params)\n",
    "\n",
    "    array = [\n",
    "        [1,1,0,0],\n",
    "        [2,3,4,5],\n",
    "        [6,6,6,6],\n",
    "        [7,7,7,7],\n",
    "        [8,8,8,8]\n",
    "    ]\n",
    "    fig, axs = plot.subplots(array,\n",
    "                            figsize=(7,7),\n",
    "                            hratios=(0.25,1,1,0.25,1),\n",
    "                            wspace=('2em'),hspace=('5em','5em','0em','0em'),\n",
    "                            sharey=False,spany=False,\n",
    "                            sharex=False,spanx=False\n",
    "                            )\n",
    "\n",
    "    paleoData = df_nonIPL[df_nonIPL.dataType_level0=='Ancient'][df_nonIPL.QC_Indices_check=='Pass']#[df_nonIPL.paleoWaterDepth>=1000]\n",
    "\n",
    "   # Function to find distance ## see details from 4.3.1 PTD analysis \n",
    "    coef_PTD = -0.4242141432\n",
    "    intercept_PTD = 1.1579773469\n",
    "\n",
    "    # Function to find distance \n",
    "    a = float(coef_PTD)\n",
    "    b = -1\n",
    "    c = float(intercept_PTD)\n",
    "\n",
    "\n",
    "    paleoData['OrthoDist_from_PTD'] = abs(a*paleoData.gdgt23ratio+(b*paleoData.TEX86)+c)/np.sqrt(a*a+b*b)\n",
    "    selected_data = paleoData.dropna(how='any',subset=['gdgt23ratio','TEX86','sampleAge',\n",
    "                                                        'paleolat','paleolon','paleoWaterDepth',\n",
    "                                                       'OrthoDist_from_PTD',\n",
    "                                                    ])\n",
    "    selected_data = selected_data.reset_index()\n",
    "    selected_data = selected_data.drop(columns=['index'])\n",
    "    #Pre-processing data\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    features2=['gdgt23ratio','TEX86']\n",
    "    df4 = scaler.fit_transform(selected_data[features2])\n",
    "    selected_data_scaled = pd.DataFrame(df4,columns=features2)\n",
    "    selected_data_unscaled = selected_data[features2]\n",
    "\n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn import mixture\n",
    "    from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "    import matplotlib.cm as cm\n",
    "    sns.set_palette('tableau')\n",
    "    plot.rc.cycle = 'tableau'\n",
    "    range_n_clusters = np.arange(1,11,1)\n",
    "    X = selected_data_unscaled\n",
    "    silhouette_avg=[]\n",
    "    BIC=[]\n",
    "\n",
    "    plot_n_clusters = 2\n",
    "\n",
    "    for n_clusters in range_n_clusters:\n",
    "        # Initialize the clusterer with n_clusters value and a random generator\n",
    "        # seed of 10 for reproducibility.\n",
    "    #     clusterer = KMeans(n_clusters=n_clusters, random_state=1)\n",
    "        clusterer = mixture.GaussianMixture(n_components=n_clusters,covariance_type='full',random_state=1,n_init=20).fit(X)\n",
    "        cluster_labels = clusterer.fit_predict(X)\n",
    "        \n",
    "        \n",
    "\n",
    "        # The silhouette_score gives the average value for all the samples.\n",
    "        # This gives a perspective into the density and separation of the formed\n",
    "        # clusters\n",
    "        if n_clusters == 1:\n",
    "            sil_avg = np.nan\n",
    "        else:\n",
    "            sil_avg = silhouette_score(X, cluster_labels,metric='mahalanobis')\n",
    "        silhouette_avg.append(sil_avg)\n",
    "        BIC.append(clusterer.bic(X))\n",
    "        \n",
    "        \n",
    "        if n_clusters==plot_n_clusters:\n",
    "            gmm_weights = clusterer.weights_\n",
    "            gmm_means = clusterer.means_\n",
    "            gmm_covars = clusterer.covariances_\n",
    "            \n",
    "            selected_data['cluster'] = cluster_labels\n",
    "            print(\"For n_clusters =\", n_clusters,\n",
    "                  \"The average silhouette_score is :\", np.round(sil_avg,decimals=4))\n",
    "    \n",
    "\n",
    "        ######################################################################################################\n",
    "        #### Calculated centers of each cluster on the real dimension\n",
    "            v1_mean = np.array(selected_data['gdgt23ratio'].groupby(selected_data.cluster).mean())\n",
    "            v2_mean = np.array(selected_data['TEX86'].groupby(selected_data.cluster).mean())\n",
    "            realvalue_centers = np.transpose(np.vstack([v1_mean,v2_mean]))\n",
    "\n",
    "        ################################################################################################################   \n",
    "            ax2 = axs[1]\n",
    "            ax2.format(\n",
    "                urtitle=f\"k = {n_clusters}\"\n",
    "            )    \n",
    "            # 2nd Plot showing the actual clusters formed\n",
    "        #     colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "            cmap = plot.Colormap('tableau')\n",
    "            colors = cmap(cluster_labels.astype(float) / 10)\n",
    "            ax2.scatter(selected_data['gdgt23ratio'], selected_data.TEX86, marker='.', s=5, lw=0, alpha=0.7,\n",
    "                        c=colors)\n",
    "            \n",
    "\n",
    "            # Labeling the clusters\n",
    "        #     centers = clusterer.cluster_centers_\n",
    "            centers = realvalue_centers\n",
    "\n",
    "\n",
    "            # Draw white circles at cluster centers\n",
    "\n",
    "            ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "                        c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "\n",
    "            for i, c in enumerate(centers):\n",
    "                ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
    "                            s=50, edgecolor='k')\n",
    "\n",
    "    #         ax2.set_title(\"GDGT-2/-3 vs. TEX86\")\n",
    "            ax2.set_xlabel('')\n",
    "            ax2.set_ylabel(r\"$TEX_{86}$\")\n",
    "            ax2.format(\n",
    "                ltitle='GMM of paleo-GDGTs',\n",
    "                ylim=(0,1),\n",
    "                xlim=(0,25),\n",
    "                xticks=np.arange(0,30,5),\n",
    "            )\n",
    "            \n",
    "            \n",
    "            \n",
    "            ### Plotting data into different group\n",
    "            grouped = selected_data.groupby(selected_data.dataType_level3)\n",
    "            plot_axes = {\n",
    "                'Late Cenozoic':2,\n",
    "                'Early Cenozoic':3,\n",
    "                'Mesozoic':4\n",
    "            }\n",
    "            for name, group in grouped:\n",
    "                cmap = plot.Colormap('tableau')\n",
    "                colors2 = cmap(group.cluster.astype(float) / 10)\n",
    "                ax = axs[plot_axes.get(name)]\n",
    "                ax.scatter(group.gdgt23ratio,group.TEX86,color=colors2,marker='.', s=5, lw=0, alpha=0.7,)\n",
    "                ax.format(\n",
    "                    rtitle=name,\n",
    "                    ylim=(0,1),\n",
    "                    xlim=(0,25),\n",
    "                    xticks=np.arange(0,30,5),\n",
    "                    xlabel='',\n",
    "                    ylabel='',\n",
    "                    yticklabels=[]\n",
    "                )\n",
    "                ax.fill_between((15,25),1,0.95,color=colors_mapping.get(name),edgecolor='0.5',alpha=1)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    ###########################################################################\n",
    "    ax = axs[0]\n",
    "    ax.plot(range_n_clusters,silhouette_avg,marker='o',color='k',zorder=2)\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(range_n_clusters,BIC,marker='o',ls='--',color='0.5',zorder=1)\n",
    "    # ax2.plot(range_n_clusters,AIC,marker='o',ls='--',zorder=0)\n",
    "\n",
    "    ax.format(\n",
    "        abc=True,abcstyle='A',abcloc='ur',\n",
    "        xticks=np.arange(1,11,1),\n",
    "        xtickminor=[],\n",
    "        xlabel='Number of clusters (k)',\n",
    "        ylabel='SS',\n",
    "    #     ylim=(0,1)\n",
    "    )\n",
    "    ax2.format(\n",
    "        ytickcolor='gray6',\n",
    "        ycolor='gray8',\n",
    "        ylabel='BIC'\n",
    "    )\n",
    "    ##########################################################################\n",
    "\n",
    "    ##### Draw envelop of OD ############\n",
    "\n",
    "    theta = np.arctan(np.float(coef_PTD))\n",
    "    intercept_OD = 1/np.cos(theta) ### the distance from the OD line is the numerator\n",
    "    x1 = 0\n",
    "    y1 = (np.float(coef_PTD)*x1+(np.float(intercept_OD)+intercept_OD))\n",
    "    y2 = 0\n",
    "    x2 = (y2-(np.float(intercept_OD)+intercept_OD))/np.float(coef_PTD)\n",
    "\n",
    "\n",
    "    x3 = 0\n",
    "    y3 = (np.float(coef_PTD)*x3+(np.float(intercept_OD)-intercept_OD))\n",
    "    y4 = 0\n",
    "    x4 = (y4-(np.float(intercept_OD)-intercept_OD))/np.float(coef_PTD)\n",
    "\n",
    "    x_line = np.linspace(0,8,5)\n",
    "    topLine = (np.float(coef_PTD)*x_line+(np.float(intercept_OD)+intercept_OD))\n",
    "    bottomLine = (np.float(coef_PTD)*x_line+(np.float(intercept_OD)-intercept_OD))\n",
    "    ThCren_Line = (np.float(coef_PTD)*x_line+(np.float(intercept_OD)))\n",
    "\n",
    "    plot_axes = [1,2,3,4]\n",
    "    for i in range(len(plot_axes)):\n",
    "        ax = axs[plot_axes[i]]\n",
    "        ax.fill_between(x_line,topLine,bottomLine,alpha=0.8,zorder=0,color='gray2')\n",
    "        ax.plot(x_line,ThCren_Line,\n",
    "            zorder=0,color='gray5',ls='--',lw=1)\n",
    "        ax.format(\n",
    "            abc=True,abcstyle='A',abcloc='lr',\n",
    "        )\n",
    "    axs[2].text(20,-0.2,'GDGT-2/-3')\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ax = axs[5]\n",
    "\n",
    "    grouped2 = selected_data.groupby(selected_data.cluster)\n",
    "    ii=0\n",
    "    for name2, group2 in grouped2:\n",
    "        ax.scatter(group2.sampleAge,  group2.gdgt23ratio, marker='.', s=5, lw=0, alpha=0.7,\n",
    "                        c=('tableau',ii))\n",
    "        binsize=2\n",
    "        paleoData_rollmean = rollmean_calculation_step(group2,'gdgt23ratio',0,200,binsize)\n",
    "        # ax.step(paleoData_rollmean[:,0],paleoData_rollmean[:,2],color=('tableau',ii),lw=0.5)\n",
    "        ax.fill_between(paleoData_rollmean[:,0],paleoData_rollmean[:,5],paleoData_rollmean[:,6],\n",
    "                        step='post',color=('tableau',ii),\n",
    "                        alpha=0.1)\n",
    "    #     ax.vlines(paleoData_rollmean[:,0]+binsize/2,paleoData_rollmean[:,3],paleoData_rollmean[:,5],color=('tableau',ii))\n",
    "        ax.fill_between(paleoData_rollmean[:,0],paleoData_rollmean[:,3],paleoData_rollmean[:,4],\n",
    "                        step='post',color=('tableau',ii),\n",
    "                        alpha=0.3)\n",
    "        ii += 1\n",
    "    ax.format(\n",
    "        abc=True,abcstyle='A',abcloc='ul',\n",
    "        ylabel='GDGT-2/-3',\n",
    "        ylim=(0,25),\n",
    "        yticks=np.arange(0,21,5),\n",
    "        ytickrange=(0,20),\n",
    "        xlim=(0,200),\n",
    "        xticks=np.arange(0,205,10),\n",
    "        xticklabels=[]\n",
    "    )\n",
    "\n",
    "    ax = axs[6]\n",
    "    sns.kdeplot(data=selected_data,x='sampleAge',hue=\"cluster\",multiple='fill',legend=False,ax=ax)\n",
    "    ax.format(\n",
    "        abc=True,abcstyle='A',abcloc='ul',\n",
    "        ylabel='Density',\n",
    "        xlim=(0,200),\n",
    "        xticks=np.arange(0,205,10),\n",
    "        xticklabels=[]\n",
    "    )\n",
    "\n",
    "    ax = axs[7]\n",
    "    ii=0\n",
    "    for name2, group2 in grouped2:\n",
    "        ax.scatter(group2.sampleAge,  group2.paleoWaterDepth, marker='.', s=5, lw=0, alpha=0.7,\n",
    "                        c=('tableau',ii))\n",
    "        binsize=2\n",
    "        paleoDepth_rollmean = rollmean_calculation_step(group2,'paleoWaterDepth',0,200,binsize)\n",
    "        # ax.step(paleoDepth_rollmean[:,0],paleoDepth_rollmean[:,2],color=('tableau',ii),lw=0.5)\n",
    "        ax.fill_between(paleoDepth_rollmean[:,0],paleoDepth_rollmean[:,5],paleoDepth_rollmean[:,6],\n",
    "                        step='post',color=('tableau',ii),\n",
    "                        alpha=0.1)\n",
    "        # ax.vlines(paleoDepth_rollmean[:,0]+binsize/2,paleoDepth_rollmean[:,3],paleoDepth_rollmean[:,5],color=('tableau',ii))\n",
    "        ax.fill_between(paleoDepth_rollmean[:,0],paleoDepth_rollmean[:,3],paleoDepth_rollmean[:,4],\n",
    "                        step='post',color=('tableau',ii),\n",
    "                        alpha=0.3)\n",
    "        ii += 1\n",
    "    ax.format(\n",
    "        abc=True,abcstyle='A',abcloc='ul',\n",
    "        ylabel='Paleo water depth (mbsl)',\n",
    "        ylim=(-2000,7000),\n",
    "        yticks=np.arange(0,5100,1000),\n",
    "        ytickrange=(0,5000)\n",
    "    )\n",
    "\n",
    "    ldf = gts.data.loc[gts.data.Level == \"Period\", :]\n",
    "    ageName = ldf.Name\n",
    "    ageStart = ldf.Start\n",
    "    ageEnd = ldf.End\n",
    "    ageMean = ldf.MeanAge\n",
    "    ageColor = ldf.Color\n",
    "\n",
    "    for i in range(len(ldf.Name[:5])):\n",
    "\n",
    "        h = 800\n",
    "        w = ageStart[i] - ageEnd[i]\n",
    "        y = 6200\n",
    "        x = ageEnd[i]\n",
    "        xy = (x,y)\n",
    "        \n",
    "        rect = Rectangle(xy,w,h,\n",
    "                        facecolor=ageColor[i],\n",
    "                        edgecolor=\"k\")\n",
    "        ax.add_artist(rect)\n",
    "        if ageName[i] == \"Quaternary\":\n",
    "            continue\n",
    "        else:        \n",
    "            ax.text(ageMean[i]-9,y+(h/1.25),ageName[i],\n",
    "                fontname='TeX Gyre Heros',\n",
    "                rotation=0)\n",
    "\n",
    "    ldf = gts.data.loc[gts.data.Level == \"Epoch\", :]\n",
    "    ageName = ldf.Epoch\n",
    "    ageStart = ldf.Start\n",
    "    ageEnd = ldf.End\n",
    "    ageMean = ldf.MeanAge\n",
    "    ageColor = ldf.Color\n",
    "    eraName = ldf.Era\n",
    "    for i in range(len(ldf.Name[:12])):\n",
    "\n",
    "        h = 800\n",
    "        w = ageStart[i] - ageEnd[i]\n",
    "        y = 5400\n",
    "        x = ageEnd[i]\n",
    "        xy = (x,y)\n",
    "        \n",
    "        rect = Rectangle(xy,w,h,\n",
    "                        facecolor=ageColor[i],\n",
    "                        edgecolor=\"k\")\n",
    "        ax.add_artist(rect)\n",
    "        if eraName[i] == \"Mesozoic\":\n",
    "            if ageName[i] == \"Middle\":\n",
    "                ax.text(ageMean[i]-4,y+(h/1.25),ageName[i][0:3]+'.',fontname='TeX Gyre Heros',\n",
    "                    rotation=0) \n",
    "            elif ageName[i] == \"Lower\":\n",
    "                ax.text(ageMean[i]-4,y+(h/1.25),'Early',fontname='TeX Gyre Heros',\n",
    "                    rotation=0)\n",
    "            elif ageName[i] == \"Upper\":\n",
    "                ax.text(ageMean[i]-4,y+(h/1.25),'Late',fontname='TeX Gyre Heros',\n",
    "                    rotation=0)    \n",
    "            else:\n",
    "                ax.text(ageMean[i]-4,y+(h/1.25),ageName[i],fontname='TeX Gyre Heros',\n",
    "                    rotation=0)\n",
    "        elif ((ageName[i] == \"Pliocene\")|(ageName[i] == \"Pleistocene\")|(ageName[i] == \"Holocene\")):\n",
    "            continue\n",
    "        else:        \n",
    "            ax.text(ageMean[i]-4,y+(h/1.25),ageName[i][0:3]+'.',\n",
    "                fontname='TeX Gyre Heros',\n",
    "                rotation=0)    \n",
    "\n",
    "\n",
    "    ax.format(\n",
    "        abc=True,abcstyle='A',abcloc='ul',\n",
    "        yreverse=True,\n",
    "        xlim=(0,200),\n",
    "        xticks=np.arange(0,205,10),\n",
    "        xtickloc='bottom',\n",
    "        xlabel=\"Age (Million years ago, Ma)\",\n",
    "        ylabel='GDGT-2/-3'\n",
    "    )\n",
    "\n",
    "    plt.show()\n",
    "    # filepath = \"/content/drive/MyDrive/Colab Notebooks/images/MarineAOA_project/\"\n",
    "    # filename = 'fig4_PNAS_GDGT_GMM_overTime.png'\n",
    "    # fig.savefig(filepath+filename,api=330)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 734
    },
    "id": "sfEW04_D-ToU",
    "outputId": "4840eef7-9e84-4da9-ef04-411d4d2d7d83"
   },
   "outputs": [],
   "source": [
    "fig4_mainText_PNAS_marineAOA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KNjIO_K6YxrQ"
   },
   "source": [
    "### Figure 4. Clustering Analysis of paleo lipid biomarkers and the evolution of recognized clusters over the past 192 million years\n",
    "Figure caption:\n",
    "> Fig. 4. Clustering Analysis of paleo lipid biomarkers and the evolution of recognized clusters over the past 192 million years. (A) MD-based SS and BIC plots show that the optimal number of clusters (K) is 2; the strongest improvement of BIC and the highest SS. (B) The GMM clustering results where K=2. Cluster 1 (orange, C1) exhibits ‘thermal’ behavior pattern while Cluster 0 (blue, C0) shows ‘non-thermal’ behavior pattern deviating from the established PTD trend based on combined cultured datasets (dash line). Scatter plots of resulting clusters during each geologic time interval including (C) late Cenozoic, (D) early Cenozoic, and (E) Mesozoic show changes in distribution patterns over time. (F) Evolution of GDGT-2/-3 over geologic time scale for C0 and C1 with 2-myr binned values including medians (middle lines), interquartile range (darker shaded boxes), and min-max range (lighter shaded boxes). (G) Proportion of data density between C0 and C1 based on kernel density estimates. (H) Paleo water depth estimates based on a series of paleogeographic maps from PaleoDEMS project. Note: Labeled major climatic and oceanic anoxic events with relative ice volumes are modified from Westerhold et al. (2021) and Grossman & Joachimski (2020)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gl7Ik8WXnz4Z"
   },
   "source": [
    "## **4.3 Supplementary figures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fLiNvbhLJ5bC",
    "outputId": "7357e492-b273-427f-e9c9-82f7505cb9d9"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VKPDbTHGts5w"
   },
   "source": [
    "### **4.3.1 Figure S1 - Presumed Temperature Dependent (PTD) trend establishment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "4dDWbuwutsJb",
    "outputId": "b4b4c033-b903-47ad-c8b3-39ccde758514"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',4,'display.max_columns',10)\n",
    "frames = [df_nonIPL[df_nonIPL.dataType_level1 == 'Culture - AOA'][df_nonIPL.QC_Indices_check=='Pass'],df_nonIPL_hs]\n",
    "sel_PTD = pd.concat(frames)\n",
    "sel_PTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YhPTa8S1VOpm",
    "outputId": "9144b8c0-bf9c-4718-b9fc-0324c961af77"
   },
   "outputs": [],
   "source": [
    "df_nonIPL_hs.dataType_level0.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29CFuBKDvR26",
    "outputId": "f3916e15-5e67-45fd-e0ba-0ae7c2c2b27c"
   },
   "outputs": [],
   "source": [
    "np.divide(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "s67kEiuqEH1J",
    "outputId": "ceb84eb8-1d3d-42ad-8cc8-06c05b0a7449"
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "array = [[1,2,5,5],\n",
    "         [3,4,5,5]]\n",
    "\n",
    "fig, axs = plot.subplots(array,width=7)\n",
    "axs.format(abc=True,abcstyle='A',abcloc='lr',\n",
    "           suptitle='Linear regressions comparison for establishing PTD trend',\n",
    "           xlim=(0,25),ylim=(0,1),\n",
    "           xticks=np.arange(0,26,5),\n",
    "           xlabel='GDGT-2/-3',\n",
    "           ylabel='TEX$_{86}$'\n",
    "           )\n",
    "selected_data = pd.concat([df_nonIPL[df_nonIPL.dataType_level1=='Culture - AOA'][df_nonIPL.QC_Indices_check=='Pass'],df_nonIPL_hs[df_nonIPL_hs.dataType_level0=='Culture']])\n",
    "selected_data = selected_data.reset_index()\n",
    "grouped = selected_data.groupby(selected_data.dataType_level3)\n",
    "\n",
    "\n",
    "for name, group in grouped:\n",
    "    i = plots_mapping.get(name)\n",
    "    if 'Culture - AOA' in name:\n",
    "        i = i-1\n",
    "    ax = axs[i]\n",
    "    ax.format(\n",
    "        urtitle=name\n",
    "    )\n",
    "\n",
    "    sns.kdeplot(x=group.gdgt23ratio,y=group.TEX86,ax=ax,\n",
    "                shade=True,thresh=0.05,levels=10,bw_adjust=1,linewidth=0,color=colors_mapping.get(name),alpha=0.7,zorder=0)\n",
    "    # if ('SPM' in name) | ('core top' in name):\n",
    "    #     grouped_sites = group.groupby(group.Site_edited)\n",
    "    #     for name2, group2 in grouped_sites:\n",
    "    #         if 'South China Sea' in name2:\n",
    "    #             ax.scatter(group2.gdgt23ratio,group2.TEX86,marker='.',c='red9',s=0.25,zorder=2)\n",
    "    #         else:\n",
    "    #             ax.scatter(group2.gdgt23ratio,group2.TEX86,marker='.',c='gray9',s=0.25,zorder=2)\n",
    "    # else:\n",
    "    #     ax.scatter(group.gdgt23ratio,group.TEX86,marker='.',c='gray9',s=0.25,zorder=2)\n",
    "    data_count=group.gdgt23ratio.count()\n",
    "    data = group[['gdgt23ratio','TEX86']].dropna(how='any')\n",
    "    Y = np.expand_dims(data.TEX86,axis=1)\n",
    "    x = np.array(data.gdgt23ratio)\n",
    "    \n",
    "    X2 = sm.add_constant(Y)\n",
    "    regress_model=sm.OLS(x,X2)\n",
    "    result=regress_model.fit()\n",
    "    print(result.summary())\n",
    "    print(\"P-value: \",result.pvalues)\n",
    "\n",
    "    # reg = linear_model.RANSACRegressor(random_state=0)\n",
    "    # reg = linear_model.TheilSenRegressor(random_state=0)\n",
    "    # reg = linear_model.HuberRegressor()\n",
    "    reg = linear_model.LinearRegression()\n",
    "    reg.fit(Y,x)\n",
    "    line_Y = np.arange(Y.min(),Y.max())[:, np.newaxis]\n",
    "    line_x = reg.predict(line_Y)\n",
    "    ax.plot(line_x,np.squeeze(line_Y),zorder=0,color='red')\n",
    "\n",
    "    line_Y_extended = np.arange(0,1.1,0.1)[:, np.newaxis]\n",
    "    line_x_extended = reg.predict(line_Y_extended)\n",
    "    ax.plot(line_x_extended,np.squeeze(line_Y_extended),zorder=0,color='gray7',ls=':',lw=1)\n",
    "\n",
    "    if 'RANSAC' in str(type(reg)):\n",
    "        inlier_mask = reg.inlier_mask_\n",
    "        outlier_mask = np.logical_not(inlier_mask)\n",
    "        ax.scatter(x[inlier_mask],Y[inlier_mask],marker='.',color='k')\n",
    "        ax.scatter(x[outlier_mask],Y[outlier_mask],marker='.',color='r')\n",
    "      \n",
    "        reg = linear_model.LinearRegression()\n",
    "        reg.fit(Y[inlier_mask],x[inlier_mask])\n",
    "        score = np.round(reg.score(Y[inlier_mask],x[inlier_mask]),3)\n",
    "        coef_ThCren_round = np.round(float(reg.coef_),10)\n",
    "        intercept_ThCren = np.round(float(reg.intercept_),10)\n",
    "    else:\n",
    "        ax.scatter(x,Y,marker='.',color='k')\n",
    "        score = np.round(reg.score(Y,x),3)\n",
    "        coef_ThCren_round = np.round(float(reg.coef_),10)\n",
    "        intercept_ThCren = np.round(float(reg.intercept_),10)\n",
    "    \n",
    "    coef_inv = np.round(1/coef_ThCren_round,3)\n",
    "    intercept_ThCren_round = np.round(intercept_ThCren,10)\n",
    "    new_intercept = np.round((-intercept_ThCren_round/coef_ThCren_round),3)\n",
    "    ax.text(5,0.65,f'y = {coef_inv}x+{new_intercept}',c=\"0.5\",fontsize=8)\n",
    "    ax.text(7,0.55,r\"$r^{2}$ = \"+f'{score}',c=\"0.5\",fontsize=8)\n",
    "\n",
    "    if 'Culture - Hot spring' in name:\n",
    "        X = np.expand_dims(data.gdgt23ratio,axis=1)\n",
    "        y = np.array(data.TEX86)\n",
    "\n",
    "        reg = linear_model.LinearRegression()\n",
    "        reg.fit(X,y)\n",
    "\n",
    "        line_X = np.arange(0,25)[:,np.newaxis]\n",
    "        line_y = reg.predict(line_X)\n",
    "        ax.plot(np.squeeze(line_X),line_y,color=colors_mapping.get(name),ls='-',lw=1,zorder=1)\n",
    "        axs[4].plot(np.squeeze(line_X),line_y,color=colors_mapping.get(name),ls='-',lw=1,zorder=1)\n",
    "\n",
    "        coef_inv = np.round(reg.coef_,3)\n",
    "        new_intercept = np.round(reg.intercept_,3)\n",
    "        ax.text(6,0.45,f'y = {coef_inv[0]}x+{new_intercept}',c=\"k\",fontsize=8)\n",
    "        ax.text(8,0.35,r\"$r^{2}$ = \"+f'{score}',c=\"k\",fontsize=8)\n",
    "\n",
    "    \n",
    "    ax = axs[4]\n",
    "    ax.plot(line_x_extended,np.squeeze(line_Y_extended),zorder=0,color=colors_mapping.get(name),ls='--',lw=1)\n",
    "\n",
    "    \n",
    "\n",
    "ax = axs[3]\n",
    "ax.format(\n",
    "    urtitle='Combined cultured data'\n",
    ")\n",
    "data = selected_data[['gdgt23ratio','TEX86']].dropna(how='any')\n",
    "Y = np.expand_dims(data.TEX86,axis=1)\n",
    "x = np.array(data.gdgt23ratio)\n",
    "\n",
    "X2 = sm.add_constant(Y)\n",
    "regress_model=sm.OLS(x,X2)\n",
    "result=regress_model.fit()\n",
    "print(result.summary())\n",
    "print(\"P-value: \",result.pvalues)\n",
    "\n",
    "\n",
    "# reg = linear_model.RANSACRegressor(random_state=1)\n",
    "# reg = linear_model.TheilSenRegressor(random_state=2)\n",
    "# reg = linear_model.HuberRegressor()\n",
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "\n",
    "if 'RANSAC' in str(type(reg)):\n",
    "    line_Y = np.arange(Y.min(),Y.max())[:, np.newaxis]\n",
    "    line_x = reg.predict(line_Y)\n",
    "    ax.plot(line_x,np.squeeze(line_Y),zorder=0,color='red')\n",
    "\n",
    "    line_Y_extended = np.arange(0,1.1,0.1)[:, np.newaxis]\n",
    "    line_x_extended = reg.predict(line_Y_extended)\n",
    "    ax.plot(line_x_extended,np.squeeze(line_Y_extended),zorder=0,color='gray7',ls='--',lw=2)  \n",
    "    inlier_mask = reg.inlier_mask_\n",
    "    outlier_mask = np.logical_not(inlier_mask)\n",
    "    ax.scatter(x[inlier_mask],Y[inlier_mask],marker='.',color='k')\n",
    "    ax.scatter(x[outlier_mask],Y[outlier_mask],marker='.',color='r')\n",
    "\n",
    "    reg = linear_model.LinearRegression()\n",
    "    reg.fit(Y[inlier_mask],x[inlier_mask])\n",
    "    line_Y2 = np.arange(0,1.1,0.1)[:, np.newaxis]\n",
    "    line_x2 = reg.predict(line_Y2)\n",
    "    ax.plot(line_x2,line_Y2)\n",
    "    score = np.round(reg.score(Y[inlier_mask],x[inlier_mask]),3)\n",
    "    coef_ThCren = np.format_float_positional(reg.coef_,sign=True,precision=10)\n",
    "    intercept_ThCren = np.round(float(reg.intercept_),10)\n",
    "else:\n",
    "    reg.fit(Y,x)\n",
    "\n",
    "    line_Y = np.arange(Y.min(),Y.max())[:, np.newaxis]\n",
    "    line_x = reg.predict(line_Y)\n",
    "    # ax.plot(line_x,np.squeeze(line_Y),zorder=0,color='red')\n",
    "\n",
    "    line_Y_extended = np.arange(0,20)[:, np.newaxis]\n",
    "    line_x_extended = reg.predict(line_Y_extended)\n",
    "\n",
    "    ax.plot(line_x_extended,np.squeeze(line_Y_extended),zorder=1,color='gray7',ls='-',lw=2)               \n",
    "    axs[4].plot(line_x_extended,np.squeeze(line_Y_extended),zorder=2,color='k',ls='-',lw=2)            \n",
    "    ax.scatter(x,Y,marker='.',color='k')\n",
    "    score = np.round(reg.score(Y,x),3)\n",
    "    coef_ThCren = np.format_float_positional(reg.coef_,sign=True,precision=10)\n",
    "    intercept_ThCren = np.round(float(reg.intercept_),10)\n",
    "\n",
    "\n",
    "\n",
    "coef_ThCren_round = np.round(float(coef_ThCren),10)\n",
    "coef_inv = np.round(1/coef_ThCren_round,3)\n",
    "intercept_ThCren_round = np.round(intercept_ThCren,10)\n",
    "new_intercept = np.round((-intercept_ThCren_round/coef_ThCren_round),3)\n",
    "ax.text(5,0.65,f'y = {coef_inv}x+{new_intercept}',c=\"k\",fontsize=8)\n",
    "ax.text(7,0.55,r\"$r^{2}$ = \"+f'{score}',c=\"k\",fontsize=8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "axs.format(\n",
    "    xreverse=False\n",
    ")\n",
    "axs[4].format(\n",
    "    xlim=(0,10)\n",
    ")\n",
    "\n",
    "# filepath = \"/content/drive/MyDrive/Colab Notebooks/images/MarineAOA_project/Supplementary_figures/\"\n",
    "# filename = 'figS1_RegressionComparison.pdf'\n",
    "# fig.savefig(filepath+filename,api=330)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figS2_SI_KDE_OD_PTD():\n",
    "    selected_data = pd.concat([df_nonIPL[df_nonIPL.QC_Indices_check=='Pass'],df_nonIPL_hs]).dropna(how='any',subset=['TEX86','gdgt23ratio'])\n",
    "    selected_data = selected_data.reset_index()\n",
    "    # Function to find distance ## see details from 4.3.1 PTD analysis \n",
    "    coef_PTD = -0.4242141432\n",
    "    intercept_PTD = 1.1579773469\n",
    "\n",
    "    # Function to find distance \n",
    "    a = float(coef_PTD)\n",
    "    b = -1\n",
    "    c = float(intercept_PTD)\n",
    "    array = [[1,2,3,4],\n",
    "             [5,6,7,8],\n",
    "             [9,10,11,0]]\n",
    "    fig, axs = plot.subplots(array,share=False,width=6,height=3,wspace='3.5em',hspace='3.5em')\n",
    "\n",
    "    selected_data['OrthoDist_from_PTD'] = abs(a*selected_data.gdgt23ratio+(b*selected_data.TEX86)+c)/np.sqrt(a*a+b*b)\n",
    "    selected_data\n",
    "\n",
    "    grouped = selected_data.groupby('dataType_level3')\n",
    "    temp_sktest = []\n",
    "    group_name = []\n",
    "    kde_lines_x =  []\n",
    "    kde_lines_y =  []\n",
    "    for i, (name, group) in enumerate(grouped):\n",
    "\n",
    "        ax = axs[plots_mapping.get(name)]\n",
    "        if name == 'Deep SPM':\n",
    "            sns.kdeplot(group.OrthoDist_from_PTD,ax=ax,shade=True,color=colors_mapping.get(name),alpha=0.3,\n",
    "                   common_norm=True)\n",
    "            sns.kdeplot(group.OrthoDist_from_PTD,ax=ax,color='0.3',ls='--',\n",
    "                       common_norm=True)\n",
    "            data2 = group[group.Site_edited!='South China Sea']\n",
    "\n",
    "            # removed SCS dataset\n",
    "            sns.kdeplot(data2.OrthoDist_from_PTD,ax=ax,shade=True,color=colors_mapping.get(name),alpha=1,\n",
    "                       common_norm=True)\n",
    "            kde = sns.kdeplot(data2.OrthoDist_from_PTD,ax=ax,color='k',\n",
    "                       common_norm=True)\n",
    "        else:\n",
    "            sns.kdeplot(group.OrthoDist_from_PTD,ax=ax,shade=True,color=colors_mapping.get(name),alpha=1,\n",
    "                       common_norm=True)\n",
    "            kde = sns.kdeplot(group.OrthoDist_from_PTD,ax=ax,color='k',\n",
    "                       common_norm=True)\n",
    "        line = kde.lines[0]\n",
    "        x, y = line.get_data()\n",
    "\n",
    "        a = scipy.stats.skew(x)\n",
    "        print(f\"Skewness of {name} is %.2e.\" % a)\n",
    "        temp_sktest.append(a)\n",
    "        group_name.append(name)\n",
    "        kde_lines_x.append(x)\n",
    "        kde_lines_y.append(y)\n",
    "        ax.vlines(1,0,y.max()*1.25,c='k')\n",
    "        ax.format(\n",
    "            abc=True,abcloc='ur',abcstyle=\"A\",\n",
    "            ltitle=names_mapping.get(name),\n",
    "            xlim=(-1,15),\n",
    "            ylim=(0,y.max()*1.25)\n",
    "            # xscale='symlog'\n",
    "        )\n",
    "    plot_axes = [0,1,2,3,5,6,7,8,9,10]\n",
    "    for i in range(len(plot_axes)):\n",
    "        ax = axs[plot_axes[i]]\n",
    "        ax.format(ylabel='')\n",
    "    plot_axes = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "    for i in range(len(plot_axes)):\n",
    "        ax = axs[plot_axes[i]]\n",
    "        ax.format(xlabel='')\n",
    "    axs[9].text(-8,-1,r\"Orthogonal Distance from 'PTD' Trend (dash lines; OD$_{PTD}$)\",fontsize=10)\n",
    "    \n",
    "    filepath = filepath=\"C:/Users/ratta/marine-AOA-GDGT-distribution/figures/supplementary-figure/\"\n",
    "    filename =  'fig_S2_KDEplots_OD-PTD'\n",
    "    fig.savefig(filepath+filename+'.pdf',api=330,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figS2_SI_KDE_OD_PTD()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dq6nUY9UN4LY"
   },
   "source": [
    "### **4.3.2 Figure S3 - Two-Sample Kolmogorov-Smirnoff Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOwKoww_duuj"
   },
   "source": [
    "**Calculate critical values for the two-sample Kolmogorov-Smirnov test (2-sided)**\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1-v8fS8DCKhD7W0NtIsS5cC_xuvl-33Tt'>\n",
    "\n",
    "\n",
    "\n",
    "Source: https://sparky.rice.edu//astr360/kstest.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_8X2Kc-qhYJz",
    "outputId": "eb2ad810-4bef-477c-904f-0282bdeb3658"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "features = ['gdgt23ratio','TEX86']\n",
    "a = total_GDGT_SPM[total_GDGT_SPM.dataType_level3=='Shallow SPM'][features]\n",
    "a['new_labels'] = 'Shallow-SPM-totalGDGTs'\n",
    "\n",
    "b = total_GDGT_SPM[total_GDGT_SPM.dataType_level3=='Deep SPM'][features]\n",
    "b['new_labels'] = 'Deep-SPM-totalGDGTs'\n",
    "\n",
    "c = total_GDGT_SPM[total_GDGT_SPM.cluster==0][features]\n",
    "c['new_labels'] = 'C0-totalGDGTs'\n",
    "\n",
    "d = total_GDGT_SPM[total_GDGT_SPM.cluster==1][features]\n",
    "d['new_labels'] = 'C1-totalGDGTs'\n",
    "\n",
    "frames1 = [a,b,c,d]\n",
    "\n",
    "total_SPM_df = pd.concat(frames1)\n",
    "\n",
    "\n",
    "grouped_totalGDGT = total_SPM_df.groupby('new_labels')\n",
    "\n",
    "ks_score_gdgt23ratio = pd.DataFrame(columns=[total_SPM_df.new_labels.unique()],index=[total_SPM_df.new_labels.unique()],dtype=float)\n",
    "p_values_gdgt23ratio = pd.DataFrame(columns=[total_SPM_df.new_labels.unique()],index=[total_SPM_df.new_labels.unique()],dtype=float)\n",
    "ks_score_tex86 = pd.DataFrame(columns=[total_SPM_df.new_labels.unique()],index=[total_SPM_df.new_labels.unique()],dtype=float)\n",
    "p_values_tex86 = pd.DataFrame(columns=[total_SPM_df.new_labels.unique()],index=[total_SPM_df.new_labels.unique()],dtype=float)\n",
    "crit_D_gdgt23ratio = pd.DataFrame(columns=[total_SPM_df.new_labels.unique()],index=[total_SPM_df.new_labels.unique()],dtype=float)\n",
    "crit_D_tex86 = pd.DataFrame(columns=[total_SPM_df.new_labels.unique()],index=[total_SPM_df.new_labels.unique()],dtype=float)\n",
    "ttest_gdgt23ratio = pd.DataFrame(columns=[total_SPM_df.new_labels.unique()],index=[total_SPM_df.new_labels.unique()],dtype=float)\n",
    "ttest_pvalues_gdgt23ratio = pd.DataFrame(columns=[total_SPM_df.new_labels.unique()],index=[total_SPM_df.new_labels.unique()],dtype=float)\n",
    "ttest_tex86 = pd.DataFrame(columns=[total_SPM_df.new_labels.unique()],index=[total_SPM_df.new_labels.unique()],dtype=float)\n",
    "ttest_pvalues_tex86 = pd.DataFrame(columns=[total_SPM_df.new_labels.unique()],index=[total_SPM_df.new_labels.unique()],dtype=float)\n",
    "\n",
    "for i, (name, group) in enumerate(grouped_totalGDGT):\n",
    "    print(name)\n",
    "    for j in range(4):\n",
    "        ks_score1, p_value1 = ks_2samp(group.gdgt23ratio,frames1[j].gdgt23ratio)\n",
    "        \n",
    "        idx = frames1[j].new_labels.unique()[0]\n",
    "        ks_score_gdgt23ratio.at[idx, [name]] = ks_score1\n",
    "        p_values_gdgt23ratio.at[idx, [name]] = p_value1\n",
    "        ttest_gdgt23ratio.at[idx, [name]] = stats.ttest_ind(group.gdgt23ratio,frames1[j].gdgt23ratio,equal_var=False)[0]\n",
    "        ttest_pvalues_gdgt23ratio.at[idx, [name]] = stats.ttest_ind(group.gdgt23ratio,frames1[j].gdgt23ratio,equal_var=False)[1]\n",
    "        \n",
    "        n1 = len(group.gdgt23ratio)\n",
    "        n2 = len(frames1[j].gdgt23ratio)\n",
    "        \n",
    "        crit_D_gdgt23ratio.at[idx, [name]] = 1.36*(np.sqrt(((n1+n2)/(n1*n2))))\n",
    "        \n",
    "        ks_score2, p_value2 = ks_2samp(group.TEX86,frames1[j].TEX86)\n",
    "        idx = frames1[j].new_labels.unique()[0]\n",
    "        ks_score_tex86.at[idx, [name]] = ks_score2\n",
    "        p_values_tex86.at[idx, [name]] = p_value2\n",
    "        ttest_tex86.at[idx, [name]] = stats.ttest_ind(group.TEX86,frames1[j].TEX86,equal_var=False)[0]\n",
    "        ttest_pvalues_tex86.at[idx, [name]] = stats.ttest_ind(group.TEX86,frames1[j].TEX86,equal_var=False)[1]\n",
    "        \n",
    "        n1 = len(group.TEX86)\n",
    "        n2 = len(frames1[j].TEX86)\n",
    "        \n",
    "        crit_D_tex86.at[idx, [name]] = 1.36*(np.sqrt(((n1+n2)/(n1*n2))))\n",
    "\n",
    "##############################################################################################################################\n",
    "##############################################################################################################################\n",
    "e = IPL_GDGT_SPM[IPL_GDGT_SPM.dataType_level3=='Shallow SPM'][features]\n",
    "e['new_labels'] = 'Shallow-SPM-IPL-GDGTs'\n",
    "\n",
    "f = IPL_GDGT_SPM[IPL_GDGT_SPM.dataType_level3=='Deep SPM'][features]\n",
    "f['new_labels'] = 'Deep-SPM-IPL-GDGTs'\n",
    "\n",
    "g = IPL_GDGT_SPM[IPL_GDGT_SPM.cluster==0][features]\n",
    "g['new_labels'] = 'C0-IPL-GDGTs'\n",
    "\n",
    "h = IPL_GDGT_SPM[IPL_GDGT_SPM.cluster==1][features]\n",
    "h['new_labels'] = 'C1-IPL-GDGTs'\n",
    "\n",
    "frames2 = [e,f,g,h]\n",
    "IPL_SPM_df = pd.concat(frames2)\n",
    "grouped_IPL_GDGT = IPL_SPM_df.groupby('new_labels')\n",
    "\n",
    "IPL_ks_score_gdgt23ratio = pd.DataFrame(columns=[IPL_SPM_df.new_labels.unique()],index=[IPL_SPM_df.new_labels.unique()],dtype=float)\n",
    "IPL_p_values_gdgt23ratio = pd.DataFrame(columns=[IPL_SPM_df.new_labels.unique()],index=[IPL_SPM_df.new_labels.unique()],dtype=float)\n",
    "IPL_ks_score_tex86 = pd.DataFrame(columns=[IPL_SPM_df.new_labels.unique()],index=[IPL_SPM_df.new_labels.unique()],dtype=float)\n",
    "IPL_p_values_tex86 = pd.DataFrame(columns=[IPL_SPM_df.new_labels.unique()],index=[IPL_SPM_df.new_labels.unique()],dtype=float)\n",
    "IPL_crit_D_gdgt23ratio = pd.DataFrame(columns=[IPL_SPM_df.new_labels.unique()],index=[IPL_SPM_df.new_labels.unique()],dtype=float)\n",
    "IPL_crit_D_tex86 = pd.DataFrame(columns=[IPL_SPM_df.new_labels.unique()],index=[IPL_SPM_df.new_labels.unique()],dtype=float)\n",
    "IPL_ttest_gdgt23ratio = pd.DataFrame(columns=[IPL_SPM_df.new_labels.unique()],index=[IPL_SPM_df.new_labels.unique()],dtype=float)\n",
    "IPL_ttest_pvalues_gdgt23ratio = pd.DataFrame(columns=[IPL_SPM_df.new_labels.unique()],index=[IPL_SPM_df.new_labels.unique()],dtype=float)\n",
    "IPL_ttest_tex86 = pd.DataFrame(columns=[IPL_SPM_df.new_labels.unique()],index=[IPL_SPM_df.new_labels.unique()],dtype=float)\n",
    "IPL_ttest_pvalues_tex86 = pd.DataFrame(columns=[IPL_SPM_df.new_labels.unique()],index=[IPL_SPM_df.new_labels.unique()],dtype=float)\n",
    "\n",
    "for i, (name, group) in enumerate(grouped_IPL_GDGT):\n",
    "    print(name)\n",
    "    for j in range(4):\n",
    "        ks_score1, p_value1 = ks_2samp(group.gdgt23ratio,frames2[j].gdgt23ratio)\n",
    "        \n",
    "        idx = frames2[j].new_labels.unique()[0]\n",
    "        IPL_ks_score_gdgt23ratio.at[idx, [name]] = ks_score1\n",
    "        IPL_p_values_gdgt23ratio.at[idx, [name]] = p_value1\n",
    "        IPL_ttest_gdgt23ratio.at[idx, [name]] = stats.ttest_ind(group.gdgt23ratio,frames2[j].gdgt23ratio,equal_var=False)[0]\n",
    "        IPL_ttest_pvalues_gdgt23ratio.at[idx, [name]] = stats.ttest_ind(group.gdgt23ratio,frames2[j].gdgt23ratio,equal_var=False)[1]\n",
    "        \n",
    "        n1 = len(group.gdgt23ratio)\n",
    "        n2 = len(frames2[j].gdgt23ratio)\n",
    "        \n",
    "        IPL_crit_D_gdgt23ratio.at[idx, [name]] = 1.36*(np.sqrt(((n1+n2)/(n1*n2))))\n",
    "        \n",
    "        ks_score2, p_value2 = ks_2samp(group.TEX86,frames2[j].TEX86)\n",
    "        idx = frames2[j].new_labels.unique()[0]\n",
    "        IPL_ks_score_tex86.at[idx, [name]] = ks_score2\n",
    "        IPL_p_values_tex86.at[idx, [name]] = p_value2\n",
    "        IPL_ttest_tex86.at[idx, [name]] = stats.ttest_ind(group.TEX86,frames2[j].TEX86,equal_var=False)[0]\n",
    "        IPL_ttest_pvalues_tex86.at[idx, [name]] = stats.ttest_ind(group.TEX86,frames2[j].TEX86,equal_var=False)[1]\n",
    "        \n",
    "        n1 = len(group.TEX86)\n",
    "        n2 = len(frames2[j].TEX86)\n",
    "        \n",
    "        IPL_crit_D_tex86.at[idx, [name]] = 1.36*(np.sqrt(((n1+n2)/(n1*n2))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KS_stats_frames = [ks_score_gdgt23ratio,ks_score_tex86,IPL_ks_score_gdgt23ratio, IPL_ks_score_tex86]\n",
    "KS_pvalues_frames = [p_values_gdgt23ratio,p_values_tex86,IPL_p_values_gdgt23ratio, IPL_p_values_tex86]\n",
    "ttest_stats_frames = [ttest_gdgt23ratio,ttest_tex86,IPL_ttest_gdgt23ratio, IPL_ttest_tex86]\n",
    "ttest_pvalues_stats_frames = [ttest_pvalues_gdgt23ratio,ttest_pvalues_tex86,IPL_ttest_pvalues_gdgt23ratio, IPL_ttest_pvalues_tex86]\n",
    "\n",
    "shallow = total_GDGT_SPM[total_GDGT_SPM.dataType_level3=='Shallow SPM']\n",
    "deep = total_GDGT_SPM[total_GDGT_SPM.dataType_level3=='Deep SPM']\n",
    "c1 = total_GDGT_SPM[total_GDGT_SPM.cluster==1]\n",
    "c0 = total_GDGT_SPM[total_GDGT_SPM.cluster==0]\n",
    "\n",
    "IPL_shallow = IPL_GDGT_SPM[IPL_GDGT_SPM.dataType_level3=='Shallow SPM']\n",
    "IPL_deep = IPL_GDGT_SPM[IPL_GDGT_SPM.dataType_level3=='Deep SPM']\n",
    "IPL_c1 = IPL_GDGT_SPM[IPL_GDGT_SPM.cluster==1]\n",
    "IPL_c0 = IPL_GDGT_SPM[IPL_GDGT_SPM.cluster==0]\n",
    "\n",
    "total_SPM_frames = [shallow, deep, c1, c0]\n",
    "IPL_SPM_frames = [IPL_shallow, IPL_deep, IPL_c1, IPL_c0]\n",
    "color_mappings_frame = ['Shallow SPM','Deep SPM','C0 cluster','C1 cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fmr9W6z6J_t-"
   },
   "outputs": [],
   "source": [
    "def figS3_SI_figure_PNAS_KStest():\n",
    "    from scipy.stats import ks_2samp\n",
    "    labels = ['Shallow\\nSPM','Deep\\nSPM', 'C0', 'C1']\n",
    "    cmap1 = mpl.colors.ListedColormap(['grey5', 'teal9'])\n",
    "    bounds1=[0,0.05,1]\n",
    "    norm1 = mpl.colors.BoundaryNorm(bounds1, cmap1.N)\n",
    "\n",
    "    cmap2 = mpl.colors.ListedColormap(['grey5','cyan9'])\n",
    "    bounds2=[-1,0,1]\n",
    "    norm2 = mpl.colors.BoundaryNorm(bounds2, cmap2.N)\n",
    "\n",
    "\n",
    "    fig, axs = plot.subplots(ncols=3,nrows=4,sharex=False,sharey=False)\n",
    "    axs.format(\n",
    "        suptitle='Cumulative probability density functions and Kolmogorov-Smirnov statistics',\n",
    "        abc=True,abcstyle='A',abcloc='l'\n",
    "    )\n",
    "    plot_axes = [0,3]\n",
    "    for i in range(len(plot_axes)):\n",
    "        ax = axs[plot_axes[i]]\n",
    "        ax.format(\n",
    "            ltitle = 'CDFs of GDGT-2/-3',\n",
    "            xlabel='GDGT-2/-3',\n",
    "            xlim=(-10,60),\n",
    "            xticks=np.arange(0,61,10),\n",
    "            xtickrange=(0,60),\n",
    "        )\n",
    "        for j in range(len(total_SPM_frames)):\n",
    "            n, bins, patches = ax.hist(total_SPM_frames[j].gdgt23ratio,cumulative=True,bins=np.arange(0,60,0.5),density=True,histtype='step',lw=1.5,c=colors_mapping.get(color_mappings_frame[j]),label='Shallow SPM')\n",
    "            patches[0].set_xy(patches[0].get_xy()[:-1]) ### This line is to remove a vertical line of the CDF\n",
    "            \n",
    "    plot_axes = [6,9]\n",
    "    for i in range(len(plot_axes)):\n",
    "        ax = axs[plot_axes[i]]\n",
    "        ax.format(\n",
    "            ltitle = 'CDFs of GDGT-2/-3',\n",
    "            xlabel='GDGT-2/-3',\n",
    "            xlim=(-10,60),\n",
    "            xticks=np.arange(0,61,10),\n",
    "            xtickrange=(0,60),\n",
    "        )\n",
    "        for j in range(len(IPL_SPM_frames)):\n",
    "            n, bins, patches = ax.hist(IPL_SPM_frames[j].gdgt23ratio,cumulative=True,bins=np.arange(0,60,0.5),density=True,histtype='step',lw=1.5,c=colors_mapping.get(color_mappings_frame[j]),label='Shallow SPM')\n",
    "            patches[0].set_xy(patches[0].get_xy()[:-1]) ### This line is to remove a vertical line of the CDF\n",
    "            \n",
    "        \n",
    "    ax = axs[1]\n",
    "    ax.imshow((crit_D_gdgt23ratio - ks_score_gdgt23ratio),cmap=cmap2, norm=norm2)\n",
    "    ax.format(\n",
    "        ltitle=r'Critical D$_{0.05}$ minus D$_{max}$',\n",
    "        xticks = np.arange(len(labels)),\n",
    "        yticks = np.arange(len(labels)),\n",
    "        xticklabels=labels,\n",
    "        yticklabels=labels,\n",
    "        xrotation=45\n",
    "    )\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            text = ax.text(j, i, f'{(crit_D_gdgt23ratio - ks_score_gdgt23ratio).iloc[i, j]:.2}',\n",
    "                          ha=\"center\", va=\"center\", color=\"w\",fontweight='bold')\n",
    "\n",
    "    ax = axs[2]\n",
    "    ax.imshow(p_values_gdgt23ratio,cmap=cmap1, norm=norm1)\n",
    "    ax.format(\n",
    "        ltitle=r'P values',\n",
    "        xticks = np.arange(len(labels)),\n",
    "        yticks = np.arange(len(labels)),\n",
    "        xticklabels=labels,\n",
    "        yticklabels=labels,\n",
    "        xrotation=45\n",
    "    )\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            text = ax.text(j, i, f'{p_values_gdgt23ratio.iloc[i, j]:.1e}',\n",
    "                          ha=\"center\", va=\"center\", color=\"w\",fontweight='bold')\n",
    "\n",
    "\n",
    "    # patches[0].set_xy(patches[0].get_xy()[:-1]) ### This line is to remove a vertical line of the CDF\n",
    "\n",
    "    ax = axs[4]\n",
    "    ax.imshow((crit_D_tex86 - ks_score_tex86),cmap=cmap2, norm=norm2)\n",
    "    ax.format(\n",
    "        ltitle=r'Critical D$_{0.05}$ minus D$_{max}$',\n",
    "        xticks = np.arange(len(labels)),\n",
    "        yticks = np.arange(len(labels)),\n",
    "        xticklabels=labels,\n",
    "        yticklabels=labels,\n",
    "        xrotation=45\n",
    "    )\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            text = ax.text(j, i, f'{(crit_D_tex86 - ks_score_tex86).iloc[i, j]:.2}',\n",
    "                          ha=\"center\", va=\"center\", color=\"w\",fontweight='bold')\n",
    "            \n",
    "    ax = axs[5]\n",
    "    ax.imshow(p_values_tex86,cmap=cmap1, norm=norm1)\n",
    "    ax.format(\n",
    "        ltitle=r'P values',\n",
    "        xticks = np.arange(len(labels)),\n",
    "        yticks = np.arange(len(labels)),\n",
    "        xticklabels=labels,\n",
    "        yticklabels=labels,\n",
    "        xrotation=45\n",
    "    )\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            text = ax.text(j, i, f'{p_values_tex86.iloc[i, j]:.1e}',\n",
    "                          ha=\"center\", va=\"center\", color=\"w\",fontweight='bold')\n",
    "\n",
    "\n",
    "    ax = axs[7]\n",
    "    ax.imshow((IPL_crit_D_gdgt23ratio - IPL_ks_score_gdgt23ratio),cmap=cmap2, norm=norm2)\n",
    "    ax.format(\n",
    "        ltitle=r'Critical D$_{0.05}$ minus D$_{max}$',\n",
    "        xticks = np.arange(len(labels)),\n",
    "        yticks = np.arange(len(labels)),\n",
    "        xticklabels=labels,\n",
    "        yticklabels=labels,\n",
    "        xrotation=45\n",
    "    )\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            text = ax.text(j, i, f'{(IPL_crit_D_gdgt23ratio - IPL_ks_score_gdgt23ratio).iloc[i, j]:.2}',\n",
    "                          ha=\"center\", va=\"center\", color=\"w\",fontweight='bold')\n",
    "\n",
    "    ax = axs[8]\n",
    "    ax.imshow(IPL_p_values_gdgt23ratio,cmap=cmap1, norm=norm1)\n",
    "    ax.format(\n",
    "        ltitle=r'P values',\n",
    "        xticks = np.arange(len(labels)),\n",
    "        yticks = np.arange(len(labels)),\n",
    "        xticklabels=labels,\n",
    "        yticklabels=labels,\n",
    "        xrotation=45\n",
    "    )\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            text = ax.text(j, i, f'{IPL_p_values_gdgt23ratio.iloc[i, j]:.1e}',\n",
    "                          ha=\"center\", va=\"center\", color=\"w\",fontweight='bold')\n",
    "\n",
    "\n",
    "    ax = axs[10]\n",
    "    h = ax.imshow((IPL_crit_D_tex86 - IPL_ks_score_tex86),cmap=cmap2, norm=norm2)\n",
    "    ax.format(\n",
    "        ltitle=r'Critical D$_{0.05}$ minus D$_{max}$',\n",
    "        xticks = np.arange(len(labels)),\n",
    "        yticks = np.arange(len(labels)),\n",
    "        xticklabels=labels,\n",
    "        yticklabels=labels,\n",
    "        xrotation=45\n",
    "    )\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            text = ax.text(j, i, f'{(IPL_crit_D_tex86 - IPL_ks_score_tex86).iloc[i, j]:.2}',\n",
    "                          ha=\"center\", va=\"center\", color=\"w\",fontweight='bold')\n",
    "\n",
    "    ax.colorbar(h,loc='b',ticks=np.arange(-1,1.1,0.25))\n",
    "\n",
    "    ax = axs[11]\n",
    "    h = ax.imshow(IPL_p_values_tex86,cmap=cmap1, norm=norm1)\n",
    "    ax.format(\n",
    "        ltitle=r'P values',\n",
    "        xticks = np.arange(len(labels)),\n",
    "        yticks = np.arange(len(labels)),\n",
    "        xticklabels=labels,\n",
    "        yticklabels=labels,\n",
    "        xrotation=45\n",
    "    )\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            text = ax.text(j, i, f'{IPL_p_values_tex86.iloc[i, j]:.1e}',\n",
    "                          ha=\"center\", va=\"center\", color=\"w\",fontweight='bold')\n",
    "\n",
    "    ax.colorbar(h,loc='b',ticks=[0,0.05,1])\n",
    "\n",
    "    # filepath = '/content/drive/MyDrive/Colab Notebooks/images/MarineAOA_project/Supplementary_figures/'\n",
    "    # filepath = filepath=\"C:/Users/ratta/marine-AOA-GDGT-distribution/figures/supplementary-figure/\"\n",
    "    # filename =  'fig_S2_KS_test_2ways_SPM_GDGT'\n",
    "    # fig.savefig(filepath+filename+'.pdf',api=330,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "S7VNjDDcOPK1",
    "outputId": "798011f3-936f-404a-ba94-79c584c37a08"
   },
   "outputs": [],
   "source": [
    "figS3_SI_figure_PNAS_KStest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ay7JCwKyX1oj"
   },
   "source": [
    "### **4.3.3 Figure S4 - GMM results of SPM datasets with K=3 scenario**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nt066KkfX1JH"
   },
   "outputs": [],
   "source": [
    "def figS4_SI_figure_PNAS_MarineAOA():\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    mpl.rcParams['pdf.fonttype'] = 42\n",
    "    mpl.rcParams['ps.fonttype'] = 42\n",
    "    new_rc_params = {'text.usetex': False,\n",
    "    \"svg.fonttype\": 'none'\n",
    "    }\n",
    "    plot.rc.update({'fontsize': 9,'fontname': 'Tex Gyre Heros','text.labelsize':9,})\n",
    "    pycno_label_name = {\n",
    "        'Shallow SPM':'Shallow',\n",
    "        'Deep SPM':'Deep',\n",
    "        'Shallow core tops':'Shallow',\n",
    "        'Deep core tops':'Deep'\n",
    "    }\n",
    "\n",
    "\n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    array = [\n",
    "        [1,0,5,0,0],\n",
    "        [2,3,4,6,7],\n",
    "        [8,0,12,0,0],\n",
    "        [9,10,11,13,14]\n",
    "\n",
    "    ]\n",
    "\n",
    "    fig, axs = plot.subplots(array,figsize=(12/1.2,4*2/1.2),sharex=False,sharey=False,\n",
    "                             wratios=[1,1,1,0.25,1],hratios=[0.25,1,0.25,1],\n",
    "                             wspace=['5em','1.5em','1.5em','5em'],hspace=['2em','4em','2em'],\n",
    "                            )\n",
    "\n",
    "    selected_data = df_nonIPL[df_nonIPL.QC_Indices_check=='Pass']\n",
    "    selected_data = selected_data[((selected_data.dataType_level1=='Water-column SPM')\n",
    "                          &(selected_data.Site_edited!='South China Sea'))]\n",
    "    selected_data = selected_data.dropna(how='any',subset=['gdgt23ratio','TEX86'])\n",
    "    selected_data = selected_data.reset_index()\n",
    "\n",
    "    # Function to find distance ## see details from 4.3.1 PTD analysis \n",
    "    coef_PTD = -0.4242141432\n",
    "    intercept_PTD = 1.1579773469\n",
    "    \n",
    "    a = float(coef_PTD)\n",
    "    b = -1\n",
    "    c = float(intercept_PTD)\n",
    "    selected_data['OrthoDist_from_PTD'] = abs(a*selected_data.gdgt23ratio+(b*selected_data.TEX86)+c)/np.sqrt(a*a+b*b)\n",
    "\n",
    "    selected_data = selected_data.dropna(how='any',subset=['OrthoDist_from_PTD'])\n",
    "    selected_data = selected_data.reset_index()\n",
    "    selected_data = selected_data.drop(columns=['index'])\n",
    "\n",
    "    features2=['gdgt23ratio','TEX86']\n",
    "    selected_data_unscaled = selected_data[features2]\n",
    "    \n",
    "    n_clusters_plot = [3,3]\n",
    "\n",
    "    from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "    import matplotlib.cm as cm\n",
    "    sns.set_palette('tableau')\n",
    "    plot.rc.cycle = 'tableau'\n",
    "    range_n_clusters = np.arange(1,10,1)\n",
    "    \n",
    "    X = selected_data_unscaled\n",
    "    silhouette_avg=[]\n",
    "    BIC = []\n",
    "\n",
    "    for n_clusters in range_n_clusters:\n",
    "        # Initialize the clusterer with n_clusters value\n",
    "        clusterer = mixture.GaussianMixture(n_components=n_clusters, covariance_type='full',\n",
    "                                            n_init=20,random_state=1).fit(X)\n",
    "        cluster_labels = clusterer.predict(X)\n",
    "\n",
    "        # The silhouette_score gives the average value for all the samples.\n",
    "        # This gives a perspective into the density and separation of the formed clusters\n",
    "        if n_clusters == 1:\n",
    "            sil_avg = np.nan\n",
    "        else:\n",
    "            sil_avg = silhouette_score(X, cluster_labels,metric='mahalanobis')\n",
    "\n",
    "        bic = clusterer.bic(X)\n",
    "        silhouette_avg.append(sil_avg)\n",
    "        BIC.append(bic)\n",
    "\n",
    "        if n_clusters==n_clusters_plot[0]:\n",
    "            cl_weights, cl_means, cl_covars = clusterer.weights_, clusterer.means_, clusterer.covariances_\n",
    "            selected_data['cluster'] = cluster_labels\n",
    "            \n",
    "            ax1 = axs[1]\n",
    "            ax1.format(\n",
    "                abc=True,abcloc='lr',abcstyle='A'\n",
    "            )\n",
    "\n",
    "            # The 1st subplot is the silhouette plot\n",
    "            # The silhouette coefficient can range from -1, 1 \n",
    "            ax1.set_xlim([-0.2, 1])\n",
    "            # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "            # plots of individual clusters, to demarcate them clearly.\n",
    "            ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "            print(\"For n_clusters =\", n_clusters,\n",
    "                  \"The average silhouette_score is :\", np.round(sil_avg,decimals=4))\n",
    "\n",
    "            # Compute the silhouette scores for each sample\n",
    "            sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "            y_lower = 10\n",
    "            for i in range(n_clusters):\n",
    "                # Aggregate the silhouette scores for samples belonging to\n",
    "                # cluster i, and sort them\n",
    "                ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "                ith_cluster_silhouette_values.sort()\n",
    "                ith_cluster_silh_mean = ith_cluster_silhouette_values.mean()\n",
    "\n",
    "                size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "                y_upper = y_lower + size_cluster_i\n",
    "\n",
    "                cmap = plot.Colormap('tableau')\n",
    "                color = cmap(float(i) /10)\n",
    "                ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                                  0, ith_cluster_silhouette_values,\n",
    "                                  facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "                # Label the silhouette plots with their cluster numbers at the middle\n",
    "                ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "                ax1.text(0.8, y_lower + 0.5 * size_cluster_i, str(np.round(ith_cluster_silh_mean,3)))\n",
    "\n",
    "                # Add middle line for each silhouette plot\n",
    "                ax1.axhline(y_lower + (0.5 * size_cluster_i),0.1,color='gray5',ls='--')\n",
    "\n",
    "                # Compute the new y_lower for next plot\n",
    "                y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "            ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "            ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "            # The vertical line for average silhouette score of all the value\n",
    "            ax1.axvline(x=sil_avg, color=\"red\", linestyle=\"--\")\n",
    "            ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "            ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    ######################################################################################################\n",
    "    #### Calculated centers of each cluster on the real dimension\n",
    "        v1_mean = np.array(selected_data['gdgt23ratio'].groupby(selected_data.cluster).mean())\n",
    "        v2_mean = np.array(selected_data['TEX86'].groupby(selected_data.cluster).mean())\n",
    "        v3_mean = np.array(selected_data['OrthoDist_from_PTD'].groupby(selected_data.cluster).mean())\n",
    "        realvalue_centers = np.transpose(np.vstack([v1_mean,v2_mean,v3_mean]))\n",
    "    #######################################################################################################   \n",
    "        ax2 = axs[2]\n",
    "        ax2.format(\n",
    "            abc=True,abcloc='lr',abcstyle='A',\n",
    "        )    \n",
    "        # 2nd Plot showing the actual clusters formed\n",
    "        cmap = plot.Colormap('tableau')\n",
    "        colors = cmap(cluster_labels.astype(float) /10)\n",
    "        ax2.scatter(selected_data['gdgt23ratio'], selected_data.TEX86, marker='.', s=30, lw=0, alpha=0.7,\n",
    "                    c=colors, edgecolor='k')\n",
    "\n",
    "        # Labeling the clusters\n",
    "        centers = realvalue_centers\n",
    "\n",
    "\n",
    "        # Draw white circles at cluster centers\n",
    "        ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "                    c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "\n",
    "        for i, c in enumerate(centers):\n",
    "            ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
    "                        s=50, edgecolor='k')\n",
    "\n",
    "        ax2.set_xlabel(\"GDGT-2/-3\")\n",
    "        ax2.set_ylabel(\"TEX86\")\n",
    "        ax2.format(\n",
    "            ylim=(0,1)\n",
    "        )\n",
    "\n",
    "    ####################################################################################################\n",
    "    #Create a contour plot of sigma with T=0-30, S=32-38. Make sure the axes are labelled.\n",
    "    t_plot = np.arange(-5,31,0.05)\n",
    "    s_plot = np.arange(15,42.01,0.01)\n",
    "    S, T = np.meshgrid(s_plot,t_plot)\n",
    "    sigma_plot=sigmaT_cal_Miller_and_Poisson_1981(T,S)\n",
    "\n",
    "    #SPM column\n",
    "    ax = axs[6]\n",
    "    ax.format(\n",
    "        ultitle=\"C.I. = 1\",\n",
    "        abc=True,\n",
    "        abcstyle='A',\n",
    "        abcloc='lr',\n",
    "        xlim=(30,40),\n",
    "        xticks=np.arange(30,42,2),\n",
    "        xlabel='WOA18_insituS',\n",
    "        ylabel='WOA18_insituT'\n",
    "    )\n",
    "\n",
    "    CS = ax.contourf(s_plot,t_plot,sigma_plot,levels=np.arange(21,31,1), \n",
    "                     labels=False,\n",
    "                     cmap='Deep', \n",
    "                     labels_kw={'weight': 'bold'},\n",
    "                     lw=0.5,\n",
    "                     alpha=0.1,\n",
    "                     zorder=0\n",
    "    )\n",
    "    CS = ax.contour(s_plot,t_plot,sigma_plot,levels=np.arange(26.5,27,0.5), \n",
    "                     labels=False,\n",
    "                     c='darkred',ls='--',\n",
    "                     labels_kw={'weight': 'bold'},\n",
    "                     lw=2,\n",
    "                    zorder=1\n",
    "    ) \n",
    "    x1, y1, x2, y2 = 33,0,30.5,10\n",
    "    ax.annotate(r'$\\sigma_{T}$=26.5',color='0.1',weight='bold',\n",
    "                fontsize=9,\n",
    "                xy=(x1, y1), xycoords='data',\n",
    "                xytext=(x2, y2), textcoords='data',\n",
    "                arrowprops=dict(arrowstyle=\"fancy\",\n",
    "                                color='0',\n",
    "                                shrinkB=5,\n",
    "                                connectionstyle=\"arc3,rad=0.3\",\n",
    "                                relpos=(0.5,0)\n",
    "                               ),\n",
    "           )\n",
    "\n",
    "\n",
    "    ############################################################################################\n",
    "    grouped_cluster = selected_data.groupby(selected_data.cluster)\n",
    "    sns.set_palette('tableau')\n",
    "    for name, group in grouped_cluster:\n",
    "\n",
    "        data2 = group\n",
    "        ax = axs[4]\n",
    "        ax.format(\n",
    "            abc=True,abcloc='lr',abcstyle='A'\n",
    "        )    \n",
    "        ax.hist(data2.gdgt23ratio.values,bins=np.arange(0,30,2),\n",
    "                orientation='vertical',alpha=0.5,histtype='step',lw=1.5,\n",
    "                color=colors_GMM_mapping.get(name)\n",
    "               )\n",
    "\n",
    "        ax.format(\n",
    "            xlim=(0,50),\n",
    "            xticklabels=None,\n",
    "        )\n",
    "        ax.set_xticklabels([])\n",
    "\n",
    "        ax = axs[3]\n",
    "\n",
    "        sns.kdeplot(x=data2.gdgt23ratio,y=data2.TEX86,ax=ax,\n",
    "                    shade=True,thresh=0.05,color=colors_GMM_mapping.get(name),\n",
    "                    levels=np.arange(0.1,1.1,0.1),\n",
    "                    alpha=0.5,lw=0\n",
    "                   )\n",
    "\n",
    "        ax.format(\n",
    "            abc=True,abcloc='lr',abcstyle='A',\n",
    "            yticks=np.arange(0,1.2,0.2),\n",
    "            yticklabels=None,\n",
    "            xreverse=False,\n",
    "            ylim=(0,1),\n",
    "            xlim=(0,50),\n",
    "            xlabel='GDGT-2/-3'\n",
    "        )\n",
    "\n",
    "        ax.grid(True)\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "        ax = axs[5]\n",
    "        ax.format(\n",
    "            abc=True,abcloc='lr',abcstyle='A'\n",
    "        )    \n",
    "        ax.hist(data2.TEX86.values,bins=np.arange(0.1,1.1,0.1),orientation='horizontal',alpha=0.5,histtype='step',lw=1.5,color=colors_GMM_mapping.get(name))\n",
    "        ax.format(\n",
    "            ylabel=None,\n",
    "    #         ylim=(0,1),\n",
    "    #         yticks=np.arange(0,1.2,0.2)\n",
    "        )\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "        ax = axs[6]\n",
    "        ax.scatter(data2.WOA18_decav_insituS,data2.WOA18_decav_insituT,marker='.',alpha=1,zorder=2,color=colors_GMM_mapping.get(name))\n",
    "\n",
    "    ##### Envelop of the pycnocline separation (not GMM clustering)\n",
    "    ax = axs[3]\n",
    "    grouped_pycno = selected_data.groupby(selected_data.dataType_level3)\n",
    "    for name, gr_pycno in grouped_pycno:\n",
    "        x = gr_pycno.gdgt23ratio\n",
    "        y = gr_pycno.TEX86\n",
    "        \n",
    "        if 'Shallow' in pycno_label_name.get(name):\n",
    "            sns.kdeplot(x=x,y=y,shade=False,thresh=0.05,levels=[0.1],ls='--',\n",
    "                        color='k',\n",
    "                        zorder=0,\n",
    "                        ax=ax)\n",
    "\n",
    "            x1, y1, x2, y2 = 5,0.82,8,0.87\n",
    "            ax.annotate('Above Pycnocline\\n(Dash line)',color='0.25',\n",
    "                        fontsize=9,\n",
    "                        xy=(x1, y1), xycoords='data',\n",
    "                        xytext=(x2, y2), textcoords='data',\n",
    "                        arrowprops=dict(arrowstyle=\"fancy\",\n",
    "                                        color='0.25',\n",
    "                                        shrinkB=5,\n",
    "                                        connectionstyle=\"arc3,rad=0.3\",\n",
    "                                        relpos=(0,1)\n",
    "                                       ),\n",
    "                   )\n",
    "        elif 'Deep' in pycno_label_name.get(name):\n",
    "            print(pycno_label_name.get(name))\n",
    "            sns.kdeplot(x,y,shade=False,thresh=0.05,levels=[0.1],ls='dotted',\n",
    "                        color='k',\n",
    "                        zorder=0,\n",
    "                        ax=ax)\n",
    "    #         ax.scatter(x,y,marker='.',s=5,\n",
    "    #                    color='k',\n",
    "    #                   )\n",
    "            x1, y1, x2, y2 = 10,0.4,12,0.1\n",
    "            ax.annotate('Below Pycnocline\\n(Dotted line)',color='0.25',\n",
    "                        fontsize=9,\n",
    "                        xy=(x1, y1), xycoords='data',\n",
    "                        xytext=(x2, y2), textcoords='data',\n",
    "                        arrowprops=dict(arrowstyle=\"fancy\",\n",
    "                                        color='0.25',\n",
    "                                        shrinkB=8,\n",
    "                                        connectionstyle=\"arc3,rad=0.3\",\n",
    "                                        relpos=(0,1)\n",
    "                                       ),\n",
    "                   )\n",
    "\n",
    "    ####################################################################################################### \n",
    "    ##### Plotting Silhouette Scores and BIC curves\n",
    "    ax = axs[0]\n",
    "    ax.plot(range_n_clusters,silhouette_avg,marker='o',color='k',zorder=2)\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(range_n_clusters,BIC,marker='o',ls='--',color='0.5',zorder=1)\n",
    "\n",
    "    ax.format(\n",
    "        xticks=np.arange(1,10,1),\n",
    "        xtickminor=[],\n",
    "        ylabel='SS'\n",
    "    )\n",
    "    ax2.format(\n",
    "        ytickcolor='gray5',\n",
    "        ylabel='BIC'\n",
    "    )\n",
    "\n",
    "\n",
    "    ############################################################################\n",
    "    ############################################################################\n",
    "    ############################################################################\n",
    "    ############################################################################\n",
    "\n",
    "    selected_data_IPL = df_IPL[df_IPL.dataType_level1=='Water-column SPM'][df_IPL.QC_Indices_check=='Pass']\n",
    "    selected_data_IPL = selected_data_IPL.dropna(how='any',subset=['gdgt23ratio','TEX86'])\n",
    "    selected_data_IPL = selected_data_IPL.reset_index()\n",
    "    # Function to find distance ## see details from 4.3.1 PTD analysis \n",
    "    coef_PTD = -0.4242141432\n",
    "    intercept_PTD = 1.1579773469\n",
    "\n",
    "    # Function to find distance \n",
    "    a = float(coef_PTD)\n",
    "    b = -1\n",
    "    c = float(intercept_PTD)\n",
    "    selected_data_IPL['OrthoDist_from_PTD'] = abs(a*selected_data_IPL.gdgt23ratio+(b*selected_data_IPL.TEX86)+c)/np.sqrt(a*a+b*b)\n",
    "    selected_data_IPL = selected_data_IPL.dropna(how='any',subset=['gdgt23ratio','TEX86'])\n",
    "    selected_data_IPL = selected_data_IPL.reset_index()\n",
    "    selected_data_IPL = selected_data_IPL.drop(columns=['index'])\n",
    "\n",
    "    #Pre-processing data\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    features2=['gdgt23ratio','TEX86']\n",
    "    # df4 = scaler.fit_transform(selected_data_IPL[features2])\n",
    "    # selected_data_scaled = pd.DataFrame(df4,columns=features2)\n",
    "\n",
    "    selected_data_unscaled = selected_data_IPL[features2]\n",
    "\n",
    "\n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "    import matplotlib.cm as cm\n",
    "    sns.set_palette('tableau')\n",
    "    plot.rc.cycle = 'tableau'\n",
    "    range_n_clusters = np.arange(1,10,1)\n",
    "    X = selected_data_unscaled\n",
    "    silhouette_avg=[]\n",
    "    BIC = []\n",
    "\n",
    "    for n_clusters in range_n_clusters:\n",
    "        # Initialize the clusterer with n_clusters value and a random generator\n",
    "        # seed of 10 for reproducibility.\n",
    "        clusterer = mixture.GaussianMixture(n_components=n_clusters, covariance_type='full',n_init=20,random_state=1).fit(X)\n",
    "        cluster_labels = clusterer.predict(X)\n",
    "\n",
    "        # The silhouette_score gives the average value for all the samples.\n",
    "        # This gives a perspective into the density and separation of the formed\n",
    "        # clusters\n",
    "        if n_clusters == 1:\n",
    "            sil_avg = np.nan\n",
    "        else:\n",
    "            sil_avg = silhouette_score(X, cluster_labels,metric='mahalanobis')\n",
    "\n",
    "        bic = clusterer.bic(X)\n",
    "        aic = clusterer.aic(X)\n",
    "        silhouette_avg.append(sil_avg)\n",
    "        BIC.append(bic)\n",
    "\n",
    "        if n_clusters==n_clusters_plot[1]:\n",
    "            cl_weights, cl_means, cl_covars = clusterer.weights_, clusterer.means_, clusterer.covariances_\n",
    "            selected_data_IPL['cluster'] = cluster_labels\n",
    "            ax1 = axs[1+7]\n",
    "            ax1.format(\n",
    "                abc=True,abcloc='lr',abcstyle='A'\n",
    "            )\n",
    "\n",
    "            # The 1st subplot is the silhouette plot\n",
    "            # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "            # lie within [-0.1, 1]\n",
    "            ax1.set_xlim([-0.2, 1])\n",
    "            # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "            # plots of individual clusters, to demarcate them clearly.\n",
    "            ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "            print(\"For n_clusters =\", n_clusters,\n",
    "                  \"The average silhouette_score is :\", np.round(sil_avg,decimals=4))\n",
    "\n",
    "            # Compute the silhouette scores for each sample\n",
    "            sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "            y_lower = 10\n",
    "            for i in range(n_clusters):\n",
    "                # Aggregate the silhouette scores for samples belonging to\n",
    "                # cluster i, and sort them\n",
    "                ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "                ith_cluster_silhouette_values.sort()\n",
    "                ith_cluster_silh_mean = ith_cluster_silhouette_values.mean()\n",
    "\n",
    "                size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "                y_upper = y_lower + size_cluster_i\n",
    "\n",
    "                cmap = plot.Colormap('tableau')\n",
    "                color = cmap(float(i)/10)\n",
    "                ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                                  0, ith_cluster_silhouette_values,\n",
    "                                  facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "                # Label the silhouette plots with their cluster numbers at the middle\n",
    "                ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "                ax1.text(0.8, y_lower + 0.5 * size_cluster_i, str(np.round(ith_cluster_silh_mean,3)))\n",
    "\n",
    "                # Add middle line for each silhouette plot\n",
    "                ax1.axhline(y_lower + (0.5 * size_cluster_i),0.1,color='gray5',ls='--')\n",
    "\n",
    "                # Compute the new y_lower for next plot\n",
    "                y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "            ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "            ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "            # The vertical line for average silhouette score of all the values\n",
    "\n",
    "            ax1.axvline(x=sil_avg, color=\"red\", linestyle=\"--\")\n",
    "    #         ax1.format(\n",
    "    #             title='Silhouette average score\\nfor $%d$ clusters = '% n_clusters+str(np.round(silhouette_avg[0],decimals=3),)\n",
    "    #         )\n",
    "\n",
    "            ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "            ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "        ######################################################################################################\n",
    "        #### Calculated centers of each cluster on the real dimension ########################################\n",
    "\n",
    "            v1_mean = np.array(selected_data_IPL['gdgt23ratio'].groupby(selected_data_IPL.cluster).mean())\n",
    "        #     v1_mean = np.array(selected_data_IPL['log10gdgt23ratio'].groupby(selected_data_IPL.cluster).mean())\n",
    "            v2_mean = np.array(selected_data_IPL['TEX86'].groupby(selected_data_IPL.cluster).mean())\n",
    "            v3_mean = np.array(selected_data_IPL['OrthoDist_from_PTD'].groupby(selected_data_IPL.cluster).mean())\n",
    "        # #     v4_mean = np.array(selected_data_IPL['Depth'].groupby(selected_data_IPL.cluster).mean())\n",
    "        #     v4_mean = np.array(selected_data_IPL['log10Depth'].groupby(selected_data_IPL.cluster).mean())\n",
    "            realvalue_centers = np.transpose(np.vstack([v1_mean,v2_mean,v3_mean]))\n",
    "        #######################################################################################################   \n",
    "            ax2 = axs[2+7]\n",
    "            ax2.format(\n",
    "                abc=True,abcloc='lr',abcstyle='A',\n",
    "            )    \n",
    "            # 2nd Plot showing the actual clusters formed\n",
    "        #     colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "            cmap = plot.Colormap('tableau')\n",
    "            colors = cmap(cluster_labels.astype(float) /10)\n",
    "            ax2.scatter(selected_data_IPL['gdgt23ratio'], selected_data_IPL.TEX86, marker='.', s=30, lw=0, alpha=0.7,\n",
    "                        c=colors, edgecolor='k')\n",
    "\n",
    "            # Labeling the clusters\n",
    "        #     centers = clusterer.cluster_centers_\n",
    "            centers = realvalue_centers\n",
    "\n",
    "\n",
    "            # Draw white circles at cluster centers\n",
    "\n",
    "            ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "                        c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "\n",
    "            for i, c in enumerate(centers):\n",
    "                ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
    "                            s=50, edgecolor='k')\n",
    "\n",
    "                ax2.set_xlabel(\"GDGT-2/-3\")\n",
    "                ax2.set_ylabel(\"TEX86\")\n",
    "                ax2.format(\n",
    "                    ylim=(0,1)\n",
    "                )\n",
    "            #########################################################\n",
    "            ########################################################\n",
    "            grouped_cluster = selected_data_IPL.groupby(selected_data_IPL.cluster)\n",
    "            sns.set_palette('tableau')\n",
    "            for name, group in grouped_cluster:\n",
    "\n",
    "                data2 = group\n",
    "                ax = axs[4+7]\n",
    "                ax.format(\n",
    "                    abc=True,abcloc='lr',abcstyle='A'\n",
    "                )    \n",
    "                ax.hist(data2.gdgt23ratio.values,bins=np.arange(0,30,2),\n",
    "                        orientation='vertical',alpha=0.5,histtype='step',lw=1.5,\n",
    "                        color=colors_GMM_mapping.get(name)\n",
    "                       )\n",
    "\n",
    "                ax.format(\n",
    "                    xlim=(0,50),\n",
    "                    xticklabels=None,\n",
    "                )\n",
    "                ax.set_xticklabels([])\n",
    "\n",
    "                ax = axs[3+7]\n",
    "                ax.format(\n",
    "                    abc=True,abcloc='lr',abcstyle='A'\n",
    "                )\n",
    "\n",
    "                sns.kdeplot(data2.gdgt23ratio,data2.TEX86,ax=ax,\n",
    "                            shade=True,thresh=0.05,color=colors_GMM_mapping.get(name),\n",
    "                            levels=np.arange(0.1,1.1,0.1),\n",
    "                            alpha=0.5,lw=0\n",
    "                           )\n",
    "\n",
    "                ax.format(\n",
    "                    yticks=np.arange(0,1.2,0.2),\n",
    "                    yticklabels=None,\n",
    "                    xreverse=False,\n",
    "                    ylim=(0,1),\n",
    "                    xlim=(0,50),\n",
    "                    xlabel='GDGT-2/-3'\n",
    "                )\n",
    "\n",
    "                ax.grid(True)\n",
    "                ax.set_yticklabels([])\n",
    "\n",
    "                ax = axs[5+7]\n",
    "                ax.format(\n",
    "                    abc=True,abcloc='lr',abcstyle='A'\n",
    "                )    \n",
    "                ax.hist(data2.TEX86.values,bins=np.arange(0.1,1.1,0.1),orientation='horizontal',alpha=0.5,histtype='step',lw=1.5,color=colors_GMM_mapping.get(name))\n",
    "                ax.format(\n",
    "                    ylabel=None\n",
    "                )\n",
    "                ax.set_yticklabels([])\n",
    "\n",
    "                ax = axs[6+7]\n",
    "                ax.scatter(data2.WOA18_decav_insituS,data2.WOA18_decav_insituT,marker='.',alpha=1,zorder=2,color=colors_GMM_mapping.get(name))\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    ####################################################################################################\n",
    "    #Create a contour plot of sigma with T=0-30, S=32-38. Make sure the axes are labelled.\n",
    "    t_plot = np.arange(-5,31,0.05)\n",
    "    s_plot = np.arange(15,42.01,0.01)\n",
    "    S, T = np.meshgrid(s_plot,t_plot)\n",
    "    sigma_plot=sigmaT_cal_Miller_and_Poisson_1981(T,S)\n",
    "\n",
    "    #SPM column\n",
    "    ax = axs[6+7]\n",
    "    ax.format(\n",
    "        ultitle=\"C.I. = 1\",\n",
    "        abc=True,\n",
    "        abcstyle='A',\n",
    "        abcloc='lr',\n",
    "        xlim=(30,40),\n",
    "        xticks=np.arange(30,42,2),\n",
    "        xlabel='WOA18_insituS',\n",
    "        ylabel='WOA18_insituT'\n",
    "    )\n",
    "\n",
    "    CS = ax.contourf(s_plot,t_plot,sigma_plot,levels=np.arange(21,31,1), \n",
    "                     labels=False,\n",
    "                     cmap='Deep', \n",
    "                     labels_kw={'weight': 'bold'},\n",
    "                     lw=0.5,\n",
    "                     alpha=0.1,\n",
    "                     zorder=0\n",
    "    )\n",
    "    CS = ax.contour(s_plot,t_plot,sigma_plot,levels=np.arange(26.5,27,0.5), \n",
    "                     labels=False,\n",
    "                     c='darkred',ls='--',\n",
    "                     labels_kw={'weight': 'bold'},\n",
    "                     lw=2,\n",
    "                    zorder=1\n",
    "    ) \n",
    "    x1, y1, x2, y2 = 33,0,30.5,10\n",
    "    ax.annotate(r'$\\sigma_{T}$=26.5',color='0.1',weight='bold',\n",
    "                fontsize=9,\n",
    "                xy=(x1, y1), xycoords='data',\n",
    "                xytext=(x2, y2), textcoords='data',\n",
    "                arrowprops=dict(arrowstyle=\"fancy\",\n",
    "                                color='0',\n",
    "                                shrinkB=5,\n",
    "                                connectionstyle=\"arc3,rad=0.3\",\n",
    "                                relpos=(0.5,0)\n",
    "                               ),\n",
    "           )\n",
    "\n",
    "\n",
    "    # ############################################################################################\n",
    "\n",
    "    ax = axs[3+7]\n",
    "    grouped_pycno = selected_data_IPL.groupby(selected_data_IPL.dataType_level3)\n",
    "    for name, gr_pycno in grouped_pycno:\n",
    "        x = gr_pycno.gdgt23ratio\n",
    "        y = gr_pycno.TEX86\n",
    "        print(name)\n",
    "        if 'Shallow' in pycno_label_name.get(name):\n",
    "            sns.kdeplot(x,y,shade=False,thresh=0.05,levels=[0.1],ls='--',\n",
    "                        color='k',\n",
    "                        zorder=0,\n",
    "                        ax=ax)\n",
    "\n",
    "            x1, y1, x2, y2 = 8,0.82,15,0.87\n",
    "            ax.annotate('Above Pycnocline\\n(Dash line)',color='0.25',\n",
    "                        fontsize=9,\n",
    "                        xy=(x1, y1), xycoords='data',\n",
    "                        xytext=(x2, y2), textcoords='data',\n",
    "                        arrowprops=dict(arrowstyle=\"fancy\",\n",
    "                                        color='0.25',\n",
    "                                        shrinkB=5,\n",
    "                                        connectionstyle=\"arc3,rad=0.3\",\n",
    "                                        relpos=(0,1)\n",
    "                                       ),\n",
    "                       )\n",
    "            \n",
    "        elif 'Deep' in pycno_label_name.get(name):\n",
    "            print(pycno_label_name.get(name))\n",
    "            sns.kdeplot(x,y,shade=False,thresh=0.05,levels=[0.1],ls='dotted',\n",
    "                        color='k',\n",
    "                        zorder=0,\n",
    "                        ax=ax)\n",
    "\n",
    "            x1, y1, x2, y2 = 30,0.4,20,0.1\n",
    "            ax.annotate('Below Pycnocline\\n(Dotted line)',color='0.25',\n",
    "                        fontsize=9,\n",
    "                        xy=(x1, y1), xycoords='data',\n",
    "                        xytext=(x2, y2), textcoords='data',\n",
    "                        arrowprops=dict(arrowstyle=\"fancy\",\n",
    "                                        color='0.25',\n",
    "                                        shrinkB=8,\n",
    "                                        connectionstyle=\"arc3,rad=0.3\",\n",
    "                                        relpos=(0.5,1)\n",
    "                                       ),\n",
    "                   )\n",
    "\n",
    "    \n",
    "    #######################################################################################################   \n",
    "    ax = axs[0+7]\n",
    "    ax.plot(range_n_clusters,silhouette_avg,marker='o',color='k',zorder=2)\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(range_n_clusters,BIC,marker='o',ls='--',color='0.5',zorder=1)\n",
    "\n",
    "    ax.format(\n",
    "        abc=True,abcstyle='A',abcloc='ur',\n",
    "        xticks=np.arange(1,10,1),\n",
    "        xtickminor=[],\n",
    "        ylabel='SS'\n",
    "    )\n",
    "    \n",
    "    ax2.format(\n",
    "        ytickcolor='gray6',\n",
    "        ycolor='gray8',\n",
    "        ylabel='BIC'\n",
    "    )\n",
    "\n",
    "\n",
    "    ##### Draw envelop of OD ############\n",
    "    # Function to find distance ## see details from 4.3.1 PTD analysis \n",
    "    coef_PTD = -0.4242141432\n",
    "    intercept_PTD = 1.1579773469\n",
    "    \n",
    "    theta = np.arctan(float(coef_PTD))\n",
    "    intercept_OD = 1/np.cos(theta)\n",
    "    x1 = 0\n",
    "    y1 = (float(coef_PTD)*x1+(float(intercept_PTD)+intercept_OD))\n",
    "    y2 = 0\n",
    "    x2 = (y2-(float(intercept_PTD)+intercept_OD))/float(coef_PTD)\n",
    "\n",
    "\n",
    "    x3 = 0\n",
    "    y3 = (float(coef_PTD)*x3+(float(intercept_PTD)-intercept_OD))\n",
    "    y4 = 0\n",
    "    x4 = (y4-(float(intercept_PTD)-intercept_OD))/float(coef_PTD)\n",
    "\n",
    "    x_line = np.linspace(0,8,5)\n",
    "    topLine = (float(coef_PTD)*x_line+(float(intercept_PTD)+intercept_OD))\n",
    "    bottomLine = (float(coef_PTD)*x_line+(float(intercept_PTD)-intercept_OD))\n",
    "    PTD_Line = (float(coef_PTD)*x_line+(float(intercept_PTD)))\n",
    "\n",
    "    plot_axes = [2,9]\n",
    "    for i in range(len(plot_axes)):\n",
    "        ax = axs[plot_axes[i]]\n",
    "        ax.fill_between(x_line,topLine,bottomLine,alpha=0.8,zorder=0,color='gray2')\n",
    "        ax.plot(x_line,PTD_Line,\n",
    "             zorder=0,color='gray5',ls='--',lw=1)\n",
    "        ax.format(\n",
    "            xlim=(0,50)\n",
    "        )\n",
    "\n",
    "    plot_axes = [3,4,10,11]\n",
    "    for i in range(len(plot_axes)):\n",
    "        ax = axs[plot_axes[i]]\n",
    "        ax.format(\n",
    "            xlim=(0,50),\n",
    "            xticks=np.arange(0,55,10)\n",
    "        )\n",
    "    plot_axes = [0,7]\n",
    "    for i in range(len(plot_axes)):\n",
    "        ax = axs[plot_axes[i]]\n",
    "        ax.format(\n",
    "            abc=True,abcstyle='A',abcloc='ur'\n",
    "        )\n",
    "    plot_axes = [3,10]\n",
    "    for i in range(len(plot_axes)):\n",
    "        ax = axs[plot_axes[i]]\n",
    "        ax.format(\n",
    "            ylabel=''\n",
    "        )\n",
    "\n",
    "    # filepath = \"/content/drive/MyDrive/Colab Notebooks/images/MarineAOA_project/Supplementary_figures/\"\n",
    "    # filepath = \"C:\\\\Users\\\\ratta\\\\marine-AOA-GDGT-distribution\\\\supplementary-figure\\\\\"\n",
    "    # filename = 'figS4_SI_PNAS_SPM_GMM.pdf'\n",
    "    # fig.savefig(filepath+filename,api=330,bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 785
    },
    "id": "60eU-JpOYGxc",
    "outputId": "ede41d09-1f29-4c92-9640-1b50d2f2ac0b"
   },
   "outputs": [],
   "source": [
    "figS4_SI_figure_PNAS_MarineAOA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tsWF7k51xmnR"
   },
   "source": [
    "### **4.3.4 Figure S5 - Deep-water paleo-data (>1000m) subset analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eXC03IxSxyta"
   },
   "outputs": [],
   "source": [
    "def figS5_SI_figure_PNAS_marineAOA():\n",
    "    rc_params = {\n",
    "        'fontsize': 8,\n",
    "        'fontname': 'Tex Gyre Heros',\n",
    "        'text.labelsize':8,\n",
    "        'axes.labelpad':2\n",
    "    }\n",
    "    plot.rc.update(rc_params)\n",
    "\n",
    "\n",
    "    array = [\n",
    "        [1,1,0,0],\n",
    "        [2,3,4,5],\n",
    "        [6,6,6,6]\n",
    "    ]\n",
    "    fig, axs = plot.subplots(array,\n",
    "                            figsize=(7,6),\n",
    "                            hratios=(0.25,0.7,1),\n",
    "                            wspace=('2em'),hspace=('5em'),\n",
    "                            sharey=False,spany=False,\n",
    "                            sharex=False,spanx=False\n",
    "                            )\n",
    "\n",
    "    paleoData = df_nonIPL[df_nonIPL.dataType_level0=='Ancient'][df_nonIPL.QC_Indices_check=='Pass'][df_nonIPL.detectionLimit_check=='Pass'][df_nonIPL.paleoWaterDepth>=1000]\n",
    "\n",
    "    # Function to find distance \n",
    "    coef_ThCren = -0.2375\n",
    "    intercept_ThCren = 0.9956\n",
    "\n",
    "    a = float(coef_ThCren)\n",
    "    b = -1\n",
    "    c = float(intercept_ThCren)\n",
    "    paleoData['OrthoDist_from_PTD'] = abs(a*paleoData.gdgt23ratio+(b*paleoData.TEX86)+c)/np.sqrt(a*a+b*b)\n",
    "    selected_data = paleoData.dropna(how='any',subset=['gdgt23ratio','TEX86','sampleAge',\n",
    "                                                        'paleolat','paleolon','paleoWaterDepth',\n",
    "                                                       'OrthoDist_from_PTD',\n",
    "                                                    ])\n",
    "    selected_data = selected_data.reset_index()\n",
    "    selected_data = selected_data.drop(columns=['index'])\n",
    "    #Pre-processing data\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    features2=['gdgt23ratio','TEX86']\n",
    "    df4 = scaler.fit_transform(selected_data[features2])\n",
    "    selected_data_scaled = pd.DataFrame(df4,columns=features2)\n",
    "    selected_data_unscaled = selected_data[features2]\n",
    "\n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn import mixture\n",
    "    from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "    import matplotlib.cm as cm\n",
    "    sns.set_palette('tableau')\n",
    "    plot.rc.cycle = 'tableau'\n",
    "    range_n_clusters = np.arange(1,11,1)\n",
    "    X = selected_data_unscaled\n",
    "    silhouette_avg=[]\n",
    "    BIC=[]\n",
    "\n",
    "    plot_n_clusters = 2\n",
    "\n",
    "    for n_clusters in range_n_clusters:\n",
    "        # Initialize the clusterer with n_clusters value and a random generator\n",
    "        # seed of 10 for reproducibility.\n",
    "    #     clusterer = KMeans(n_clusters=n_clusters, random_state=1)\n",
    "        clusterer = mixture.GaussianMixture(n_components=n_clusters,covariance_type='full',random_state=1,n_init=20).fit(X)\n",
    "        cluster_labels = clusterer.fit_predict(X)\n",
    "        \n",
    "        \n",
    "\n",
    "        # The silhouette_score gives the average value for all the samples.\n",
    "        # This gives a perspective into the density and separation of the formed\n",
    "        # clusters\n",
    "        if n_clusters == 1:\n",
    "            sil_avg = np.nan\n",
    "        else:\n",
    "            sil_avg = silhouette_score(X, cluster_labels,metric='mahalanobis')\n",
    "        silhouette_avg.append(sil_avg)\n",
    "        BIC.append(clusterer.bic(X))\n",
    "        \n",
    "        \n",
    "        if n_clusters==plot_n_clusters:\n",
    "            gmm_weights = clusterer.weights_\n",
    "            gmm_means = clusterer.means_\n",
    "            gmm_covars = clusterer.covariances_\n",
    "            \n",
    "            selected_data['cluster'] = cluster_labels\n",
    "            print(\"For n_clusters =\", n_clusters,\n",
    "                  \"The average silhouette_score is :\", np.round(sil_avg,decimals=4))\n",
    "    \n",
    "\n",
    "        ######################################################################################################\n",
    "        #### Calculated centers of each cluster on the real dimension\n",
    "            v1_mean = np.array(selected_data['gdgt23ratio'].groupby(selected_data.cluster).mean())\n",
    "            v2_mean = np.array(selected_data['TEX86'].groupby(selected_data.cluster).mean())\n",
    "            realvalue_centers = np.transpose(np.vstack([v1_mean,v2_mean]))\n",
    "\n",
    "        ################################################################################################################   \n",
    "            ax2 = axs[1]\n",
    "            ax2.format(\n",
    "                urtitle=f\"k = {n_clusters}\"\n",
    "            )    \n",
    "            # 2nd Plot showing the actual clusters formed\n",
    "        #     colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "            cmap = plot.Colormap('tableau')\n",
    "            colors = cmap(cluster_labels.astype(float) / 10)\n",
    "            ax2.scatter(selected_data['gdgt23ratio'], selected_data.TEX86, marker='.', s=5, lw=0, alpha=0.7,\n",
    "                        c=colors)\n",
    "            \n",
    "\n",
    "            # Labeling the clusters\n",
    "        #     centers = clusterer.cluster_centers_\n",
    "            centers = realvalue_centers\n",
    "\n",
    "\n",
    "            # Draw white circles at cluster centers\n",
    "\n",
    "            ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "                        c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "\n",
    "            for i, c in enumerate(centers):\n",
    "                ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
    "                            s=50, edgecolor='k')\n",
    "\n",
    "    #         ax2.set_title(\"GDGT-2/-3 vs. TEX86\")\n",
    "            ax2.set_xlabel('')\n",
    "            ax2.set_ylabel(r\"$TEX_{86}$\")\n",
    "            ax2.format(\n",
    "                ltitle='GMM of paleo-GDGTs',\n",
    "                ylim=(0,1),\n",
    "                xlim=(0,25),\n",
    "                xticks=np.arange(0,30,5),\n",
    "            )\n",
    "            \n",
    "            \n",
    "            \n",
    "            ### Plotting data into different group\n",
    "            grouped = selected_data.groupby(selected_data.dataType_level3)\n",
    "            plot_axes = {\n",
    "                'Late Cenozoic':2,\n",
    "                'Early Cenozoic':3,\n",
    "                'Mesozoic':4\n",
    "            }\n",
    "            for name, group in grouped:\n",
    "                cmap = plot.Colormap('tableau')\n",
    "                colors2 = cmap(group.cluster.astype(float) / 10)\n",
    "                ax = axs[plot_axes.get(name)]\n",
    "                ax.scatter(group.gdgt23ratio,group.TEX86,color=colors2,marker='.', s=5, lw=0, alpha=0.7,)\n",
    "                ax.format(\n",
    "                    rtitle=name,\n",
    "                    ylim=(0,1),\n",
    "                    xlim=(0,25),\n",
    "                    xticks=np.arange(0,30,5),\n",
    "                    xlabel='',\n",
    "                    ylabel='',\n",
    "                    yticklabels=[]\n",
    "                )\n",
    "                ax.fill_between((15,25),1,0.95,color=colors_mapping.get(name),edgecolor='0.5',alpha=1)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    ###########################################################################\n",
    "    ax = axs[0]\n",
    "    ax.plot(range_n_clusters,silhouette_avg,marker='o',color='k',zorder=2)\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(range_n_clusters,BIC,marker='o',ls='--',color='0.5',zorder=1)\n",
    "    # ax2.plot(range_n_clusters,AIC,marker='o',ls='--',zorder=0)\n",
    "\n",
    "    ax.format(\n",
    "        abc=True,abcstyle='A',abcloc='ur',\n",
    "        xticks=np.arange(1,11,1),\n",
    "        xtickminor=[],\n",
    "        xlabel='Number of clusters (k)',\n",
    "        ylabel='SS',\n",
    "    #     ylim=(0,1)\n",
    "    )\n",
    "    ax2.format(\n",
    "        ytickcolor='gray6',\n",
    "        ycolor='gray8',\n",
    "        ylabel='BIC'\n",
    "    )\n",
    "    ##########################################################################\n",
    "\n",
    "    ##### Draw envelop of OD = 0.6 ############\n",
    "\n",
    "    theta = np.arctan(np.float(coef_ThCren))\n",
    "    intercept_OD06 = 0.6/np.cos(theta)\n",
    "    x1 = 0\n",
    "    y1 = (np.float(coef_ThCren)*x1+(np.float(intercept_ThCren)+intercept_OD06))\n",
    "    y2 = 0\n",
    "    x2 = (y2-(np.float(intercept_ThCren)+intercept_OD06))/np.float(coef_ThCren)\n",
    "\n",
    "\n",
    "    x3 = 0\n",
    "    y3 = (np.float(coef_ThCren)*x3+(np.float(intercept_ThCren)-intercept_OD06))\n",
    "    y4 = 0\n",
    "    x4 = (y4-(np.float(intercept_ThCren)-intercept_OD06))/np.float(coef_ThCren)\n",
    "\n",
    "    x_line = np.linspace(0,8,5)\n",
    "    topLine = (np.float(coef_ThCren)*x_line+(np.float(intercept_ThCren)+intercept_OD06))\n",
    "    bottomLine = (np.float(coef_ThCren)*x_line+(np.float(intercept_ThCren)-intercept_OD06))\n",
    "    ThCren_Line = (np.float(coef_ThCren)*x_line+(np.float(intercept_ThCren)))\n",
    "\n",
    "    plot_axes = [1,2,3,4]\n",
    "    for i in range(len(plot_axes)):\n",
    "        ax = axs[plot_axes[i]]\n",
    "        ax.fill_between(x_line,topLine,bottomLine,alpha=0.8,zorder=0,color='gray2')\n",
    "        ax.plot(x_line,ThCren_Line,\n",
    "            zorder=0,color='gray5',ls='--',lw=1)\n",
    "        ax.format(\n",
    "            abc=True,abcstyle='A',abcloc='lr',\n",
    "        )\n",
    "    axs[2].text(20,-0.2,'GDGT-2/-3')\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ax = axs[5]\n",
    "\n",
    "    grouped2 = selected_data.groupby(selected_data.cluster)\n",
    "    ii=0\n",
    "    for name2, group2 in grouped2:\n",
    "        ax.scatter(group2.sampleAge,  group2.gdgt23ratio, marker='.', s=5, lw=0, alpha=0.7,\n",
    "                        c=('tableau',ii))\n",
    "        binsize=2\n",
    "        paleoDepth_rollmean = rollmean_calculation_step(group2,'gdgt23ratio',0,200,binsize)\n",
    "        ax.step(paleoDepth_rollmean[:,0],paleoDepth_rollmean[:,2],where='post',color=('tableau',ii),lw=0.5)\n",
    "        ax.fill_between(paleoDepth_rollmean[:,0],paleoDepth_rollmean[:,5],paleoDepth_rollmean[:,6],\n",
    "                        step='post',color=('tableau',ii),\n",
    "                        alpha=0.1)\n",
    "    #     ax.vlines(paleoDepth_rollmean[:,0]+binsize/2,paleoDepth_rollmean[:,3],paleoDepth_rollmean[:,5],color=('tableau',ii))\n",
    "        ax.fill_between(paleoDepth_rollmean[:,0],paleoDepth_rollmean[:,3],paleoDepth_rollmean[:,4],\n",
    "                        step='post',color=('tableau',ii),\n",
    "                        alpha=0.3)\n",
    "        ii += 1\n",
    "\n",
    "    ldf = gts.data.loc[gts.data.Level == \"Period\", :]\n",
    "    ageName = ldf.Name\n",
    "    ageStart = ldf.Start\n",
    "    ageEnd = ldf.End\n",
    "    ageMean = ldf.MeanAge\n",
    "    ageColor = ldf.Color\n",
    "\n",
    "    for i in range(len(ldf.Name[:5])):\n",
    "\n",
    "        h = 2\n",
    "        w = ageStart[i] - ageEnd[i]\n",
    "        y = -4\n",
    "        x = ageEnd[i]\n",
    "        xy = (x,y)\n",
    "        \n",
    "        rect = Rectangle(xy,w,h,\n",
    "                        facecolor=ageColor[i],\n",
    "                        edgecolor=\"k\")\n",
    "        ax.add_artist(rect)\n",
    "        if ageName[i] == \"Quaternary\":\n",
    "            continue\n",
    "        else:        \n",
    "            ax.text(ageMean[i]-9,(y-h)/1.75,ageName[i],\n",
    "                fontname='TeX Gyre Heros',\n",
    "                rotation=0)\n",
    "\n",
    "    ldf = gts.data.loc[gts.data.Level == \"Epoch\", :]\n",
    "    ageName = ldf.Epoch\n",
    "    ageStart = ldf.Start\n",
    "    ageEnd = ldf.End\n",
    "    ageMean = ldf.MeanAge\n",
    "    ageColor = ldf.Color\n",
    "    eraName = ldf.Era\n",
    "    for i in range(len(ldf.Name[:12])):\n",
    "\n",
    "        h = 2\n",
    "        w = ageStart[i] - ageEnd[i]\n",
    "        y = -2\n",
    "        x = ageEnd[i]\n",
    "        xy = (x,y)\n",
    "        \n",
    "        rect = Rectangle(xy,w,h,\n",
    "                        facecolor=ageColor[i],\n",
    "                        edgecolor=\"k\")\n",
    "        ax.add_artist(rect)\n",
    "        if eraName[i] == \"Mesozoic\":\n",
    "            if ageName[i] == \"Middle\":\n",
    "                ax.text(ageMean[i]-4,y/1.5,ageName[i][0:3]+'.',fontname='TeX Gyre Heros',\n",
    "                    rotation=0) \n",
    "            elif ageName[i] == \"Lower\":\n",
    "                ax.text(ageMean[i]-4,y/1.5,'Early',fontname='TeX Gyre Heros',\n",
    "                    rotation=0)\n",
    "            elif ageName[i] == \"Upper\":\n",
    "                ax.text(ageMean[i]-4,y/1.5,'Late',fontname='TeX Gyre Heros',\n",
    "                    rotation=0)    \n",
    "            else:\n",
    "                ax.text(ageMean[i]-4,y/1.5,ageName[i],fontname='TeX Gyre Heros',\n",
    "                    rotation=0)\n",
    "        elif ((ageName[i] == \"Pliocene\")|(ageName[i] == \"Pleistocene\")|(ageName[i] == \"Holocene\")):\n",
    "            continue\n",
    "        else:        \n",
    "            ax.text(ageMean[i]-4,y/1.5,ageName[i][0:3]+'.',\n",
    "                fontname='TeX Gyre Heros',\n",
    "                rotation=0)    \n",
    "\n",
    "\n",
    "    ax.format(\n",
    "        abc=True,abcstyle='A',abcloc='ul',\n",
    "        yreverse=False,\n",
    "        xlim=(0,200),\n",
    "        xticks=np.arange(0,205,10),\n",
    "        xtickloc='bottom',\n",
    "        ylim=(-4,25),\n",
    "        ytickrange=(0,25),\n",
    "        yticks=np.arange(0,25,5),\n",
    "        xlabel=\"Age (Million years ago, Ma)\",\n",
    "        ylabel='GDGT-2/-3'\n",
    "    )\n",
    "\n",
    "    plt.show()\n",
    "    # filepath = \"/content/drive/MyDrive/Colab Notebooks/images/MarineAOA_project/Supplementary_figures/\"\n",
    "    # filepath = \"C:\\\\Users\\\\ratta\\\\marine-AOA-GDGT-distribution\\\\figures\\\\supplementary-figure\\\\\"\n",
    "    # figname = 'figS5_GMM_Paleo_deepSamples'\n",
    "    # fig.savefig(filepath+figname+'.pdf',dpi=330,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 634
    },
    "id": "jkH6MG-nyE2v",
    "outputId": "564e2f1b-03cf-4074-9df0-68e56f14db1c"
   },
   "outputs": [],
   "source": [
    "figS5_SI_figure_PNAS_marineAOA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUvSBwcrI3lw"
   },
   "source": [
    "### **4.3.5 Figure S6 - Ancient GDGTs above and below 1000 mbsl**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rwYM07L_I38J"
   },
   "outputs": [],
   "source": [
    "def figS6_SI_PNAS_MarineAOA():\n",
    "    paleo_plots_order = {\n",
    "        'Late Cenozoic':0,\n",
    "        'Early Cenozoic':1,\n",
    "        'Mesozoic':2\n",
    "    }\n",
    "\n",
    "    fig, axs = plot.subplots(ncols=3,nrows=2,width=7)\n",
    "    axs.format(\n",
    "        collabels=['Late Cenozoic','Early Cenozoic','Mesozoic'],\n",
    "        rowlabels=['Shallow ancient GDGTs\\n(0-1000m)         ','Deep ancient GDGTs\\n(>1000m)         '],\n",
    "        abc=True,abcloc='ur',abcstyle='A',\n",
    "    )\n",
    "    paleoData = df_nonIPL[df_nonIPL.dataType_level0=='Ancient'][df_nonIPL.QC_Indices_check=='Pass'][df_nonIPL.detectionLimit_check=='Pass']\n",
    "\n",
    "    grouped = paleoData.groupby('dataType_level2')\n",
    "    for i, (name,group) in enumerate(grouped):\n",
    "        temp_col = []\n",
    "        for j in range(len(group)):\n",
    "            if group.paleoWaterDepth.iloc[j] <= 1000:\n",
    "                temp_col.append('Shallow (0-1000m)')\n",
    "            elif group.paleoWaterDepth.iloc[j] > 1000:\n",
    "                temp_col.append('Deep (>1000m)')\n",
    "            else:\n",
    "                temp_col.append(np.nan)\n",
    "        group['paleoOceanLayer'] = temp_col \n",
    "        grouped2 = group.groupby('paleoOceanLayer')\n",
    "        for ii, (name2,group2) in enumerate(grouped2):\n",
    "            if 'Shallow' in name2:\n",
    "              ax = axs[paleo_plots_order.get(name)]\n",
    "              ax.scatter(group2.gdgt23ratio,group2.TEX86,marker='.',color='orange8')\n",
    "            elif 'Deep' in name2:\n",
    "              ax = axs[paleo_plots_order.get(name)+3]\n",
    "              ax.scatter(group2.gdgt23ratio,group2.TEX86,marker='.')\n",
    "    ##### Draw envelop of OD = ############\n",
    "    # Function to find distance ## see details from 4.3.1 PTD analysis \n",
    "    coef_PTD = -0.4242141432\n",
    "    intercept_PTD = 1.1579773469\n",
    "\n",
    "\n",
    "    theta = np.arctan(float(coef_PTD))\n",
    "    intercept_OD = 1/np.cos(theta)\n",
    "    x1 = 0\n",
    "    y1 = (float(coef_PTD)*x1+(float(intercept_PTD)+intercept_OD))\n",
    "    y2 = 0\n",
    "    x2 = (y2-(float(intercept_PTD)+intercept_OD))/float(coef_PTD)\n",
    "\n",
    "\n",
    "    x3 = 0\n",
    "    y3 = (float(coef_PTD)*x3+(float(intercept_PTD)-intercept_OD))\n",
    "    y4 = 0\n",
    "    x4 = (y4-(float(intercept_PTD)-intercept_OD))/float(coef_PTD)\n",
    "\n",
    "    x_line = np.linspace(0,8,5)\n",
    "    topLine = (float(coef_PTD)*x_line+(float(intercept_PTD)+intercept_OD))\n",
    "    bottomLine = (float(coef_PTD)*x_line+(float(intercept_PTD)-intercept_OD))\n",
    "    midLine = (float(coef_PTD)*x_line+(float(intercept_PTD)))\n",
    "\n",
    "    for i in range(6):\n",
    "        ax = axs[i]\n",
    "        ax.plot([x1,x2],[y1,y2],color='gray5',zorder=0,ls='dotted',lw=1)\n",
    "        ax.plot([x3,x4],[y3,y4],color='gray5',zorder=0,ls='dotted',lw=1)\n",
    "        ax.fill_between(x_line,topLine,bottomLine,alpha=0.8,zorder=0,color='gray2')\n",
    "        ax.plot(x_line,midLine,\n",
    "              zorder=0,color='gray5',ls='--',lw=1)\n",
    "        ax.format(\n",
    "            abc=True,abcstyle='A',abcloc='ur',\n",
    "            xlim=(0,25),\n",
    "            ylim=(0,1),\n",
    "            yticks=np.arange(0,1.2,0.2),\n",
    "            xticks=np.arange(0,25,5),\n",
    "            xlabel='',\n",
    "            ylabel=''\n",
    "        )\n",
    "    # filepath = \"/content/drive/MyDrive/Colab Notebooks/images/MarineAOA_project/Supplementary_figures/\"\n",
    "    # filepath = \"C:\\\\Users\\\\ratta\\\\marine-AOA-GDGT-distribution\\\\figures\\\\supplementary-figure\\\\\"\n",
    "    # figname = 'figS6_Paleo_deepSamples_1000m_cutOff'\n",
    "    # fig.savefig(filepath+figname+'.pdf',dpi=330,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "KXKerbFPOelt",
    "outputId": "96d23f05-a77e-4348-ba26-e2e8d16489bb"
   },
   "outputs": [],
   "source": [
    "figS6_SI_PNAS_MarineAOA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9PskEVns16m"
   },
   "source": [
    "### **4.3.6 Figure S7 - Location map**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6vMi5Bo5IeQM"
   },
   "outputs": [],
   "source": [
    "def figS7_SI_PNAS_MarineAOA():\n",
    "    new_rc_params = {'text.usetex': False,\n",
    "                    \"svg.fonttype\": 'none',\n",
    "                    'text.labelsize':'10',\n",
    "                    'facecolor':'#FFFFFF',\n",
    "                    'fontname': 'TeX Gyre Heros'\n",
    "                    }\n",
    "    plot.rc.update(new_rc_params)\n",
    "    plot_data = pd.concat([df_nonIPL[df_nonIPL.QC_Indices_check=='Pass'],df_nonIPL_hs]).dropna(how='any',subset=['TEX86','gdgt23ratio'])\n",
    "    \n",
    "    array=[[1,2],\n",
    "           [3,4],\n",
    "           [5,6],\n",
    "           [7,8],\n",
    "          ]\n",
    "    fig, axs = plot.subplots(array,proj='robin',figsize=(7,7))\n",
    "    axs.format(\n",
    "        land=True,landcolor='gray4',landzorder=0,\n",
    "        abc=True, abcstyle='A'\n",
    "    )\n",
    "    ax = axs[0]\n",
    "    grouped = plot_data[plot_data.dataType_level0!='Culture'].groupby(['dataType_level3'])\n",
    "    \n",
    "    for i, (name,group) in enumerate(grouped):\n",
    "        ax = axs[plots_mapping2.get(name)]\n",
    "\n",
    "        plot_data = group.dropna(how='any',subset=['Latitude','Longitude'])\n",
    "        ax.scatter(plot_data.Longitude,plot_data.Latitude,marker='.',alpha=1,\n",
    "                   zorder=2,\n",
    "                   color=colors_mapping.get(name),\n",
    "                   transform=ccrs.PlateCarree())\n",
    "        if group.dataType_level0.unique()[0] == 'Ancient':\n",
    "            grouped2 = group.groupby(['Latitude','Longitude'])\n",
    "            number_sites = len(grouped2)\n",
    "            ax.format(\n",
    "                ltitle=name+f' (n = {group.sampleID_new.count()}; {number_sites} drilling sites)',\n",
    "            )\n",
    "        else:# (('SPM' in name)|('Hot spring' in name)):\n",
    "            grouped2 = group.groupby(['Latitude','Longitude'])\n",
    "            number_sites = len(grouped2)\n",
    "            ax.format(\n",
    "                ltitle=name+f' (n = {group.sampleID_new.count()}; {number_sites} sampling sites)',\n",
    "            )\n",
    "            \n",
    "    # filepath = \"/content/drive/MyDrive/Colab Notebooks/images/MarineAOA_project/Supplementary_figures/\"\n",
    "    filepath = \"C:\\\\Users\\\\ratta\\\\marine-AOA-GDGT-distribution\\\\figures\\\\supplementary-figure\\\\\"\n",
    "    figname = 'figS7_PNAS_location_maps'\n",
    "    fig.savefig(filepath+figname+'.pdf',dpi=330,bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "id": "b0HXc3pLIkjP",
    "outputId": "c2449f31-0c51-45c4-d0e6-34f2a45429c7"
   },
   "outputs": [],
   "source": [
    "figS7_SI_PNAS_MarineAOA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tRARptFS67xs"
   },
   "source": [
    "### **4.3.7 Figure S9 - Permanent pycnoclines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T-OuLF5wUy7d"
   },
   "outputs": [],
   "source": [
    "def figS7_permanent_pycnocline():\n",
    "    rc_params = {\n",
    "        'fontsize': 10,\n",
    "        'fontname': 'Tex Gyre Heros',\n",
    "        'text.labelsize':10,\n",
    "    }\n",
    "    plot.rc.update(rc_params)\n",
    "\n",
    "    array = [[1,2],\n",
    "             [3,3]]\n",
    "\n",
    "    fig, axs = plot.subplots(array,width=6.5)\n",
    "\n",
    "\n",
    "\n",
    "    ax = axs[0]\n",
    "    #### DATA for suplot A #####\n",
    "    sel_sigma_mon = sigma_all_mon.sel(lat=40,lon=-25,method='nearest')\n",
    "    plot_depth = sigma_all_mon.sel(lat=40,lon=-25,method='nearest').depth\n",
    "    for i in range(12):\n",
    "        plot_data = sel_sigma_mon.sel(time=i,method='nearest')\n",
    "        ax.plot(plot_data,plot_depth,cycle='reds',label=month_mapping.get(i))\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles,loc='lower left',frameon=True, ncol=2)\n",
    "    ax.hlines(75,24,27.5,ls='--')\n",
    "\n",
    "    sigma_all.sel(lat=40,lon=-25,method='nearest').plot(y='depth',color='k',ls='--',ax=ax)\n",
    "    ax.format(\n",
    "        abc=True,abcstyle='A',abcloc='ul',\n",
    "        title='Monthly and annual\\nof seawater density\\nat 40°N, 25°W',\n",
    "        ylim = (0,300),\n",
    "        xlim = (24,27.5),\n",
    "        xlabel='Seawater Density (sigma-T)'\n",
    "    )\n",
    "\n",
    "    ax = axs[1]\n",
    "    #### DATA for suplot B #####\n",
    "    sigma_mon_std.sel(lat=40,lon=-25,method='nearest').plot(y='depth',color='k',ax=ax)\n",
    "    ax.vlines(0.1,0,300,ls='--')\n",
    "    ax.hlines(75,0,0.7,ls='--')\n",
    "    ax.format(\n",
    "        abc=True,abcstyle='A',abcloc='ul',\n",
    "        title='Standard Deviation (SD)\\nof seawater density\\nat 40°N, 25°W',\n",
    "        xlim=(0,0.7),\n",
    "        ylim = (0,300),\n",
    "        xlabel='Seawater Density (sigma-T)'\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    ax = axs[2]\n",
    "    ax.format(\n",
    "        abc=True,abcstyle='A',\n",
    "        ltitle='    25°W Meridional Section of the Atlantic Ocean',\n",
    "        ylim=(0,800),\n",
    "        xformatter='deglat',\n",
    "        xlabel=''\n",
    "    )\n",
    "\n",
    "    ############INPUT DATA from WOA18 decav and monav ####################\n",
    "\n",
    "    sigma25W_decav = sigma_all.sel(lon=-25,method='nearest')\n",
    "    # sigma170W_decav = sigma_all.sel(lon=-170,method='nearest')\n",
    "    lon_decav = sigma_all.lon\n",
    "    lat_decav = sigma_all.lat\n",
    "    depth_decav = sigma_all.depth\n",
    "\n",
    "\n",
    "    # sigmaSTD_0m = sigma_mon_std.sel(depth=0,method='nearest')\n",
    "    sigmaSTD_25W = sigma_mon_std.sel(lon=-25,method='nearest')\n",
    "    # sigmaSTD_170W = sigma_mon_std.sel(lon=-170,method='nearest')\n",
    "    lon_STD = sigma_mon_std.lon\n",
    "    lat_STD = sigma_mon_std.lat\n",
    "    depth_STD = sigma_mon_std.depth \n",
    "    CB = ax.contourf(lat_STD,depth_STD,sigmaSTD_25W,\n",
    "                      vmin=0,vmax=1,levels=10,cmap='blues_r'\n",
    "                    )\n",
    "    CS0 = ax.contour(lat_STD,depth_STD,sigmaSTD_25W,\n",
    "                      vmin=0,vmax=1,levels=10,cmap='blues_r'\n",
    "                    )\n",
    "    CS0.collections[1].set_lw(1.5)\n",
    "    CS0.collections[1].set_ls('--')\n",
    "    CS0.collections[1].set_color('w')\n",
    "\n",
    "\n",
    "    CS1 = ax.contour(\n",
    "        lat_decav,depth_decav,\n",
    "        sigma25W_decav,\n",
    "        vmin=20,vmax=30,\n",
    "        levels=np.linspace(20,30,21),\n",
    "        color='w',\n",
    "        lw=0.5,\n",
    "    )\n",
    "\n",
    "    ax.clabel(CS1,np.linspace(20,29,10),fmt='%1.0f')\n",
    "\n",
    "    ax.colorbar(CB,loc='l',boundaries=np.linspace(0,1,10),col=[1,2],\n",
    "                label=\"Sigma-T SD\")\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patches as mpatches\n",
    "\n",
    "    x1, y1 = 0, 100\n",
    "    x2, y2 = -40, 300\n",
    "    ax.annotate(\"Permanent Pycnocline\",color='w',\n",
    "                xy=(x1, y1), xycoords='data',\n",
    "                xytext=(x2, y2), textcoords='data',\n",
    "                arrowprops=dict(arrowstyle=\"fancy\",\n",
    "                                color=\"w\",\n",
    "                                shrinkB=5,\n",
    "                                connectionstyle=\"arc3,rad=-0.3\",\n",
    "                                ),\n",
    "                )\n",
    "    axs.format(\n",
    "        yreverse=True\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    # filepath = '/content/drive/MyDrive/Colab Notebooks/images/MarineAOA_project/Supplementary_figures/'\n",
    "    # figname = 'figS7_permanent_pycnoclines'\n",
    "    # fig.savefig(filepath+figname+'.pdf',dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 671
    },
    "id": "dW4QX7LnN8A9",
    "outputId": "d988e6ac-3c32-425e-e7bd-f26d981acb15"
   },
   "outputs": [],
   "source": [
    "figS7_permanent_pycnocline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dL-g94Namr4"
   },
   "source": [
    "## **4.4 Supplementary Tables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRVOFXdbauWj"
   },
   "source": [
    "### **4.4.1 Table S1 - Data sources for modern archives**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "VyopRHsUa0au",
    "outputId": "9da28001-cf6c-4d44-920b-8d028afccec3"
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "plot_data = pd.concat([df_nonIPL[df_nonIPL.QC_Indices_check=='Pass'],df_nonIPL_hs,df_IPL[df_IPL.dataType_level1=='Water-column SPM'][df_IPL.QC_Indices_check=='Pass']])\n",
    "plot_table = plot_data[plot_data.dataType_level0!='Ancient'].dropna(how='any',subset=['TEX86','gdgt23ratio'])\n",
    "tableS1 = pd.pivot_table(plot_table, values=['sampleID_new'], index=['dataType_level1','short_remark','lipidClass','Source2'],\n",
    "                    aggfunc=lambda x: len(x.unique()),margins=True)\n",
    "tableS1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmJZAuY_sHqy"
   },
   "source": [
    "### **4.4.2 Table S2 - Data sources for modern archives**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "plot_data = pd.concat([df_nonIPL[df_nonIPL.QC_Indices_check=='Pass'],df_nonIPL_hs])\n",
    "plot_table = plot_data[plot_data.dataType_level0=='Ancient']\n",
    "tableS2 = pd.pivot_table(plot_table, values=['sampleID_new'], index=['dataType_level1','short_remark','lipidClass','Source2'],\n",
    "                    aggfunc=lambda x: len(x.unique()),margins=True)\n",
    "tableS2"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPfYdk42/Xy8awt9GdqZwjL",
   "include_colab_link": true,
   "name": "PNAS_pythonCodeS2_BeyondTEX86_Analytics_Visualizations_RR.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "pyleo",
   "language": "python",
   "name": "pyleo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
